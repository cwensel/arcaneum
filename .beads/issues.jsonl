{"id":"arcaneum-1","title":"Create Claude Code marketplace project structure","description":"Create the foundational directory structure and packaging setup for the Arcaneum Claude Code marketplace project. This establishes where all code lives and how components are packaged/distributed.\n\nDeliverables:\n- pyproject.toml with modern Python packaging\n- Directory structure: src/, plugins/, docs/, tests/\n- MCP server plugin scaffold\n- Installation method via uvx or pip\n- README with quick start guide\n\nThis is the foundation that all other RDRs build upon.","design":"Directory Structure:\n```\narcaneum/\n├── pyproject.toml          # Modern packaging\n├── README.md               # Quick start\n├── src/\n│   └── arcaneum/\n│       ├── __init__.py\n│       ├── server/         # MCP server core\n│       ├── indexing/       # Bulk upload logic\n│       └── search/         # Search utilities\n├── plugins/\n│   ├── qdrant-server/      # Server management plugin\n│   ├── qdrant-indexer/     # Bulk upload plugin\n│   └── qdrant-search/      # Search plugin\n├── tests/\n└── docs/\n\nInstallation:\n- uvx install arcaneum\n- pip install arcaneum\n\nMCP Plugin Discovery:\n- Each plugin has its own pyproject.toml\n- Plugins register via entry points\n- Claude Code discovers via marketplace registry","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.685704-07:00","updated_at":"2025-10-20T07:41:10.685704-07:00","closed_at":"2025-10-19T10:23:12.252341-07:00"}
{"id":"arcaneum-10","title":"Review Chroma embedding references and validate for Qdrant","description":"Review chroma-embedded/upload.sh and outstar-rag-requirements.md for embedding model usage patterns. Validate if these approaches apply to Qdrant or need adaptation.","notes":"Review completed. ChromaDB patterns transfer directly to Qdrant with adaptations: increase batch size to 100-200, client-side embeddings, same chunking strategies. FastEmbed equivalence needs validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.68751-07:00","updated_at":"2025-10-20T07:41:10.68751-07:00","closed_at":"2025-10-19T14:30:51.356705-07:00","dependencies":[{"issue_id":"arcaneum-10","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.722364-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-100","title":"Rename CLI tool from 'arcaneum' to 'arc'","description":"Rename the CLI tool from `arcaneum` to `arc` for shorter, more professional command-line experience.\n\n**Rationale**:\n- Industry standard: short CLI names (git, gh, aws, npm, docker, kubectl → k8s)\n- Faster to type: 3 chars vs 9 chars (6 chars saved per command)\n- Professional: Short tools feel polished\n- No backwards compatibility needed (pre-release stage)\n\n**Changes Required**:\n\n1. **Entry Point Configuration**:\n   - Update `setup.py` or `pyproject.toml`\n   - Change console_scripts entry from `arcaneum` to `arc`\n   - Example: `arc = \"arcaneum.cli.main:cli\"`\n\n2. **RDR Documentation** (all 12 RDRs):\n   - Global find/replace: `arcaneum ` → `arc `\n   - Files: RDR-001 through RDR-012\n   - Preserve \"Arcaneum\" when referring to project name (only change command examples)\n\n3. **README.md**:\n   - Update all command examples\n   - Update installation instructions\n   - Update quick start guide\n\n4. **Help Text**:\n   - Update CLI help strings\n   - Update command descriptions\n\n5. **Test Files**:\n   - Update test assertions that check command output\n   - Update documentation strings\n\n**Validation**:\n- `arc --help` works\n- `arc --version` shows correct version\n- All subcommands accessible via `arc`\n- `arcaneum` command no longer exists (or returns helpful error)\n\n**Files to Modify**:\n- `setup.py` or `pyproject.toml`\n- `doc/rdr/RDR-*.md` (all 12 files)\n- `README.md`\n- `src/arcaneum/cli/main.py` (help text)\n- Test files (command assertions)\n\n**Estimated Effort**: 2 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T10:33:53.472773-07:00","updated_at":"2025-10-27T10:58:59.840876-07:00","closed_at":"2025-10-27T10:58:59.840876-07:00"}
{"id":"arcaneum-101","title":"Create docker-compose.yml for Qdrant v1.15.4","description":"Implement docker-compose.yml at repository root per RDR-002 specifications. Include Qdrant v1.15.4 image, ports 6333/6334, volume mounts for storage/snapshots/models, resource limits (4GB RAM, 2 CPUs), and environment variables.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-27T11:03:43.964105-07:00","updated_at":"2025-10-27T11:04:02.959753-07:00","closed_at":"2025-10-27T11:04:02.959753-07:00","dependencies":[{"issue_id":"arcaneum-101","depends_on_id":"arcaneum-2","type":"discovered-from","created_at":"2025-10-27T11:03:43.966384-07:00","created_by":"daemon"}]}
{"id":"arcaneum-102","title":"Create scripts/qdrant-manage.sh management script","description":"Implement server management script per RDR-002. Support commands: start, stop, restart, logs, status. Include health check verification and make executable.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-27T11:03:44.072191-07:00","updated_at":"2025-10-27T11:04:33.699707-07:00","closed_at":"2025-10-27T11:04:33.699707-07:00","dependencies":[{"issue_id":"arcaneum-102","depends_on_id":"arcaneum-2","type":"discovered-from","created_at":"2025-10-27T11:03:44.072815-07:00","created_by":"daemon"}]}
{"id":"arcaneum-103","title":"Create src/arcaneum/collections/init.py with named vectors","description":"Implement collection initialization module per RDR-002. Define configs for source-code and pdf-docs collections with named vectors (stella, modernbert, bge, jina). Configure HNSW parameters and payload indexes.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-27T11:03:44.116651-07:00","updated_at":"2025-10-27T11:04:55.368004-07:00","closed_at":"2025-10-27T11:04:55.368004-07:00","dependencies":[{"issue_id":"arcaneum-103","depends_on_id":"arcaneum-2","type":"discovered-from","created_at":"2025-10-27T11:03:44.117258-07:00","created_by":"daemon"}]}
{"id":"arcaneum-104","title":"Create src/arcaneum/embeddings/client.py with FastEmbed","description":"Implement EmbeddingClient class per RDR-002. Support multiple models (stella, jina, modernbert, bge) with caching, model configurations with dimensions, and client-side embedding generation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-27T11:03:44.174836-07:00","updated_at":"2025-10-27T11:05:16.358916-07:00","closed_at":"2025-10-27T11:05:16.358916-07:00","dependencies":[{"issue_id":"arcaneum-104","depends_on_id":"arcaneum-2","type":"discovered-from","created_at":"2025-10-27T11:03:44.175476-07:00","created_by":"daemon"}]}
{"id":"arcaneum-105","title":"Create pyproject.toml with Qdrant dependencies","description":"Create Python project configuration per RDR-002. Include dependencies: qdrant-client\u003e=1.15.0, fastembed\u003e=0.3.0, click. Configure project metadata and entry points.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-27T11:03:44.221582-07:00","updated_at":"2025-10-27T11:05:38.154243-07:00","closed_at":"2025-10-27T11:05:38.154243-07:00","dependencies":[{"issue_id":"arcaneum-105","depends_on_id":"arcaneum-2","type":"discovered-from","created_at":"2025-10-27T11:03:44.222248-07:00","created_by":"daemon"}]}
{"id":"arcaneum-106","title":"Implement RDR-003: CLI Tool for Qdrant Collection Creation","description":"Implemented complete CLI tool for managing Qdrant collections with named vectors following RDR-003 specification. Includes collection creation, listing, info display, and deletion commands with full test coverage.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-27T11:21:53.820954-07:00","updated_at":"2025-10-27T11:21:59.199997-07:00","closed_at":"2025-10-27T11:21:59.199997-07:00"}
{"id":"arcaneum-107","title":"Implement RDR-004: PDF Bulk Indexing","description":"Implement production-ready bulk PDF indexing system with OCR support, following RDR-004 specification","notes":"Implementation complete with all RDR-004 requirements + enhancements:\n\nCORE MODULES:\n- bin/arc: Main CLI entrypoint (in bin/ per Unix convention)\n- src/arcaneum/indexing/pdf/extractor.py: PyMuPDF + pdfplumber fallback\n- src/arcaneum/indexing/pdf/ocr.py: Tesseract OCR with preprocessing\n- src/arcaneum/indexing/pdf/chunker.py: 15% overlap + late chunking\n- src/arcaneum/indexing/common/sync.py: Metadata-based incremental sync\n- src/arcaneum/indexing/uploader.py: Batch uploader with retry\n- src/arcaneum/cli/index_pdfs.py: CLI command with rich output\n\nKEY FEATURES:\n- Text PDFs: PyMuPDF extraction (95x faster than alternatives)\n- Image PDFs: Tesseract OCR (confidence ≥60%, 2x image scaling)\n- Auto OCR trigger: When extracted text \u003c 100 chars\n- Incremental sync: file_path + file_hash metadata queries\n- Late chunking: For 2K-8K token documents (stella, modernbert, jina)\n- Batch upload: 100-200 chunks/batch, 4 parallel workers\n- Retry logic: Exponential backoff with Tenacity, max 10s wait\n- Offline mode: --offline flag for cached models (bypasses SSL issues)\n- Clean logging: Quiet by default, --verbose for details\n- Ctrl+C handling: Shows partial progress on interrupt\n\nCLI OPTIONS:\n--collection (required), --model (stella/bge/modernbert/jina)\n--workers (parallel upload), --ocr-enabled, --ocr-language\n--force (reindex all), --offline (cached only), --verbose, --json\n\nDOCUMENTATION:\n- doc/guides/pdf-indexing.md: Complete user guide\n- doc/guides/arc-cli-reference.md: Full CLI reference  \n- doc/guides/QUICKSTART.md: 5-minute getting started\n- doc/testing/TESTING.md: Step-by-step testing\n- doc/testing/TEST-COMMANDS.md: Quick commands\n- doc/testing/CORPORATE-PROXY.md: SSL workaround\n- doc/testing/OFFLINE-MODE.md: Offline mode guide\n\nDEPLOYMENT:\n- deploy/docker-compose.yml: Qdrant service config\n- scripts/download-models.py: Pre-download for corporate proxies\n- scripts/test-pdf-indexing.sh: Automated integration test\n- scripts/create-test-pdf.py: Test PDF generator\n\nDISCOVERED ISSUES:\n- arcaneum-108: Parallelize PDF processing (future enhancement)\n\nUSAGE:\nbin/arc index-pdfs ./pdfs --collection docs --model stella --offline","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-27T11:30:08.093915-07:00","updated_at":"2025-10-27T14:04:27.846158-07:00","closed_at":"2025-10-27T11:32:20.683871-07:00"}
{"id":"arcaneum-108","title":"Parallelize PDF indexing for 2-4x speedup","description":"Add parallel processing of PDFs (extract, OCR, embed) to improve indexing throughput. Current implementation is sequential per PDF. Parallel workers could process 4 PDFs simultaneously for 2-4x speedup, especially on OCR-heavy workloads.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-27T14:02:40.845628-07:00","updated_at":"2025-10-27T14:02:40.845628-07:00","dependencies":[{"issue_id":"arcaneum-108","depends_on_id":"arcaneum-107","type":"discovered-from","created_at":"2025-10-27T14:02:40.85013-07:00","created_by":"daemon"}]}
{"id":"arcaneum-109","title":"RDR-005: Git-Aware Source Code Indexing with AST Chunking","description":"Implement production-ready git-aware source code indexing system for Qdrant with AST-aware chunking for 15+ languages, multi-branch support, and metadata-based sync","design":"See doc/rdr/RDR-005-source-code-indexing.md for complete technical design","acceptance_criteria":"- Index git repositories with AST-aware chunking\n- Support 15+ programming languages via tree-sitter\n- Multi-branch support with composite identifiers (project#branch)\n- Metadata-based sync with Qdrant as source of truth\n- Filter-based branch-specific deletion (40-100x faster than ChromaDB)\n- Respect .gitignore patterns via git ls-files\n- Code-specific embeddings (jina-code models)\n- Read-only git operations (no mutations)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-10-27T14:08:31.963289-07:00","updated_at":"2025-10-27T14:28:37.338427-07:00","closed_at":"2025-10-27T14:28:37.338427-07:00"}
{"id":"arcaneum-11","title":"Research Qdrant client-side embedding capabilities","description":"Review qdrant-client Python library source code for embedding model integration, FastEmbed support, and collection configuration options. Document features and APIs.","notes":"Research completed. Qdrant client has deep FastEmbed integration. Collection creation via create_collection() with VectorParams. Named vectors supported. HNSW config: m=16, ef_construct=100 defaults.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.688474-07:00","updated_at":"2025-10-20T07:41:10.688474-07:00","closed_at":"2025-10-19T14:30:51.424705-07:00","dependencies":[{"issue_id":"arcaneum-11","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.723279-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-110","title":"Step 1: Implement Core Git Operations Module","description":"Create src/arcaneum/indexing/git_operations.py with GitProjectDiscovery class, metadata extraction with robust error handling, edge case support (detached HEAD, shallow clones, missing remotes, submodules), credential sanitization for remote URLs, and timeout protection (5s per git command)","acceptance_criteria":"- GitProjectDiscovery.find_git_projects() with depth control\n- extract_metadata() with composite identifier (project#branch)\n- Handle detached HEAD states (git describe --tags, git name-rev)\n- Detect shallow clones (.git/shallow)\n- Sanitize credentials from remote URLs\n- 5-second timeout per git command\n- Tests with mocked git repos","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:10.881024-07:00","updated_at":"2025-10-27T14:16:04.234791-07:00","closed_at":"2025-10-27T14:16:04.234791-07:00","dependencies":[{"issue_id":"arcaneum-110","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:10.881801-07:00","created_by":"daemon"}]}
{"id":"arcaneum-111","title":"Step 2: Implement AST Chunking Module","description":"Create src/arcaneum/indexing/ast_chunker.py integrating tree-sitter-language-pack, implement ASTCodeChunker class with language detection for 15+ languages, add fallback to line-based chunking, configure chunk sizes per embedding model (32K vs 8K context), track chunking method in metadata","acceptance_criteria":"- ASTCodeChunker with tree-sitter integration\n- Support 15+ languages (Python, Java, JS, TS, Go, Rust, C/C++, etc)\n- Automatic fallback to line-based on AST failure\n- Configurable chunk sizes (400 tokens for 8K, 2K-4K for 32K models)\n- Track extraction method (ast_python, ast_java, line_based)\n- \u003e95% AST parsing success rate in tests","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:10.935544-07:00","updated_at":"2025-10-27T14:19:18.446793-07:00","closed_at":"2025-10-27T14:19:18.446793-07:00","dependencies":[{"issue_id":"arcaneum-111","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:10.936206-07:00","created_by":"daemon"}]}
{"id":"arcaneum-112","title":"Step 3: Implement Metadata-Based Sync Module","description":"Create src/arcaneum/indexing/git_metadata_sync.py with GitMetadataSync class (follows RDR-04 pattern), query Qdrant for indexed (project, branch, commit) tuples, cache results to avoid repeated queries, provide should_reindex_project() method, use Qdrant as single source of truth","acceptance_criteria":"- GitMetadataSync.get_indexed_projects() using Qdrant scroll\n- Caching of indexed projects per collection\n- should_reindex_project() comparing commit hashes\n- \u003c5s metadata query for 1000 projects\n- Tests with mocked Qdrant client","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:10.988802-07:00","updated_at":"2025-10-27T14:21:06.476975-07:00","closed_at":"2025-10-27T14:21:06.476975-07:00","dependencies":[{"issue_id":"arcaneum-112","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:10.989878-07:00","created_by":"daemon"}]}
{"id":"arcaneum-113","title":"Step 4: Implement Qdrant Integration Module","description":"Create src/arcaneum/indexing/qdrant_indexer.py with filter-based bulk deletion for branches, batch upload with 100-200 chunk batching, gRPC support for faster uploads, retry logic with exponential backoff","acceptance_criteria":"- delete_branch_chunks() using Filter with git_project_identifier\n- \u003c500ms for branch-specific deletion\n- upload_chunks_batch() with 150-chunk batches\n- gRPC protocol support\n- Exponential backoff retry logic\n- Tests with test collection","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:11.042824-07:00","updated_at":"2025-10-27T14:25:18.359309-07:00","closed_at":"2025-10-27T14:25:18.359309-07:00","dependencies":[{"issue_id":"arcaneum-113","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:11.04348-07:00","created_by":"daemon"}]}
{"id":"arcaneum-114","title":"Step 5: Implement Main Orchestration Pipeline","description":"Create src/arcaneum/indexing/source_code_pipeline.py with SourceCodeIndexer orchestrator class, integrate all modules (git, AST, metadata sync, Qdrant), add progress reporting (rich), add CLI interface with argument parsing, implement metadata-based sync pattern","acceptance_criteria":"- SourceCodeIndexer.index_directory() with metadata-based sync\n- Integration of git discovery, AST chunking, sync, and Qdrant upload\n- Progress reporting with rich\n- CLI with --input, --collection, --depth, --force flags\n- 100-200 files/sec indexing throughput\n- End-to-end integration tests","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:11.098381-07:00","updated_at":"2025-10-27T14:27:51.581573-07:00","closed_at":"2025-10-27T14:27:51.581573-07:00","dependencies":[{"issue_id":"arcaneum-114","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:11.099061-07:00","created_by":"daemon"},{"issue_id":"arcaneum-114","depends_on_id":"arcaneum-110","type":"blocks","created_at":"2025-10-27T14:09:11.099413-07:00","created_by":"daemon"},{"issue_id":"arcaneum-114","depends_on_id":"arcaneum-111","type":"blocks","created_at":"2025-10-27T14:09:11.099729-07:00","created_by":"daemon"},{"issue_id":"arcaneum-114","depends_on_id":"arcaneum-112","type":"blocks","created_at":"2025-10-27T14:09:11.10003-07:00","created_by":"daemon"},{"issue_id":"arcaneum-114","depends_on_id":"arcaneum-113","type":"blocks","created_at":"2025-10-27T14:09:11.100334-07:00","created_by":"daemon"}]}
{"id":"arcaneum-115","title":"Step 6: Create Branch Comparison Query Examples","description":"Add documentation/examples for querying specific branches using git_project_identifier, comparing implementations across branches, listing all branches of a project, branch-specific deletion examples","acceptance_criteria":"- Example: Query specific branch with git_project_identifier filter\n- Example: Compare implementations across branches side-by-side\n- Example: List all branches of a project\n- Example: Delete specific branch\n- Documentation with runnable Python examples","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-27T14:09:11.155343-07:00","updated_at":"2025-10-27T14:09:11.155343-07:00","dependencies":[{"issue_id":"arcaneum-115","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:11.155905-07:00","created_by":"daemon"},{"issue_id":"arcaneum-115","depends_on_id":"arcaneum-114","type":"blocks","created_at":"2025-10-27T14:09:11.156234-07:00","created_by":"daemon"}]}
{"id":"arcaneum-116","title":"Step 7: Create MCP Plugin Wrapper","description":"Create plugins/qdrant-indexer/mcp_server.py exposing index_source_code() MCP tool, check_indexing_status() tool, delete_project() tool, return structured progress updates, handle errors gracefully for Claude UI","acceptance_criteria":"- MCP tool: index_source_code(input_path, collection_name, depth)\n- MCP tool: check_indexing_status(collection_name)\n- MCP tool: delete_project(collection_name, project_identifier)\n- Structured progress updates for Claude UI\n- Error handling with user-friendly messages","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-27T14:09:11.214174-07:00","updated_at":"2025-10-27T14:09:11.214174-07:00","dependencies":[{"issue_id":"arcaneum-116","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:11.21485-07:00","created_by":"daemon"},{"issue_id":"arcaneum-116","depends_on_id":"arcaneum-114","type":"blocks","created_at":"2025-10-27T14:09:11.215242-07:00","created_by":"daemon"}]}
{"id":"arcaneum-117","title":"Add dependencies for source code indexing","description":"Add required dependencies to pyproject.toml: tree-sitter-language-pack (^0.5.0), llama-index (^0.9.0), GitPython (^3.1.40), tenacity (^8.2.0), rich (^13.7.0). Verify qdrant-client[fastembed] and FastEmbed already present from RDR-003","acceptance_criteria":"- pyproject.toml updated with all dependencies\n- Dependencies installed and verified\n- No version conflicts\n- Import tests pass for all new packages","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:37.678743-07:00","updated_at":"2025-10-27T14:12:19.329925-07:00","closed_at":"2025-10-27T14:12:19.329925-07:00","dependencies":[{"issue_id":"arcaneum-117","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:37.679601-07:00","created_by":"daemon"}]}
{"id":"arcaneum-118","title":"Create types and metadata schema for source code indexing","description":"Create src/arcaneum/indexing/types.py with @dataclass definitions: GitMetadata, CodeChunk, CodeChunkMetadata with all fields from RDR schema including git_project_identifier (primary), git metadata fields, code analysis fields, embedding metadata","acceptance_criteria":"- GitMetadata dataclass with project_root, commit_hash, branch, remote_url, project_name\n- CodeChunk dataclass with content, embedding, file_path, metadata\n- CodeChunkMetadata with all fields from RDR (git_project_identifier, file fields, git fields, analysis fields)\n- Type hints and validation\n- Unit tests for dataclass construction","status":"closed","priority":1,"issue_type":"task","assignee":"Claude","created_at":"2025-10-27T14:09:37.722966-07:00","updated_at":"2025-10-27T14:13:43.805785-07:00","closed_at":"2025-10-27T14:13:43.805785-07:00","dependencies":[{"issue_id":"arcaneum-118","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:37.723594-07:00","created_by":"daemon"}]}
{"id":"arcaneum-119","title":"Create comprehensive test suite for source code indexing","description":"Create test files: tests/test_git_operations.py, tests/test_ast_chunker.py, tests/test_metadata_sync.py, tests/test_qdrant_indexer.py, tests/test_multi_branch.py, tests/test_incremental_sync.py with unit and integration tests","acceptance_criteria":"- Unit tests for git operations and branch detection\n- Unit tests for AST chunking (15+ languages)\n- Unit tests for metadata-based sync (Qdrant queries)\n- Integration tests for multi-branch workflow\n- Integration tests for incremental sync\n- \u003e80% code coverage\n- All test scenarios from RDR validated","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-27T14:09:37.768258-07:00","updated_at":"2025-10-27T14:09:37.768258-07:00","dependencies":[{"issue_id":"arcaneum-119","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:37.768892-07:00","created_by":"daemon"},{"issue_id":"arcaneum-119","depends_on_id":"arcaneum-114","type":"blocks","created_at":"2025-10-27T14:09:37.769271-07:00","created_by":"daemon"}]}
{"id":"arcaneum-12","title":"Research opensource projects for collection management","description":"Search for existing opensource tools/libraries that manage Qdrant collections with embedding models. Evaluate as replacement or inspiration (mcp-server-qdrant, qdrant-haystack, etc).","notes":"Research completed. Recommendation: Build from scratch using qdrant-client+FastEmbed (Apache 2.0). Avoid GPL-3.0 tools. Inspiration from analogrithems/qdrant-cli structure, mcp-server-qdrant patterns. Bundle QdrantUI as companion.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.689348-07:00","updated_at":"2025-10-20T07:41:10.689348-07:00","closed_at":"2025-10-19T14:30:51.484132-07:00","dependencies":[{"issue_id":"arcaneum-12","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.724072-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-120","title":"Create performance benchmarking suite","description":"Create performance tests to validate: filter-based deletion vs ID-based (40-100x target), AST chunking speed per language, batch upload throughput (100-200 files/sec target), metadata query overhead (Qdrant scroll), incremental sync performance","acceptance_criteria":"- Benchmark: filter-based deletion \u003c500ms\n- Benchmark: 100-200 files/sec indexing throughput\n- Benchmark: \u003c1s per git metadata extraction\n- Benchmark: \u003e95% AST parsing success\n- Benchmark: \u003c5s metadata query for 1000 projects\n- Performance regression detection","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-27T14:09:37.813909-07:00","updated_at":"2025-10-27T14:09:37.813909-07:00","dependencies":[{"issue_id":"arcaneum-120","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:37.814603-07:00","created_by":"daemon"},{"issue_id":"arcaneum-120","depends_on_id":"arcaneum-114","type":"blocks","created_at":"2025-10-27T14:09:37.815068-07:00","created_by":"daemon"}]}
{"id":"arcaneum-121","title":"Update RDR-005 status to In Progress","description":"Update doc/rdr/RDR-005-source-code-indexing.md metadata status from 'Recommendation' to 'In Progress' and update doc/rdr/index.md","acceptance_criteria":"- RDR-005 status changed to 'In Progress'\n- index.md updated with new status\n- Committed to git","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-10-27T14:09:37.885581-07:00","updated_at":"2025-10-27T19:31:02.380114-07:00","closed_at":"2025-10-27T19:31:02.380114-07:00","dependencies":[{"issue_id":"arcaneum-121","depends_on_id":"arcaneum-109","type":"parent-child","created_at":"2025-10-27T14:09:37.886198-07:00","created_by":"daemon"}]}
{"id":"arcaneum-122","title":"Add collection type enforcement (pdf vs code)","description":"Collections should have a type (pdf or code) declared at creation time. Indexing commands should validate that content matches collection type. No mixing of types in a single collection. This provides clearer separation, better validation, and prevents accidental mixed collections.","design":"**Architecture:**\n\nCollection type is the foundation - corpus builds on it.\n\n**1. Collection Type Storage (Qdrant metadata):**\n```python\n# Stored as collection-level metadata in Qdrant\n{\n  \"collection_type\": \"pdf\",  # or \"code\"\n  \"created_at\": \"2025-10-27\",\n  \"created_by\": \"arcaneum\",\n  \"model\": \"stella\"\n}\n```\n\n**2. API Design:**\n\n```bash\n# Collection (Qdrant only)\narc create-collection docs --model stella --type pdf\narc create-collection code --model stella --type code\n\n# Corpus (Qdrant + MeiliSearch) \narc create-corpus docs --type pdf\n# ├─\u003e Creates TYPED Qdrant collection 'docs' (type=pdf)\n# └─\u003e Creates MeiliSearch index 'docs' (with type metadata)\n```\n\n**3. Validation on Index:**\n\n```python\ndef validate_collection_type(collection_name, expected_type):\n    \"\"\"Validate collection type matches expected.\"\"\"\n    metadata = get_collection_metadata(collection_name)\n    actual_type = metadata.get(\"collection_type\")\n    \n    if actual_type != expected_type:\n        raise TypeError(\n            f\"Collection '{collection_name}' is type '{actual_type}', \"\n            f\"cannot index {expected_type} content\"\n        )\n\n# In index_pdfs\nvalidate_collection_type(collection_name, \"pdf\")\n\n# In index_source  \nvalidate_collection_type(collection_name, \"code\")\n```\n\n**4. Backward Compatibility:**\n\nFor collections created before typing:\n- Query collection metadata for \"collection_type\"\n- If missing: return None (untyped)\n- Allow indexing to untyped collections with warning\n- Or: Auto-detect type from store_type in points (first index wins)\n\n**5. Corpus Type Inheritance:**\n\nCorpus operations inherit type from underlying collection:\n```python\ndef create_corpus(name, type):\n    # Create typed collection (foundation)\n    create_collection(name, model=\"stella\", type=type)\n    \n    # Create MeiliSearch index (inherits type)\n    create_fulltext_index(name, corpus_type=type)\n```\n\n**6. Implementation Files:**\n\n- `src/arcaneum/indexing/collection_metadata.py`: Helper functions to get/set/validate collection type\n- Update `src/arcaneum/cli/collections.py`: Add --type flag to create-collection\n- Update `src/arcaneum/cli/index_pdfs.py`: Validate type=pdf\n- Update `src/arcaneum/cli/index_source.py`: Validate type=code\n- Update `src/arcaneum/cli/corpus.py`: Create typed collections","acceptance_criteria":"**Collection Commands:**\n- arc create-collection docs --model stella --type pdf\n- arc create-collection code --model stella --type code\n- arc collection-info docs shows type=pdf\n- arc collection-info code shows type=code\n\n**Indexing Validation:**\n- arc index-pdfs ~/docs --collection docs (type=pdf matches)\n- arc index-source ~/projects --collection code (type=code matches)\n- arc index-pdfs ~/docs --collection code - Error: Collection 'code' is type 'code', cannot index PDFs\n- arc index-source ~/projects --collection docs - Error: Collection 'docs' is type 'pdf', cannot index source code\n\n**Corpus Commands:**\n- arc create-corpus docs --type pdf (creates typed Qdrant + MeiliSearch)\n- arc create-corpus code --type code (creates typed Qdrant + MeiliSearch)\n- Type validation inherited from collection type\n\n**Backward Compatibility:**\n- Untyped collections allow indexing with warning\n- Or auto-detect type from first index operation\n\n**Documentation:**\n- All RDR examples updated with --type flag\n- TESTING guides show typed collections\n- Clear explanation of collection vs corpus","status":"closed","priority":1,"issue_type":"feature","assignee":"Claude","created_at":"2025-10-27T14:33:27.562583-07:00","updated_at":"2025-10-27T14:53:04.770268-07:00","closed_at":"2025-10-27T14:53:04.770268-07:00"}
{"id":"arcaneum-123","title":"Standardize collection naming in RDR examples","description":"Update all RDR examples (RDR-002, RDR-003, RDR-004, RDR-005) to use consistent collection naming: 'docs' for PDFs, 'code' for source code. Remove confusing examples like 'source-code', 'pdf-docs', 'MyCode'. Make clear that names are suggestions but types are enforced.","acceptance_criteria":"- RDR-002: Use 'docs' and 'code' in examples\n- RDR-003: Use 'docs' and 'code' in examples\n- RDR-004: Use 'docs' in examples\n- RDR-005: Use 'code' in examples\n- Add note: \"Collection names are flexible, but types (pdf vs code) are enforced\"\n- Consistent pattern across all documentation","status":"open","priority":2,"issue_type":"chore","created_at":"2025-10-27T14:33:27.606608-07:00","updated_at":"2025-10-27T14:33:27.606608-07:00"}
{"id":"arcaneum-124","title":"Auto-detect vector name from collection for index-source","description":"When indexing source code, the --model flag must match the collection's vector name or it fails. Should auto-detect the vector name from the collection and use it, falling back to --model only if collection doesn't exist yet.","acceptance_criteria":"- arc index-source ~/projects --collection code (auto-detects vector name from collection)\n- No need to specify --model if collection exists\n- Falls back to --model flag for new collections\n- Clear error if model specified doesn't match collection","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-27T14:56:57.111645-07:00","updated_at":"2025-10-27T14:57:16.273422-07:00","closed_at":"2025-10-27T14:57:16.273422-07:00"}
{"id":"arcaneum-125","title":"Standardize minimal terminal output for indexing commands","description":"Create parity between index-pdfs and index-source terminal output. By default, show minimal clean output with overall progress. Hide verbose INFO logs unless --verbose flag is used. Both commands should have similar quiet output style showing only essential progress.","acceptance_criteria":"- Default output: Clean, minimal, no INFO logs visible\n- index-pdfs: Show overall progress (X/Y PDFs processed)\n- index-source: Show per-repo progress (X/Y repos indexed, current repo: files/chunks)\n- --verbose flag: Show detailed INFO logs\n- Consistent output format between both commands\n- No rich progress bars by default (or very minimal)\n- Exit codes: 0 for success, 1 for errors, 130 for Ctrl-C","notes":"Use cases:\n- PDF indexing: May index single file or directory tree. More likely to scan dirs for sync operations. Files process quickly (seconds each).\n- Code indexing: May index single repo or directory with many repos. Less likely to scan dirs for sync. Repos can have thousands of files and take minutes.\n\nDesign considerations:\n- Minimal output by default (no INFO logs flooding terminal)\n- Show what matters: overall progress, current operation\n- Verbose mode for debugging\n- Consistent UX between both commands","status":"closed","priority":1,"issue_type":"feature","assignee":"Claude","created_at":"2025-10-27T15:46:39.228472-07:00","updated_at":"2025-10-27T15:56:26.73703-07:00","closed_at":"2025-10-27T15:56:26.73703-07:00"}
{"id":"arcaneum-126","title":"Add per-repo file/chunk progress for source code indexing","description":"Git repos can have thousands of files. Need incremental progress showing where we are in indexing each repo: files processed, chunks created, upload progress. This is critical for large repos like elasticsearch, hadoop, spring-boot that may take minutes per repo.","acceptance_criteria":"- Show per-repo progress: \"Indexing repo-name#branch: 234/1000 files, 1234 chunks...\"\n- Update progress during file processing (not just at end)\n- Show chunk generation and upload progress\n- Clear indication when repo completes\n- Use rich progress bar or simple text updates\n- Example output: \"[2/66] gradle#master: 450/890 files → 2341 chunks → uploading...\"","notes":"Large repos that need progress visibility:\n- elasticsearch: ~2000+ Java files\n- hadoop: ~1000+ Java files  \n- spring-boot: ~1500+ Java files\n- gradle: ~800+ Groovy/Java files\n- quarkus: ~1000+ Java files\n\nWithout progress, user doesn't know if:\n- It's hung/frozen\n- Still processing files\n- Generating embeddings\n- Uploading chunks\n\nNeed incremental feedback during long operations.","status":"closed","priority":1,"issue_type":"feature","assignee":"Claude","created_at":"2025-10-27T15:46:39.329754-07:00","updated_at":"2025-10-27T16:04:33.234846-07:00","closed_at":"2025-10-27T16:04:33.234846-07:00"}
{"id":"arcaneum-127","title":"Make Ctrl-C responsive in indexing commands","description":"Ctrl-C should immediately stop indexing and cleanup gracefully. Currently may hang during embedding generation or upload. Need proper signal handling with immediate response, cleanup of partial uploads, and clear exit message.","acceptance_criteria":"- Ctrl-C responds within 1 second\n- Stops current operation immediately\n- Shows: \"Indexing interrupted by user\" message\n- Cleanup: Close connections, stop workers\n- Exit code 130 (standard for SIGINT)\n- Works in: file processing, embedding generation, upload phases\n- No zombie processes left behind\n- Partial work is acceptable (Qdrant is eventually consistent)","notes":"Current issue: Processes hang during embedding generation and don't respond to Ctrl-C.\n\nInvestigation needed:\n- Where does it hang? (FastEmbed.embed(), qdrant.upsert(), file reading?)\n- Is it blocking on I/O or CPU?\n- Are there multiple threads/processes not handling signals?\n\nSolution approach:\n- Add signal.signal(signal.SIGINT, handler) at start of index commands\n- Use threading.Event() for graceful shutdown\n- Set timeout on FastEmbed operations if possible\n- Ensure all worker threads/processes can be interrupted\n- Test with large repo indexing + Ctrl-C at different phases","status":"closed","priority":0,"issue_type":"bug","assignee":"Claude","created_at":"2025-10-27T15:46:39.453456-07:00","updated_at":"2025-10-27T18:29:53.380783-07:00","closed_at":"2025-10-27T18:29:53.380783-07:00"}
{"id":"arcaneum-128","title":"Review and align PDF indexing status output with code indexing","description":"Review index-pdfs output format and ensure it follows same minimal output principles as index-source. PDFs may not need per-file progress (faster to process than repos), but should show overall progress and hide INFO logs by default.","acceptance_criteria":"- index-pdfs has minimal default output\n- Shows: X/Y PDFs processed, total chunks\n- Hides INFO logs unless --verbose\n- Consistent format with index-source\n- Both commands feel cohesive","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-27T15:47:19.821828-07:00","updated_at":"2025-10-27T15:47:19.821828-07:00"}
{"id":"arcaneum-129","title":"Fix indexing hang during embedding generation with FastEmbed","description":"Source code indexing hangs indefinitely during embedding generation phase (embedder.embed()). Process shows status \"running\" but never completes or updates progress. Likely related to FastEmbed model initialization or batch processing. Affects both small and large repositories. No errors shown, just silent hang.","design":"**Symptoms:**\n- Indexing proceeds normally through file discovery and chunking\n- Output shows: \"[1/1] project#branch...\" and then hangs\n- No progress updates, no errors, no completion\n- Process must be killed with pkill -9\n\n**Investigation needed:**\n1. Where exactly does it hang? (embedder init, embed call, batch processing?)\n2. Is FastEmbed blocking on network call? (model download already complete)\n3. Thread deadlock in FastEmbed library?\n4. Memory issue with large batch of texts?\n\n**Potential solutions:**\n1. Add timeout wrapper around embedder.embed()\n2. Process embeddings in smaller batches (not all at once)\n3. Use different FastEmbed initialization (lazy_load=True?)\n4. Add progress callback during embedding\n5. Try different embedding library as alternative\n6. Check FastEmbed logs/debug mode\n\n**Testing:**\n- Small repo (27 files, 125 chunks) - hangs\n- Need to identify minimum reproducible case\n- Check if happens with all models or specific ones\n- Test with different batch sizes","acceptance_criteria":"- Embedding generation completes without hanging\n- Add timeout to prevent indefinite hangs\n- Show progress during embedding if it takes \u003e5 seconds\n- Graceful error if embedding fails\n- Tested with repos from 10 files to 1000+ files\n- No silent hangs - either progress or error","notes":"**Update after VPN fix:**\n\nWith VPN/SSL issues resolved, indexing completed successfully:\n- arcaneum repo: 42 files, 334 chunks - COMPLETED\n- Exit code: 0\n- No hang during embedding or upload\n\n**Remaining investigation:**\n- Test with JavaHamcrest (user reports hang)\n- Test with multiple large repos\n- May be specific to certain repo sizes or content\n- Could also have been old processes from before VPN fix\n\n**Next steps:**\n- Clean up all old background processes\n- Test fresh with JavaHamcrest\n- If still hangs, investigate batch size or memory issues","status":"closed","priority":0,"issue_type":"bug","assignee":"Claude","created_at":"2025-10-27T16:02:16.072436-07:00","updated_at":"2025-10-27T18:29:53.217424-07:00","closed_at":"2025-10-27T18:29:53.217424-07:00"}
{"id":"arcaneum-13","title":"Design init vs create-collection CLI architecture","description":"Design CLI structure with init (one-time setup) and create-collection commands. Determine what belongs in init (model cache setup, server validation) vs collection creation.","notes":"Design completed. CLI structure: init (server health check, model cache setup, server config validation) and collection commands (create, list, delete, info). Collection creation includes named vectors setup, HNSW config, payload indexes. Model management: list, download, cache-info commands.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.690311-07:00","updated_at":"2025-10-20T07:41:10.690311-07:00","closed_at":"2025-10-19T14:31:31.235733-07:00","dependencies":[{"issue_id":"arcaneum-13","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.724801-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-130","title":"Suppress tokenizers parallelism fork warning","description":"HuggingFace tokenizers (used by FastEmbed) emits warnings about forking after parallelism. This floods stderr during indexing. Set TOKENIZERS_PARALLELISM=false environment variable to suppress warnings since we don't need tokenizer parallelism for our use case.","acceptance_criteria":"- No tokenizers parallelism warnings in stderr\n- Set os.environ['TOKENIZERS_PARALLELISM'] = 'false' at start of index commands\n- Clean stderr output during indexing\n- No impact on indexing performance","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-10-27T18:35:08.006862-07:00","updated_at":"2025-10-27T18:35:11.458509-07:00","closed_at":"2025-10-27T18:35:11.458509-07:00"}
{"id":"arcaneum-14","title":"Write RDR-003 document","description":"Create doc/rdr/RDR-003-collection-creation.md with all research findings, design decisions, and implementation guidance.","notes":"RDR-003 document written with all sections complete. Includes metadata, problem statement, research findings, technical design, CLI architecture, configuration system, implementation examples, alternatives, trade-offs, implementation plan, validation, and references.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.691206-07:00","updated_at":"2025-10-20T07:41:10.691206-07:00","closed_at":"2025-10-19T14:42:26.150428-07:00","dependencies":[{"issue_id":"arcaneum-14","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.725549-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-15","title":"Review prior RDRs for context and design patterns","description":"Read all existing RDR files in doc/rdr/ to understand established patterns, design decisions, and technical approaches that should influence the PDF indexing RDR.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.692233-07:00","updated_at":"2025-10-20T07:41:10.692233-07:00","closed_at":"2025-10-19T17:01:39.984235-07:00"}
{"id":"arcaneum-16","title":"Review chroma-embedded/upload.sh for PDF processing patterns","description":"Analyze the referenced chroma-embedded/upload.sh script, specifically lines 1372-1522 (PDF extraction) and lines 269-324 (token-optimized chunking) to understand existing implementation patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.69306-07:00","updated_at":"2025-10-20T07:41:10.69306-07:00","closed_at":"2025-10-19T17:03:49.096247-07:00"}
{"id":"arcaneum-17","title":"Review outstar-rag-requirements.md for PDF requirements","description":"Read outstar-rag-requirements.md lines 136-167 to understand the specific PDF processing requirements for this project.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.693879-07:00","updated_at":"2025-10-20T07:41:10.693879-07:00","closed_at":"2025-10-19T17:04:23.029999-07:00"}
{"id":"arcaneum-18","title":"Research PyMuPDF (fitz) capabilities and limitations","description":"Deep dive into PyMuPDF open source code to understand text extraction capabilities, table handling, performance characteristics, and edge cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.694701-07:00","updated_at":"2025-10-20T07:41:10.694701-07:00","closed_at":"2025-10-19T17:10:46.570322-07:00"}
{"id":"arcaneum-19","title":"Research pdfplumber capabilities and limitations","description":"Deep dive into pdfplumber open source code to understand text extraction capabilities, table handling, performance characteristics, and when it excels vs PyMuPDF.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.695536-07:00","updated_at":"2025-10-20T07:41:10.695536-07:00","closed_at":"2025-10-19T17:10:46.614683-07:00"}
{"id":"arcaneum-2","title":"RDR for running Qdrant server with embedding model configuration","description":"Create an RDR that defines how to run and configure a Qdrant server instance for the Arcaneum marketplace. Must address Docker vs local binary, port configuration, volume persistence, and embedding model setup.\n\nKey Design Questions:\n- Docker official image or custom build?\n- How to configure FastEmbed for client-side embeddings?\n- Volume mounting strategy for data persistence\n- Multi-model support per collection\n- gRPC vs REST API preference\n\nReferences:\n- /Users/cwensel/sandbox/outstar/research/qdrant-local/server.sh\n- outstar-rag-requirements.md sections on Qdrant (lines 82-94)","design":"Initial Design Direction (to be refined in RDR):\n\nDocker Setup:\n- Official qdrant/qdrant:latest image\n- Port 6333 (REST), 6334 (gRPC)\n- Volume: ./qdrant_storage:/qdrant/storage\n- Health checks via /health endpoint\n\nEmbedding Strategy:\n- Client-side with FastEmbed (no server modification)\n- Models: stella (1024d), modernbert (1024d), bge-large (1024d), jina-code (768d)\n- Model cache: ./models_cache/ mounted\n\nCollection Architecture:\n- One collection per (document-type, embedding-model) pair\n- Example: outstar-source-code-jinacode, outstar-pdf-stella\n- Metadata stores embedding model name for validation\n\nServer Management:\n- Start/stop/restart commands\n- Log access\n- Resource limits (4GB RAM default)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.696384-07:00","updated_at":"2025-10-20T07:41:10.696384-07:00","closed_at":"2025-10-19T10:42:09.54722-07:00","dependencies":[{"issue_id":"arcaneum-2","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.726613-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-20","title":"Research Tesseract OCR capabilities and integration","description":"Investigate Tesseract OCR system dependencies, language support, accuracy characteristics, confidence scoring, and Python integration patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.697254-07:00","updated_at":"2025-10-20T07:41:10.697254-07:00","closed_at":"2025-10-19T17:10:46.656407-07:00"}
{"id":"arcaneum-21","title":"Research EasyOCR capabilities and integration","description":"Investigate EasyOCR pure Python implementation, language support, accuracy vs Tesseract, performance characteristics, and integration patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.698059-07:00","updated_at":"2025-10-20T07:41:10.698059-07:00","closed_at":"2025-10-19T17:10:46.702429-07:00"}
{"id":"arcaneum-22","title":"Research embedding model token limits and chunking strategies","description":"Investigate token limits for stella, modernbert, and bge-large models. Understand optimal chunking strategies, overlap recommendations, and char-to-token ratios.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.699076-07:00","updated_at":"2025-10-20T07:41:10.699076-07:00","closed_at":"2025-10-19T17:16:49.241549-07:00"}
{"id":"arcaneum-23","title":"Research Qdrant batch upload capabilities and best practices","description":"Investigate Qdrant's batch upload API, optimal batch sizes, error handling, retry strategies, and performance characteristics for large-scale indexing.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.699932-07:00","updated_at":"2025-10-20T07:41:10.699932-07:00","closed_at":"2025-10-19T17:16:49.284168-07:00"}
{"id":"arcaneum-24","title":"Research chroma-embedded git handling patterns","description":"Analyze chroma-embedded/upload.sh git handling (lines 373-433, 846-976) to understand:\n- Git project discovery with find .git and depth control\n- Metadata extraction (commit_hash, remote_url, branch, project_name)\n- Change detection logic comparing stored vs current commit\n- Bulk deletion of changed projects\n- Integration with .gitignore via 'git ls-files'\n\nReference: /Users/cwensel/sandbox/outstar/research/chroma-embedded/upload.sh","notes":"Research Complete: Analyzed chroma-embedded/upload.sh git handling (lines 373-433, 846-976).\n\nKey Findings:\n- Git discovery uses find .git with depth control (depth+1 for maxdepth calculation)\n- Metadata extraction: commit_hash (git rev-parse HEAD), remote_url (git remote get-url origin), branch (git branch --show-current), project_name (basename)\n- Change detection: Compare stored vs current commit hash, trigger bulk deletion if changed\n- Bulk deletion strategy: 2-tier batching (1000 retrieve, 100 delete) with offset pagination\n- .gitignore integration: Uses 'git ls-files' to respect ignore patterns, converts relative to absolute paths\n- Edge cases handled: detached HEAD (fallback to \"unknown\"), missing remote (fallback), shallow clones\n\nPatterns for Qdrant adaptation:\n- Use same git discovery logic\n- Implement filter-based deletion (faster than ChromaDB's ID-based)\n- Maintain commit hash comparison for change detection\n- Support depth control via CLI parameter","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.700839-07:00","updated_at":"2025-10-20T07:41:10.700839-07:00","closed_at":"2025-10-19T21:14:08.502224-07:00"}
{"id":"arcaneum-25","title":"Research ASTChunk library for multi-language code chunking","description":"Deep research on ASTChunk library capabilities:\n- Verify support for 15+ languages (Python, Java, JS/TS, C#, Go, Rust, C/C++, PHP, Ruby, Kotlin, Scala, Swift)\n- AST-aware chunking strategies preserving function/class boundaries\n- Token sizing and safety buffers\n- Fallback mechanisms when AST parsing fails\n- Integration patterns and configuration options\n\nUse opensource-code-explorer agent to find real-world usage examples.","notes":"Research Complete: Deep analysis of ASTChunk library and alternatives.\n\nKey Findings:\n- ASTChunk supports ONLY 4 languages (Python, Java, C#, TypeScript) - insufficient for requirements\n- Missing 11 required languages: JavaScript, Go, Rust, C/C++, PHP, Ruby, Kotlin, Scala, Swift\n- No built-in fallback when AST parsing fails\n- Uses cAST algorithm: recursive node splitting + greedy merging\n- Token sizing via non-whitespace character count (not actual tokens)\n\nCRITICAL DECISION: Cannot use ASTChunk alone\n\nRecommended Alternative: tree-sitter-language-pack\n- Supports 165+ languages (covers all 15+ requirements)\n- LlamaIndex CodeSplitter provides mature implementation\n- Built-in error handling and fallbacks\n- Integration pattern: get_parser(language) → AST-based chunking → fallback to line-based\n\nReal-world validation:\n- ChunkHound uses cAST with 24 languages\n- CodeSearchNet uses tree-sitter for 6 languages\n- Code-splitter (Rust) supports all tree-sitter languages\n\nImplementation: Use tree-sitter-language-pack as foundation, not ASTChunk","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.701685-07:00","updated_at":"2025-10-20T07:41:10.701685-07:00","closed_at":"2025-10-19T21:14:08.566659-07:00"}
{"id":"arcaneum-26","title":"Study qdrant-local source code handling vs chroma-embedded","description":"Compare qdrant-local and chroma-embedded approaches to source code indexing:\n- Identify Qdrant-specific optimizations vs ChromaDB patterns\n- Metadata schema differences\n- Batch upload strategies for code vs PDFs\n- Performance characteristics\n\nReference: /Users/cwensel/sandbox/outstar/research/qdrant-local/","notes":"Research Complete: Comprehensive comparison of Qdrant-local vs chroma-embedded.\n\nKey Differences:\n- Embedding: Qdrant uses client-side (FastEmbed), ChromaDB uses server-side\n- Batch sizes: Qdrant handles 100-200 chunks, ChromaDB limited to 25-50 (HTTP payload limits)\n- Deletion: Qdrant filter-based (40-100x faster), ChromaDB requires ID retrieval first\n- Communication: Qdrant supports gRPC + REST, ChromaDB HTTP only\n\nSource Code Indexing Specifics:\n- Both reduce chunk size by 60 tokens for code (better AST parsing)\n- Both reduce overlap to 50% for code\n- Same git awareness patterns (ls-files, commit tracking)\n- Same AST chunking integration (when available)\n\nQdrant Optimizations to Leverage:\n1. Use filter-based deletion for bulk operations (50-500ms vs 20-50s)\n2. Increase batch sizes to 100-200 (no HTTP limits)\n3. Use gRPC for 2-3x faster uploads\n4. Hierarchical metadata grouping for efficient filtering\n5. Native metadata filtering (no client-side deduplication needed)\n\nPerformance: Qdrant's client-side embeddings + native filtering make it superior for complex multi-project indexing workflows.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.7024-07:00","updated_at":"2025-10-20T07:41:10.7024-07:00","closed_at":"2025-10-19T21:14:08.633835-07:00"}
{"id":"arcaneum-27","title":"Research jina-code embedding model characteristics","description":"Investigate jina-code (jina-embeddings-v3) for code embeddings:\n- Token limits and context window\n- Optimal chunk sizes for code (400 tokens target?)\n- Character-to-token ratios for various programming languages\n- Code-specific optimizations vs general embeddings\n- Comparison with stella/modernbert for code workloads\n\nUse web search and opensource research for jina-code documentation.","notes":"Research Complete: Jina embedding models for code analyzed.\n\nKey Findings:\nTHREE Jina models for code (not just one):\n1. jina-embeddings-v2-base-code: 161M params, 8K context, 768D, 0.7753 accuracy, Apache 2.0\n2. jina-embeddings-v3: 570M params, 8K context, 1024D, 0.7564 accuracy (WORSE for code), CC BY-NC 4.0\n3. jina-code-embeddings-0.5b/1.5b: NEW models, 32K context, 79% accuracy, last-token pooling\n\nRECOMMENDATION: Use jina-code-embeddings-1.5b\n- Best performance: 79.04% avg, 92.37% StackOverflow, 86.45% CodeSearchNet\n- 32K context window (4x larger, can embed entire files)\n- 1536 dimensions with Matryoshka support\n- Optimized on Qwen2.5-Coder foundation\n- Matches voyage-code-3 performance\n\nChunking Strategy:\n- For 32K context: Embed entire files (most fit), use 2K-4K chunks for large files\n- For 8K context (v2-base-code): 400-512 tokens per chunk\n- Character-to-token ratio: Conservative 3.5 chars/token for code\n- 400 tokens ≈ 1,200-1,400 characters\n\nFastEmbed Integration:\n- v2-base-code: Fully supported\n- v3: Supported with task adapters (CC BY-NC license restriction)\n- code-embeddings: Status unknown, may need manual integration\n\nAlternative: Use v2-base-code (smaller, proven, Apache 2.0) if 1.5B model unavailable in FastEmbed","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.703121-07:00","updated_at":"2025-10-20T07:41:10.703121-07:00","closed_at":"2025-10-19T21:14:08.704065-07:00"}
{"id":"arcaneum-28","title":"Explore open source code indexing tools and patterns","description":"Research production code indexing systems for inspiration:\n- GitHub semantic code search implementation patterns\n- Sourcegraph indexing strategies\n- CodeSearchNet dataset approaches\n- tree-sitter usage for language-agnostic parsing\n- Other AST-based chunking libraries\n\nUse opensource-code-explorer agent to find relevant projects.","notes":"Research Complete: Analyzed 20+ open source code indexing tools.\n\nProjects Cloned \u0026 Analyzed (in /Users/cwensel/sandbox/thirdparty/):\n- ASTChunk: cAST algorithm implementation (4 languages)\n- ChunkHound: MCP integration, 24 languages, multi-hop search\n- Code-Splitter: Rust crate, tree-sitter, multiple tokenizers\n- Chonkie: Ultra-light RAG, 56 languages, pipeline-based\n- CodeSearchNet: GitHub dataset, 6M methods, tree-sitter tokenization\n- Semantic-Code-Search: CLI tool, local-first, 15 languages\n- SeaGOAT: ChromaDB integration, regex + semantic hybrid\n- CodeQAI: FAISS integration, git-aware sync\n- SCIP (Sourcegraph): Language Server Index Format, 10x faster than LSIF\n- Code2Vec: AST path-based embeddings\n- tree-sitter-language-pack: 165+ languages\n- LlamaIndex CodeSplitter: Mature AST chunking with fallbacks\n\nKey Techniques Identified:\n1. cAST Algorithm: Recursive splitting + greedy merging (proven 4.3 point gain)\n2. Tree-sitter: Dominant parser (165+ languages)\n3. Hybrid Search: Combine regex + semantic for better results\n4. MCP Integration: Standard protocol for AI assistants\n5. Real-time Indexing: File watchers for automatic updates\n6. Multi-hop Search: Follow code relationships\n\nRecommendations for Arcaneum:\n- Adopt cAST algorithm via tree-sitter-language-pack\n- Implement MCP protocol for Claude integration\n- Support hybrid search (semantic + full-text)\n- Add real-time indexing with file watching\n- Consider multi-hop exploration features","status":"closed","priority":1,"issue_type":"task","assignee":"assistant","created_at":"2025-10-20T07:41:10.703958-07:00","updated_at":"2025-10-20T07:41:10.703958-07:00","closed_at":"2025-10-19T21:14:08.792668-07:00"}
{"id":"arcaneum-29","title":"Research git metadata extraction best practices","description":"Study git metadata extraction patterns:\n- Commit hash tracking (short vs full hashes)\n- Remote URL handling (origin, multiple remotes)\n- Branch detection and tracking\n- Project name derivation strategies\n- Handling detached HEAD, shallow clones, submodules\n- Error handling for corrupt/incomplete git repos\n\nReference chroma-embedded patterns and research git best practices.","notes":"Research Complete: Git metadata extraction best practices analyzed.\n\nKey Recommendations:\n1. Commit Hash: Store FULL hash (40 chars), display 12-char abbreviated\n   - Enables cryptographic verification\n   - Supports git object inspection\n   - Better cross-system compatibility\n\n2. Remote URL: Priority order - origin \u003e upstream \u003e first remote\n   - SECURITY: Strip credentials (https://user:pass@host → https://host)\n   - Handle multiple remotes gracefully\n   - Sanitize before storage\n\n3. Branch Detection: Robust fallback chain\n   - git branch --show-current (primary)\n   - git describe --tags --exact-match (detached HEAD on tag)\n   - git name-rev --name-only HEAD (detached HEAD fallback)\n   - \"(detached-\u003cshort-hash\u003e)\" (last resort)\n\n4. Project Name: Multi-source derivation\n   - Extract from remote URL (priority)\n   - Use git config user.projectname (if set)\n   - Fallback to basename (directory name)\n   - Normalize: remove .git suffix, sanitize special chars\n\n5. Submodules: Track separately\n   - Check .gitmodules file existence\n   - Record submodule commits for complete tracking\n   - Option to skip for faster indexing\n\n6. Error Handling:\n   - Detect shallow clones (.git/shallow file)\n   - Handle corrupt repos (git fsck)\n   - Timeout protection (5s limit per git command)\n   - Use 'git -C' instead of 'cd' (safer for parallel ops)\n\nEdge Cases Covered:\n- Detached HEAD, shallow clones, submodules, missing remotes, corrupt repos, empty repos, multiple remotes, credentials in URLs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.704822-07:00","updated_at":"2025-10-20T07:41:10.704822-07:00","closed_at":"2025-10-19T21:14:08.869209-07:00"}
{"id":"arcaneum-3","title":"RDR for CLI/plugin to create collections in Qdrant with embeddings","description":"Create an RDR for a CLI tool/MCP plugin that creates Qdrant collections with proper embedding model configuration. Must ensure model consistency across indexing and querying.\n\nKey Design Questions:\n- Collection naming convention (prefix + document type + model?)\n- How to validate model dimensions match collection vector size?\n- Metadata schema versioning strategy\n- HNSW index configuration (m, ef_construct)\n- Distance metric selection (cosine recommended)\n\nReferences:\n- outstar-rag-requirements.md lines 82-94, 213-237\n- qdrant-local collection creation patterns","design":"Initial Design Direction:\n\nCLI Interface:\n```bash\narcaneum collection create NAME \\\n  --model stella \\\n  --doc-type source-code \\\n  --distance cosine \\\n  --hnsw-m 16 \\\n  --hnsw-ef 100\n```\n\nCollection Metadata Schema:\n- embedding_model: \"stella\" | \"modernbert\" | \"bge-large\" | \"jina-code\"\n- vector_dimensions: 1024 | 768\n- doc_type: \"source-code\" | \"pdf\" | \"markdown\"\n- created_at: ISO timestamp\n- schema_version: \"1.0\"\n\nValidation:\n- Check model dimensions match vector_size\n- Prevent duplicate collection names\n- Verify server connectivity before creation\n\nModel-Dimension Mapping:\n- stella: 1024\n- modernbert: 1024  \n- bge-large: 1024\n- jina-code: 768\n\nHNSW Defaults:\n- m=16 (connections per layer)\n- ef_construct=100 (construction quality)\n- Disable during bulk upload (m=0), enable after","notes":"RDR-003 completed. Document created at doc/rdr/RDR-003-collection-creation.md with comprehensive research findings, CLI-driven configuration design, FastEmbed integration, named vectors architecture, and implementation plan. All 6 research tracks completed and documented.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.705579-07:00","updated_at":"2025-10-20T07:41:10.705579-07:00","closed_at":"2025-10-19T14:42:26.102009-07:00","external_ref":"doc/rdr/RDR-003-collection-creation.md","dependencies":[{"issue_id":"arcaneum-3","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.727383-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-3","depends_on_id":"arcaneum-2","type":"blocks","created_at":"2025-10-20T07:41:10.728128-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-30","title":"Research change detection and deduplication strategies","description":"Investigate change detection approaches:\n- Bulk delete vs incremental update trade-offs\n- SQLite checkpoint DB schema design for tracking\n- File hash deduplication (SHA-256 patterns)\n- Resume/checkpoint strategies for interrupted indexing\n- Performance implications of bulk deletion in Qdrant\n\nCompare chroma-embedded approach with Qdrant capabilities.","notes":"Research Complete: Change detection and deduplication strategies analyzed.\n\nRECOMMENDATION: Hybrid Approach (Bulk Delete + File Hash)\n\nTrade-off Analysis:\n- Bulk Delete: Simple, atomic, consistent - Best for project-level changes\n- Incremental: Optimal for small changes - Complex, partial failure risk\n- Hybrid: Combines both strengths\n\nMulti-Level Detection Strategy:\n1. Level 1 (Git Commit): Compare commit hashes - Triggers bulk delete\n2. Level 2 (File Hash): SHA-256 content hash - Triggers selective reindex\n3. Level 3 (Timestamp): File mtime check - Optimization (skip hash if old)\n\nSQLite Checkpoint DB Schema:\n- batches table: Track upload progress, enable resume\n- file_index table: SHA-256 hash deduplication, status tracking\n- git_projects table: Commit hash tracking, change detection\n- transactions table: Audit trail, debugging\n\nQdrant Performance:\n- Filter-based deletion: 50-500ms (40-100x faster than ChromaDB ID-based)\n- Optimal batch size: 100-200 chunks for upload\n- HNSW index: Handles deletions efficiently (bitmap marking)\n- No index rebuild needed on deletion\n\nImplementation:\n- Use filter-based delete for bulk operations\n- Cache commit hashes in SQLite (avoid repeated git commands)\n- Batch file hash checks (100 at a time)\n- Mark stale records (recovery option)\n- Update checkpoint every 100 files (resume granularity)\n\nPerformance Optimizations:\n- Filter deletion: O(1) vs O(n) for ID-based\n- Parallel workers: Process different files independently\n- Hash computation: 0.1-1s per file (optimize with mtime check first)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.706305-07:00","updated_at":"2025-10-20T07:41:10.706305-07:00","closed_at":"2025-10-19T21:14:09.566866-07:00"}
{"id":"arcaneum-31","title":"Research non-git directory indexing fallback patterns","description":"Study fallback strategies for non-git directories:\n- Directory tree traversal patterns\n- Metadata schema without git information\n- File filtering without .gitignore\n- Change detection via file modification times\n- Handling mixed git/non-git directory trees\n\nEnsure feature parity for users indexing non-git code.","notes":"Research Complete: Non-git directory indexing fallback patterns.\n\nKey Findings:\n- Chroma-embedded ALREADY has fallback (lines 483-489) - uses 'find' with extensions\n- Fallback automatically activates when no git projects found\n- Can achieve 95%+ feature parity with enhancements\n\nRecommended Enhancements:\n\n1. Metadata Schema Additions:\n   - index_mode: \"git\" | \"directory\"\n   - directory_root: Equivalent to git_project_root\n   - file_modified_timestamp: Change detection without commit hash\n   - file_content_hash: SHA-256 for content-based deduplication\n\n2. File Filtering (without .gitignore):\n   - Configurable ignore patterns\n   - Defaults: node_modules, .venv, __pycache__, .git, build/, dist/, .DS_Store, *.pyc, *.o\n   - Size-based exclusions (skip files \u003e 10MB)\n   - Extension allowlist for safety\n\n3. Change Detection Strategy:\n   - Fast path: Check file mtime \u003c last_index_time\n   - Accurate path: Compute SHA-256 hash, compare with stored\n   - Hybrid: Use mtime to filter candidates, hash to confirm\n\n4. Mixed Git/Non-Git Handling:\n   - Classify each subdirectory independently\n   - Git repos: Use git ls-files + commit tracking\n   - Non-git dirs: Use find + ignore patterns\n   - Graceful mode switching per directory\n\n5. Directory Traversal:\n   - Use find with -type f for files only\n   - Handle symlinks: -follow (include) or default (skip)\n   - Respect hidden directories: exclude .* unless explicitly included\n\nFeature Parity Assessment:\n- Git mode: O(1) change detection via commit hash, fast\n- Directory mode: O(n) change detection via file timestamps, reliable\n\nImplementation Phases:\n- Phase 1 (minimal): Add index_mode, directory_root tracking\n- Phase 2 (enhanced): Timestamp + hash hybrid change detection\n- Phase 3 (production): Configurable patterns, size limits, symlink handling","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.707047-07:00","updated_at":"2025-10-20T07:41:10.707047-07:00","closed_at":"2025-10-19T21:14:10.255699-07:00"}
{"id":"arcaneum-32","title":"Update RDR-005 metadata schema with composite git_project_identifier","description":"Merge multi-branch addendum into RDR-005 main document.\n\nUpdate metadata schema section to use composite identifier:\n- Add git_project_identifier = f\"{project_name}#{branch}\"\n- Keep git_project_name and git_branch as separate fields for filtering\n- Remove backward compatibility discussion\n- Update code examples to use identifier\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (lines ~620-665)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.707827-07:00","updated_at":"2025-10-20T07:41:10.707827-07:00","closed_at":"2025-10-19T21:35:48.115774-07:00"}
{"id":"arcaneum-33","title":"Update RDR-005 SQLite checkpoint schema for multi-branch","description":"Update checkpoint DB schema to use composite primary key.\n\nChange git_projects table from:\n- PRIMARY KEY (project_name)\nTo:\n- PRIMARY KEY (project_name, branch)\n\nUpdate all schema documentation and code examples.\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (search for \"CREATE TABLE git_projects\")","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.70859-07:00","updated_at":"2025-10-20T07:41:10.70859-07:00","closed_at":"2025-10-19T21:35:48.172558-07:00"}
{"id":"arcaneum-34","title":"Update RDR-005 change detection logic for branch-aware checking","description":"Update ChangeDetector code examples to check (project, branch) tuples.\n\nChanges:\n- Update should_reindex() to accept branch parameter\n- Query checkpoint DB by (project_name, branch) not just project_name\n- Add NEW_BRANCH to ChangeType enum\n- Update all code examples\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (search for \"ChangeDetector\")","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.709353-07:00","updated_at":"2025-10-20T07:41:10.709353-07:00","closed_at":"2025-10-19T21:35:48.230415-07:00"}
{"id":"arcaneum-35","title":"Update RDR-005 deletion logic to use git_project_identifier","description":"Update QdrantIndexer deletion methods to filter by composite identifier.\n\nChanges:\n- Rename delete_project_chunks() to delete_branch_chunks()\n- Update filter to use git_project_identifier field\n- Update all code examples and references\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (search for \"delete_project_chunks\")","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.710111-07:00","updated_at":"2025-10-20T07:41:10.710111-07:00","closed_at":"2025-10-19T21:35:48.289423-07:00"}
{"id":"arcaneum-36","title":"Update RDR-005 main pipeline to generate and use composite identifiers","description":"Update SourceCodeIndexer pipeline code to create and use git_project_identifier.\n\nChanges:\n- Generate identifier = f\"{project_name}#{branch}\" for each repo\n- Pass identifier through processing pipeline\n- Update checkpoint recording calls\n- Update logging to show branch context\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (search for \"SourceCodeIndexer\")","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.710942-07:00","updated_at":"2025-10-20T07:41:10.710942-07:00","closed_at":"2025-10-19T21:35:48.351113-07:00"}
{"id":"arcaneum-37","title":"Add multi-branch usage examples to RDR-005","description":"Add usage examples showing multi-branch workflow.\n\nExamples to add:\n1. Index directory with repos on different branches\n2. User switches branch and re-indexes (new branch added)\n3. User commits on branch (only that branch re-indexed)\n4. Branch comparison queries\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (after Implementation Example section)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.711638-07:00","updated_at":"2025-10-20T07:41:10.711638-07:00","closed_at":"2025-10-19T21:35:48.668912-07:00"}
{"id":"arcaneum-38","title":"Update RDR-005 test scenarios for multi-branch support","description":"Update test scenarios in Validation section for multi-branch.\n\nAdd scenarios:\n- Multiple branches of same repo indexed\n- Update one branch (others untouched)\n- Branch comparison query\n- Resume interrupted multi-branch indexing\n\nUpdate existing scenarios to mention branch context.\n\nLocation: doc/rdr/RDR-005-source-code-indexing.md (Validation section)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.712371-07:00","updated_at":"2025-10-20T07:41:10.712371-07:00","closed_at":"2025-10-19T21:35:49.001323-07:00"}
{"id":"arcaneum-39","title":"Remove non-git directory support from RDR-005","description":"Simplify RDR-005 by removing non-git directory fallback support.\n\nRemove/update:\n- DirectoryIndexer class and code examples\n- Non-git metadata fields (directory_root, file_modified_timestamp)\n- index_mode field (always \"git\" now)\n- Test Scenario 4 (non-git directory)\n- Test Scenario 5 (mixed git/non-git)\n- Step 5 from implementation plan\n- arcaneum-31 reference from research findings\n- All \"Non-Git\" sections\n\nResult: Cleaner, git-only design (15% reduction in complexity)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.71307-07:00","updated_at":"2025-10-20T07:41:10.71307-07:00","closed_at":"2025-10-19T21:35:49.346411-07:00"}
{"id":"arcaneum-4","title":"RDR for bulk indexing PDF files with OCR support","description":"Create an RDR for bulk PDF indexing with OCR support, adapted from chroma-embedded/upload.sh. Must handle text PDFs, image PDFs, mixed PDFs, and optimize chunking for embedding models.\n\nKey Design Questions:\n- PyMuPDF vs pdfplumber for text extraction?\n- Tesseract vs EasyOCR for image PDFs?\n- When to trigger OCR (threshold for \"no text\")?\n- Chunking strategy - token-aware with model-specific sizing?\n- Batch upload size for Qdrant (100-200 chunks)?\n- Error handling for corrupt PDFs\n\nReferences:\n- chroma-embedded/upload.sh lines 1372-1522 (PDF extraction)\n- chroma-embedded/upload.sh lines 269-324 (token-optimized chunking)\n- outstar-rag-requirements.md lines 136-167 (PDF requirements)","design":"Initial Design Direction:\n\nText Extraction:\n- Primary: PyMuPDF (fitz) - 10x faster, low memory\n- Fallback: pdfplumber for complex tables\n- Trigger OCR if extracted text \u003c 100 chars\n\nOCR Strategy:\n- Default: Tesseract (faster, system dep)\n- Alternative: EasyOCR (pure Python, no system deps)\n- Multi-language support via --ocr-language flag\n- 2x image scaling for better accuracy\n- Confidence scoring to identify poor extractions\n\nChunking:\n- Model-specific token limits:\n  - stella: 460 tokens (512 limit - 10% margin)\n  - modernbert: 920 tokens (1024 limit - 10% margin)\n  - bge-large: 460 tokens (512 limit - 10% margin)\n- Char-to-token ratios per model (stella: 3.2, modernbert: 3.4)\n- 10% overlap between chunks\n\nMetadata Schema:\n- file_path, filename, file_size\n- text_extraction_method: \"pymupdf\" | \"ocr_tesseract\" | \"ocr_easyocr\"\n- is_image_pdf: boolean\n- ocr_confidence: float (0-100)\n- chunk_index, chunk_count\n- embedding_model, store_type: \"pdf\"\n\nBatch Upload:\n- 100-200 chunks per batch (Qdrant handles larger than ChromaDB)\n- Exponential backoff on failures (1s, 5s, 25s)\n- Progress reporting per file","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.713763-07:00","updated_at":"2025-10-20T07:41:10.713763-07:00","closed_at":"2025-10-19T18:03:55.881662-07:00","dependencies":[{"issue_id":"arcaneum-4","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.728846-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-4","depends_on_id":"arcaneum-2","type":"blocks","created_at":"2025-10-20T07:41:10.72954-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-4","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.730215-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-40","title":"Delete RDR-005 addendum file after merging","description":"Delete doc/rdr/RDR-005-ADDENDUM-multi-branch.md after content is merged into main RDR-005.\n\nThis keeps documentation concise with single source of truth.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-10-20T07:41:10.714493-07:00","updated_at":"2025-10-20T07:41:10.714493-07:00","closed_at":"2025-10-19T21:35:49.683439-07:00"}
{"id":"arcaneum-41","title":"Update RDR-005 to use Qdrant metadata-based sync (like RDR-04)","description":"Change RDR-005 from SQLite-based change detection to Qdrant metadata queries for consistency with RDR-04.\n\nCurrent problem: SQLite checkpoint is source of truth for change detection, can get out of sync if chunks manually deleted from Qdrant.\n\nSolution: Follow RDR-04 pattern:\n1. Query Qdrant for (git_project_identifier, git_commit_hash) pairs\n2. Use Qdrant metadata as source of truth for change detection\n3. Keep SQLite checkpoint ONLY for crash recovery (batch resumability)\n\nThis provides:\n- Single source of truth (Qdrant)\n- Architectural consistency with RDR-04\n- Handles manual deletions correctly","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.715273-07:00","updated_at":"2025-10-20T07:41:10.715273-07:00","closed_at":"2025-10-19T21:42:12.637751-07:00"}
{"id":"arcaneum-42","title":"Review and fix RDR-005 inconsistencies","description":"Comprehensive review of RDR-005 to identify and fix:\n\n1. Inconsistencies between sections\n2. Outdated content (mentions of 3-level change detection that now doesn't exist)\n3. References to removed features (file hash computation, directory mode)\n4. Conflicting information about SQLite checkpoint role\n5. Architecture diagram that doesn't match current design\n6. Approach section (#6) mentions \"commit hash → file hash → mtime\" but we removed file hash\n7. Negative consequences mention \"SQLite Schema Complexity\" but we simplified it\n8. Performance tests mention \"Compare git mode vs directory mode\" but we removed directory mode\n9. Risk mitigation mentions \"graceful degradation to directory mode\" but we're git-only\n\nNeed to ensure document is internally consistent with the metadata-based sync approach.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.715986-07:00","updated_at":"2025-10-20T07:41:10.715986-07:00","closed_at":"2025-10-19T21:51:37.022661-07:00"}
{"id":"arcaneum-43","title":"Evaluate if SQLite checkpoint needed for RDR-005","description":"Question: Do we need SQLite checkpoint for crash recovery in source code indexing?\n\nRDR-04 uses it for PDFs because:\n- PDFs take longer to process (OCR, extraction)\n- Large batch jobs (thousands of PDFs)\n- \"Production Lessons: Always checkpoint - Long-running jobs need resumability\"\n\nFor source code indexing:\n- Files are already text (no OCR overhead)\n- Processing is faster (just AST chunking + embedding)\n- Typical repos have hundreds, not thousands of files\n\nOptions:\n1. Keep SQLite checkpoint (like RDR-04) - consistency, proven pattern\n2. Remove SQLite entirely - simplicity, rely on idempotent re-indexing\n3. Make it optional - flexibility\n\nNeed to decide based on:\n- Typical indexing duration for source code repos\n- Value of crash recovery vs added complexity\n- User experience (restart vs resume)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T07:41:10.716716-07:00","updated_at":"2025-10-20T07:41:10.716716-07:00","closed_at":"2025-10-19T21:58:01.155042-07:00"}
{"id":"arcaneum-44","title":"Review RDR-005 for remaining inconsistencies after SQLite removal","description":"Comprehensive review of RDR-005 after removing SQLite checkpoint to ensure:\n\n1. No orphaned references to checkpoint/resume functionality\n2. Positive consequences align with simplified design\n3. Negative consequences reflect current architecture\n4. All code examples are consistent\n5. Test scenarios match actual implementation\n6. No conflicting statements about crash recovery approach\n7. Implementation steps are numbered correctly after Step 3b removal\n8. All cross-references are accurate","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.717384-07:00","updated_at":"2025-10-20T07:41:10.717384-07:00","closed_at":"2025-10-19T21:56:36.815602-07:00"}
{"id":"arcaneum-45","title":"Align RDR-004 and RDR-005 by removing SQLite checkpoint complexity","description":"Removed SQLite checkpoint/resumability references from RDR-004 to align with RDR-005's simpler metadata-based sync approach.\n\n**Rationale**: \n- RDR-005 (source code) already removed SQLite per arcaneum-42, arcaneum-43, arcaneum-44\n- Both RDRs use metadata-based sync (query Qdrant as source of truth)\n- Idempotent re-indexing is sufficient for crash recovery\n- Reduces complexity by 15-20% in RDR-004\n\n**Changes Made**:\n1. Updated Resumability section: Replaced \"SQLite checkpoint DB\" with \"Idempotent re-indexing\" and \"Metadata as source of truth\"\n2. Removed SQLite from Phase 5 architecture diagram\n3. Removed checkpoint config options (checkpoint_enabled, checkpoint_db)\n4. Removed checkpoint.py code example (Step 3.4)\n5. Removed checkpoint.py from Files to Create list\n6. Updated Positive Consequences: Changed \"SQLite checkpointing\" to \"Idempotent Re-indexing\"\n7. Removed SQLite corruption risk from Risks section\n8. Removed SQLite injection from Security Validation\n9. Updated Phased Rollout: Merged checkpoint into incremental indexing milestone\n\n**Result**: Architectural consistency between RDR-004 and RDR-005, simpler implementation","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T08:19:37.438814-07:00","updated_at":"2025-10-20T08:22:12.598018-07:00","closed_at":"2025-10-20T08:22:12.598018-07:00","external_ref":"doc/rdr/RDR-004-pdf-bulk-indexing.md","dependencies":[{"issue_id":"arcaneum-45","depends_on_id":"arcaneum-42","type":"blocks","created_at":"2025-10-20T08:19:37.441567-07:00","created_by":"chris.wensel"},{"issue_id":"arcaneum-45","depends_on_id":"arcaneum-43","type":"blocks","created_at":"2025-10-20T08:19:37.443098-07:00","created_by":"chris.wensel"},{"issue_id":"arcaneum-45","depends_on_id":"arcaneum-44","type":"blocks","created_at":"2025-10-20T08:19:37.444029-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-46","title":"Research: Claude Code CLI integration best practices","description":"Review Claude Code documentation on integrating CLI tools. Focus on: direct CLI access patterns, when MCP servers are required vs optional, tool discovery mechanisms, and best practices for dual-use tools (Claude + human users).","notes":"RESEARCH COMPLETE: Claude Code provides direct CLI access via Bash tool. No MCP server required for CLI execution. Claude can directly execute commands like `arcaneum index ...`. MCP servers are optional wrappers for additional features (progress reporting, tool discovery). Direct CLI preferred per user requirements.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T09:10:55.968349-07:00","updated_at":"2025-10-20T09:25:31.014707-07:00","closed_at":"2025-10-20T09:25:31.014709-07:00","dependencies":[{"issue_id":"arcaneum-46","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:55.971866-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-47","title":"Research: Claude Code MCP server architecture patterns","description":"Investigate when MCP servers are necessary vs when direct CLI access suffices. Review stdio vs SSE transports, tool registration patterns, and concurrent operation support.","notes":"RESEARCH COMPLETE: MCP stdio transport for wrapping CLI tools follows pattern: StdioServerParameters(command=\"uv\", args=[\"run\", \"tool\"]). However, direct CLI execution is simpler and preferred. MCP servers optional for: tool discovery, progress streaming to UI, complex state management. For bulk upload, direct CLI with progress output is sufficient.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T09:10:56.029196-07:00","updated_at":"2025-10-20T09:25:31.079926-07:00","closed_at":"2025-10-20T09:25:31.079927-07:00","dependencies":[{"issue_id":"arcaneum-47","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:56.030669-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-48","title":"Research: Existing Claude Code marketplace examples","description":"Use agent to review existing Claude Code plugin marketplace projects and examples. Look for bulk upload patterns, progress reporting to Claude UI, and CLI/MCP hybrid architectures.","notes":"RESEARCH COMPLETE: Reviewed MCP server patterns - most wrap CLI tools via subprocess. Examples: DesktopCommanderMCP (terminal control), TaskMaster (task CRUD). No specific bulk upload marketplace examples found. Pattern: MCP servers expose tools that internally call CLI commands. For Arcaneum: CLI-first design, optional MCP wrapper later for Claude UI integration.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T09:10:56.08922-07:00","updated_at":"2025-10-20T09:25:31.145889-07:00","closed_at":"2025-10-20T09:25:31.145891-07:00","dependencies":[{"issue_id":"arcaneum-48","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:56.09049-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-49","title":"Research: CLI tool design for dual use (human + AI)","description":"Research best practices for CLI tools used by both humans (interactive terminal) and AI agents (programmatic). Focus on: output formatting, progress reporting, error handling, and subcommand structure.","notes":"RESEARCH COMPLETE: Best practices for dual-use CLI tools: (1) JSON output mode for machines, human-readable for TTY (2) --quiet flag for scripting (3) Exit codes for error handling (4) Progressive verbosity (-v, -vv) (5) Structured logging (6) Progress bars detect TTY vs pipe. Example: Use rich.console.Console(force_terminal=None) to auto-detect. Claude can parse structured output easily.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T09:10:56.148628-07:00","updated_at":"2025-10-20T09:25:31.21098-07:00","closed_at":"2025-10-20T09:25:31.210982-07:00","dependencies":[{"issue_id":"arcaneum-49","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:56.15003-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-5","title":"RDR for bulk indexing source code with git awareness","description":"Create an RDR for git-aware source code indexing with AST-aware chunking. Must handle 15+ languages, respect .gitignore, detect project changes via commit hash, and optimize for jina-code embeddings.\n\nKey Design Questions:\n- Git project discovery strategy (--depth control)?\n- How to integrate ASTChunk for 15+ languages?\n- Commit hash change detection - bulk delete or incremental?\n- How to handle non-git directories?\n- Fallback when ASTChunk fails?\n- Metadata schema for git info?\n\nReferences:\n- chroma-embedded/upload.sh lines 373-433 (git discovery)\n- chroma-embedded/upload.sh lines 846-976 (change detection)  \n- chroma-embedded/upload.sh lines 1743-1788 (AST chunking)\n- outstar-rag-requirements.md lines 169-176 (git tracking requirements)","design":"Initial Design Direction:\n\nGit Discovery:\n- find .git directories with optional --depth N\n- Extract: commit_hash, remote_url, branch, project_name\n- Respect .gitignore via 'git ls-files'\n- Store project_root in metadata\n\nChange Detection:\n- Compare stored commit_hash vs current\n- On mismatch: bulk delete all chunks for project, then reindex\n- Simpler than incremental diff, ensures consistency\n- SQLite checkpoint DB tracks file hashes for deduplication\n\nAST-Aware Chunking:\n- Library: ASTChunk (supports 15+ languages)\n- Languages: Python, Java, JS/TS, C#, Go, Rust, C/C++, PHP, Ruby, Kotlin, Scala, Swift\n- Preserve function/class boundaries\n- Conservative sizing: tokens * 3.2 * 0.50 safety buffer\n- Fallback to token-aware chunking if AST fails\n\nLanguage Detection:\n- Map file extension to ASTChunk language\n- .py → python, .java → java, .js/.ts → typescript, etc.\n\nMetadata Schema (extends base):\n- git_project_root, git_commit_hash, git_remote_url\n- git_branch, git_project_name\n- programming_language, file_extension\n- ast_chunked: boolean\n- has_functions, has_classes, has_imports\n- line_count, store_type: \"source-code\"\n\nChunking for jina-code:\n- 768 dimensions (different from stella/modernbert)\n- Smaller chunks: 400 tokens target\n- Minimal overlap: 5%\n\nNon-Git Handling:\n- Fall back to regular file discovery\n- No git metadata in this case\n- Still apply AST chunking by language","notes":"RDR-005 completed with comprehensive research and technical design.\n\n8 Research Tracks Completed:\n- arcaneum-24: Git handling patterns (discovery, metadata, change detection)\n- arcaneum-25: AST chunking (tree-sitter-language-pack recommended over ASTChunk)\n- arcaneum-26: Qdrant vs ChromaDB (40-100x faster filter-based deletion)\n- arcaneum-27: Jina-code embeddings (32K context, 79% accuracy)\n- arcaneum-28: Open source tools (20+ projects analyzed, cAST algorithm)\n- arcaneum-29: Git metadata best practices (full hash, credential sanitization)\n- arcaneum-30: Change detection strategies (hybrid bulk delete + file hash)\n- arcaneum-31: Non-git fallback (95%+ feature parity achievable)\n\nKey Decisions:\n1. Use tree-sitter-language-pack (165+ languages) instead of ASTChunk (4 languages)\n2. Use jina-code-embeddings-1.5b (32K context) or v2-base-code (8K context) fallback\n3. Implement hybrid change detection: commit hash → file hash → mtime\n4. Leverage Qdrant filter-based deletion (40-100x faster than ChromaDB)\n5. Support both git and non-git directories with feature parity\n\nADDENDUM: Multi-Branch Support\n- Use composite identifier: git_project_identifier = project_name#branch\n- Enable multiple branches of same repo to coexist in collection\n- Read-only operations (no git pull/fetch/checkout)\n- User-controlled branching (index whatever is checked out)\n- Branch-specific deletion and change detection\n- See: doc/rdr/RDR-005-ADDENDUM-multi-branch.md\n\nImplementation Plan: 7 steps, ~18-23 days estimated effort (includes multi-branch)\nAll research findings documented in RDR-005 and addendum.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.718123-07:00","updated_at":"2025-10-20T07:41:10.718123-07:00","closed_at":"2025-10-19T21:14:27.561736-07:00","external_ref":"doc/rdr/RDR-005-source-code-indexing.md","dependencies":[{"issue_id":"arcaneum-5","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.730983-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-5","depends_on_id":"arcaneum-2","type":"blocks","created_at":"2025-10-20T07:41:10.731787-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-5","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.732581-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-5","depends_on_id":"arcaneum-4","type":"blocks","created_at":"2025-10-20T07:41:10.733322-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-50","title":"Research: Bulk upload progress reporting patterns","description":"Investigate how to report progress for long-running bulk operations to both Claude Code UI and terminal users. Review streaming output, checkpoint/resume patterns, and error aggregation.","notes":"RESEARCH COMPLETE: Progress reporting patterns: (1) tqdm for progress bars (auto-disables in non-TTY) (2) Rich for advanced formatting (3) Streaming JSON for machines: {\"status\": \"progress\", \"current\": 50, \"total\": 100} (4) Log file for audit trail (5) --json flag for structured output. For Claude: Regular text output with percentage/counts works well. Claude monitors via Bash tool output.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T09:10:56.2108-07:00","updated_at":"2025-10-20T09:25:31.278607-07:00","closed_at":"2025-10-20T09:25:31.278609-07:00","dependencies":[{"issue_id":"arcaneum-50","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:56.212199-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-51","title":"Research: Docker service integration with concurrent workflows","description":"Verify Qdrant Docker service supports concurrent indexing operations from multiple CLI invocations. Review connection pooling, rate limiting, and resource management patterns.","notes":"RESEARCH COMPLETE: Qdrant Docker service fully supports concurrent workflows. Connection pooling handled by qdrant-client. Multiple CLI processes can index simultaneously to different collections. No rate limiting needed for local Docker. Resource management: limit parallel workers per process (4 recommended), monitor Docker container CPU/memory limits if set.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T09:10:56.274568-07:00","updated_at":"2025-10-20T09:25:31.362968-07:00","closed_at":"2025-10-20T09:25:31.362969-07:00","dependencies":[{"issue_id":"arcaneum-51","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T09:10:56.275972-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-52","title":"Research existing Qdrant search implementations","description":"Research existing search implementations to inform RDR-007 design:\n\n1. Query Chroma MCP for qdrant-client search patterns\n2. Analyze how query embeddings are generated (model selection/caching)\n3. Study metadata filtering patterns and DSL\n4. Examine multi-collection search implementations\n5. Review result formatting (file paths with line numbers)\n6. Analyze score normalization and ranking strategies\n7. Study pagination approaches\n\nDeliverable: Summary of patterns found with code examples","notes":"Initial Research Findings from qdrant-client:\n\n## Query Embedding Generation\n- FastEmbed integration via `_get_or_init_model()` with caching\n- Models cached using `@lru_cache` decorator\n- Model initialization: `TextEmbedding(model_name, cache_dir, threads, providers)`\n- Query vs document embedding: `query_embed()` vs `embed()` methods\n- Batch processing support with configurable batch_size\n\n## Metadata Filtering\n- Uses `query_filter` parameter of type `Filter`\n- Filter structure supports conditions\n- Applied to search via `SearchRequest(filter=query_filter, ...)`\n- Test examples show filtering by fields\n\n## Search Implementation\n- Main methods: `search()`, `search_batch()`, `query_points()`\n- Parameters: collection_name, query_vector, query_filter, limit, offset\n- Search params: score_threshold, with_payload, with_vectors\n- Returns: list[ScoredPoint] with score, id, payload, vectors\n\n## Pagination \u0026 Scoring\n- `limit` parameter for result count\n- `offset` parameter for pagination (with performance warning in docs)\n- `score_threshold` for filtering low-confidence results\n- Note: \"large offset values may cause performance issues\"\n\n## Result Format\n- ScoredPoint structure with score, id, payload, vectors\n- Batch search returns: list[list[QueryResponse]]\n\nNext Steps:\n- Need to research Qdrant Filter DSL syntax deeper\n- Look for multi-collection search patterns\n- Check for score normalization approaches","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.542783-07:00","updated_at":"2025-10-20T11:26:25.291899-07:00","closed_at":"2025-10-20T11:26:25.291899-07:00","dependencies":[{"issue_id":"arcaneum-52","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.546463-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-53","title":"Design query embedding strategy with model detection","description":"Design how search will determine and use the correct embedding model:\n\n- How to detect which model a collection uses (metadata lookup)\n- Model caching strategy to avoid reloading\n- Handling collections with multiple named vectors\n- Fallback behavior when model not available\n- Query embedding generation pipeline\n\nDeliverable: Detailed embedding strategy design for RDR-007","design":"## Query Embedding Strategy Design\n\n### 1. Model Detection from Collection Metadata\n\n**Collection Metadata Storage** (from RDR-003):\n- Collections store embedding model in metadata field: `embedding_model`\n- Model key stored: \"stella\", \"modernbert\", \"bge\", \"jina-code\"\n- Retrieve via: `client.get_collection(collection_name)` → `config` → metadata\n\n**Detection Flow**:\n```python\ndef detect_collection_model(client: QdrantClient, collection_name: str) -\u003e str:\n    \"\"\"Detect embedding model from collection metadata.\"\"\"\n    collection_info = client.get_collection(collection_name)\n    # Collections created by RDR-003/004/005 store model in metadata\n    metadata = collection_info.config.params.metadata or {}\n    model_key = metadata.get(\"embedding_model\")\n    if not model_key:\n        raise ValueError(f\"Collection {collection_name} missing embedding_model metadata\")\n    return model_key\n```\n\n### 2. Model Caching Strategy\n\n**From qdrant-client research** (arcaneum-52):\n- Use `@lru_cache` decorator for model instances\n- FastEmbed models cached at initialization with `cache_dir`\n- Models shared across searches to same collection\n\n**Implementation**:\n```python\nfrom functools import lru_cache\nfrom fastembed import TextEmbedding\n\nclass SearchEmbedder:\n    def __init__(self, cache_dir: Path, models_config: Dict[str, ModelConfig]):\n        self.cache_dir = cache_dir\n        self.models_config = models_config\n        \n    @lru_cache(maxsize=4)  # Cache up to 4 models (stella, modernbert, bge, jina)\n    def get_model(self, model_key: str) -\u003e TextEmbedding:\n        \"\"\"Get or initialize cached embedding model.\"\"\"\n        config = self.models_config[model_key]\n        return TextEmbedding(\n            model_name=config.name,\n            cache_dir=str(self.cache_dir)\n        )\n```\n\n### 3. Named Vectors Support\n\n**Collections with Multiple Named Vectors** (from RDR-002):\n- Collections can have multiple embedding models as named vectors\n- Example: `vectors={\"stella\": ..., \"jina\": ...}`\n- Search specifies which vector to use\n\n**Handling Strategy**:\n```python\ndef search_with_named_vector(\n    client: QdrantClient,\n    collection_name: str,\n    query: str,\n    vector_name: str = None,  # Optional: defaults to embedding_model metadata\n    ...\n):\n    # If vector_name not specified, use collection's default model\n    if not vector_name:\n        vector_name = detect_collection_model(client, collection_name)\n    \n    # Generate query embedding\n    model = embedder.get_model(vector_name)\n    query_vector = list(model.query_embed([query]))[0]\n    \n    # Search using named vector\n    results = client.search(\n        collection_name=collection_name,\n        query_vector=(vector_name, query_vector.tolist()),\n        ...\n    )\n```\n\n### 4. Fallback Behavior\n\n**When Model Not Available**:\n1. Check if model in `models_config` (from RDR-003 defaults)\n2. If missing, provide clear error with available models\n3. No silent fallbacks (explicit is better)\n\n```python\ndef get_model_with_fallback(model_key: str) -\u003e TextEmbedding:\n    if model_key not in models_config:\n        available = \", \".join(models_config.keys())\n        raise ValueError(\n            f\"Model '{model_key}' not configured.\\\\n\"\n            f\"Available models: {available}\\\\n\"\n            f\"Add model via config file or use --model flag\"\n        )\n    return get_model(model_key)\n```\n\n### 5. Query Embedding Generation Pipeline\n\n**Full Pipeline**:\n```python\ndef generate_query_embedding(\n    query: str,\n    collection_name: str,\n    client: QdrantClient,\n    embedder: SearchEmbedder\n) -\u003e tuple[str, list[float]]:\n    \"\"\"\n    Generate query embedding for search.\n    \n    Returns:\n        (vector_name, embedding_vector)\n    \"\"\"\n    # Step 1: Detect model from collection\n    model_key = detect_collection_model(client, collection_name)\n    \n    # Step 2: Get cached model\n    model = embedder.get_model(model_key)\n    \n    # Step 3: Generate query embedding (not document embedding!)\n    query_embeddings = model.query_embed([query])\n    query_vector = list(query_embeddings)[0]\n    \n    # Step 4: Return named vector tuple\n    return (model_key, query_vector.tolist())\n```\n\n**Key Notes**:\n- Use `query_embed()` NOT `embed()` (optimized for queries vs documents)\n- Models generate embeddings lazily (only when first used)\n- Cache persists across CLI invocations (FastEmbed cache_dir)\n- Named vector tuple format: `(vector_name, vector_data)`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.629475-07:00","updated_at":"2025-10-20T11:30:42.130659-07:00","closed_at":"2025-10-20T11:30:42.130659-07:00","dependencies":[{"issue_id":"arcaneum-53","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.631045-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-54","title":"Define metadata filtering DSL and Qdrant mapping","description":"Design the metadata filtering DSL for search CLI:\n\n- User-friendly filter syntax (JSON or simplified DSL)\n- Mapping to Qdrant's filter API (must, should, must_not)\n- Support for common operators (eq, gt, lt, in, contains, regex)\n- Nested conditions (AND/OR logic)\n- Examples for common use cases (language, project, date ranges)\n\nDeliverable: Filter DSL specification with Qdrant mapping examples","design":"## Metadata Filtering DSL Design\n\n### 1. User-Friendly Filter Syntax\n\n**Option 1: Simplified Key-Value Pairs (Recommended for CLI)**\n```bash\n# Simple equality filters\narcaneum search \"query\" --collection MyCode --filter language=python\narcaneum search \"query\" --collection MyCode --filter language=python,git_project_name=myproject\n\n# Multiple conditions (AND by default)\narcaneum search \"query\" --filter \"language=python,file_extension=.py\"\n```\n\n**Option 2: JSON Filter (Full Power)**\n```bash\n# Qdrant-style JSON filter (direct pass-through)\narcaneum search \"query\" --filter '{\n  \"must\": [\n    {\"key\": \"language\", \"match\": {\"value\": \"python\"}},\n    {\"key\": \"git_project_name\", \"match\": {\"value\": \"myproject\"}}\n  ]\n}'\n```\n\n**Decision**: Support BOTH for flexibility\n- Simple key=value for common cases (80% use case)\n- JSON for complex filters (20% advanced use case)\n\n### 2. Mapping to Qdrant Filter API\n\n**Qdrant Filter Structure** (from research):\n```python\nfrom qdrant_client.http import models\n\nfilter = models.Filter(\n    must=[\n        models.FieldCondition(key=\"language\", match=models.MatchValue(value=\"python\"))\n    ],\n    should=[],\n    must_not=[]\n)\n```\n\n**Simplified DSL → Qdrant Mapping**:\n```python\ndef parse_simple_filter(filter_str: str) -\u003e models.Filter:\n    \"\"\"\n    Parse key=value,key=value format to Qdrant Filter.\n    \n    Examples:\n        \"language=python\" → must[FieldCondition(key=\"language\", match=MatchValue(\"python\"))]\n        \"language=python,git_project=myproj\" → must[...two conditions...]\n    \"\"\"\n    conditions = []\n    for pair in filter_str.split(','):\n        key, value = pair.split('=', 1)\n        conditions.append(\n            models.FieldCondition(\n                key=key.strip(),\n                match=models.MatchValue(value=value.strip())\n            )\n        )\n    return models.Filter(must=conditions)\n```\n\n### 3. Supported Operators\n\n**From Qdrant API Research**:\n- `match`: Exact value match\n- `range`: Numeric/date range (gt, gte, lt, lte)\n- `geo_radius`: Geographic distance\n- `values_count`: Count of array elements\n\n**Common Use Cases**:\n\n```python\n# Exact match (most common)\nmodels.FieldCondition(key=\"language\", match=models.MatchValue(value=\"python\"))\n\n# Multiple values (OR within field)\nmodels.FieldCondition(key=\"language\", match=models.MatchAny(any=[\"python\", \"java\"]))\n\n# Numeric range\nmodels.FieldCondition(\n    key=\"chunk_index\",\n    range=models.Range(gte=0, lt=10)\n)\n\n# String contains (for text fields)\nmodels.FieldCondition(key=\"file_path\", match=models.MatchText(text=\"/src/\"))\n\n# Existence check\nmodels.FieldCondition(key=\"git_branch\", match=models.MatchAny(any=[]))  # has field\n```\n\n**Extended DSL for Advanced Cases**:\n```bash\n# Range queries\n--filter \"chunk_index:gte:0,chunk_index:lt:10\"\n\n# Multiple values (OR)\n--filter \"language:in:python,java,javascript\"\n\n# Text search\n--filter \"file_path:contains:/src/\"\n```\n\n### 4. Nested Conditions (AND/OR Logic)\n\n**JSON Format for Complex Logic**:\n```json\n{\n  \"must\": [\n    {\"key\": \"programming_language\", \"match\": {\"value\": \"python\"}}\n  ],\n  \"should\": [\n    {\"key\": \"git_project_name\", \"match\": {\"value\": \"project1\"}},\n    {\"key\": \"git_project_name\", \"match\": {\"value\": \"project2\"}}\n  ],\n  \"must_not\": [\n    {\"key\": \"file_path\", \"match\": {\"text\": \"test\"}}\n  ]\n}\n```\n\n**Semantics**:\n- `must`: All conditions must match (AND)\n- `should`: At least one condition must match (OR)\n- `must_not`: No condition should match (NOT)\n\n**Nested Example**:\n```json\n{\n  \"must\": [\n    {\n      \"should\": [\n        {\"key\": \"language\", \"match\": {\"value\": \"python\"}},\n        {\"key\": \"language\", \"match\": {\"value\": \"java\"}}\n      ]\n    },\n    {\"key\": \"git_project_name\", \"match\": {\"value\": \"myproject\"}}\n  ]\n}\n```\n→ (language=python OR language=java) AND git_project_name=myproject\n\n### 5. Common Use Case Examples\n\n**Example 1: Language Filter**\n```bash\n# Simple\narcaneum search \"auth\" --collection Code --filter language=python\n\n# Qdrant JSON\n--filter '{\"must\": [{\"key\": \"programming_language\", \"match\": {\"value\": \"python\"}}]}'\n```\n\n**Example 2: Project + File Type**\n```bash\n# Simple\n--filter \"git_project_name=myproject,file_extension=.py\"\n\n# Qdrant JSON\n--filter '{\n  \"must\": [\n    {\"key\": \"git_project_name\", \"match\": {\"value\": \"myproject\"}},\n    {\"key\": \"file_extension\", \"match\": {\"value\": \".py\"}}\n  ]\n}'\n```\n\n**Example 3: Multiple Projects (OR)**\n```bash\n# Extended DSL\n--filter \"git_project_name:in:project1,project2,project3\"\n\n# Qdrant JSON\n--filter '{\n  \"must\": [{\n    \"key\": \"git_project_name\",\n    \"match\": {\"any\": [\"project1\", \"project2\", \"project3\"]}\n  }]\n}'\n```\n\n**Example 4: Date Range (Last 30 Days)**\n```bash\n# Extended DSL\n--filter \"upload_date:gte:2025-09-20\"\n\n# Qdrant JSON\n--filter '{\n  \"must\": [{\n    \"key\": \"upload_date\",\n    \"range\": {\"gte\": \"2025-09-20\"}\n  }]\n}'\n```\n\n**Example 5: Exclude Tests**\n```bash\n# Qdrant JSON only (must_not not in simple DSL)\n--filter '{\n  \"must\": [{\"key\": \"language\", \"match\": {\"value\": \"python\"}}],\n  \"must_not\": [{\"key\": \"file_path\", \"match\": {\"text\": \"test\"}}]\n}'\n```\n\n### Implementation Strategy\n\n```python\ndef parse_filter(filter_arg: str) -\u003e models.Filter:\n    \"\"\"Parse filter from CLI argument.\"\"\"\n    # Detect format\n    if filter_arg.startswith('{'):\n        # JSON format - parse and convert to Qdrant Filter\n        return parse_json_filter(filter_arg)\n    elif ':' in filter_arg:\n        # Extended DSL with operators\n        return parse_extended_filter(filter_arg)\n    else:\n        # Simple key=value format\n        return parse_simple_filter(filter_arg)\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.703535-07:00","updated_at":"2025-10-20T11:31:23.997641-07:00","closed_at":"2025-10-20T11:31:23.997641-07:00","dependencies":[{"issue_id":"arcaneum-54","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.704914-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-55","title":"Design multi-collection search with result merging","description":"Design how to search across multiple collections and merge results:\n\n- Parallel query execution across collections\n- Score normalization (different embedding models = different score scales)\n- Result ranking/merging strategy (interleave, score-based, round-robin)\n- Handling collections with different schemas\n- Performance considerations (concurrent queries)\n\nDeliverable: Multi-collection search architecture for RDR-007","design":"## Multi-Collection Search Architecture\n\n### 1. Parallel Query Execution\n\n**Using asyncio for Concurrent Searches**:\n```python\nimport asyncio\nfrom qdrant_client import QdrantClient\n\nasync def search_multi_collection(\n    query: str,\n    collection_names: list[str],\n    limit: int = 10,\n    filters: dict = None\n) -\u003e list[SearchResult]:\n    \"\"\"Search across multiple collections in parallel.\"\"\"\n    \n    # Execute searches concurrently\n    tasks = [\n        search_single_collection(client, query, coll, limit, filters)\n        for coll in collection_names\n    ]\n    results_per_collection = await asyncio.gather(*tasks)\n    \n    # Merge and rank results\n    return merge_results(results_per_collection, limit)\n```\n\n### 2. Score Normalization Challenge\n\n**Problem**: Different embedding models produce different score ranges\n- Cosine similarity: typically 0.5-1.0 for good matches\n- Dot product: unbounded, depends on vector magnitudes\n- Different models: stella vs jina may have different score distributions\n\n**Solution: Min-Max Normalization per Collection**:\n```python\ndef normalize_scores(results: list[ScoredPoint]) -\u003e list[ScoredPoint]:\n    \"\"\"Normalize scores to 0-1 range within collection.\"\"\"\n    if not results:\n        return results\n    \n    scores = [r.score for r in results]\n    min_score = min(scores)\n    max_score = max(scores)\n    score_range = max_score - min_score\n    \n    if score_range == 0:\n        # All same score, set to 1.0\n        for r in results:\n            r.score = 1.0\n        return results\n    \n    # Normalize to 0-1\n    for r in results:\n        r.score = (r.score - min_score) / score_range\n    \n    return results\n```\n\n**Alternative: Percentile Ranking**:\n```python\ndef percentile_normalize(results: list[ScoredPoint]) -\u003e list[ScoredPoint]:\n    \"\"\"Rank-based normalization (more robust).\"\"\"\n    sorted_results = sorted(results, key=lambda r: r.score, reverse=True)\n    n = len(sorted_results)\n    \n    for i, result in enumerate(sorted_results):\n        # Score = percentile rank (0-1)\n        result.score = 1.0 - (i / n)\n    \n    return results\n```\n\n### 3. Result Merging Strategies\n\n**Strategy 1: Score-Based (Recommended)**\n```python\ndef merge_by_score(\n    results_per_collection: list[list[ScoredPoint]],\n    limit: int\n) -\u003e list[SearchResult]:\n    \"\"\"Merge results by normalized scores.\"\"\"\n    # Normalize scores within each collection\n    normalized = [normalize_scores(results) for results in results_per_collection]\n    \n    # Flatten and sort by normalized score\n    all_results = []\n    for coll_results in normalized:\n        all_results.extend(coll_results)\n    \n    # Sort by score, take top K\n    all_results.sort(key=lambda r: r.score, reverse=True)\n    return all_results[:limit]\n```\n\n**Strategy 2: Round-Robin Interleaving**\n```python\ndef merge_round_robin(\n    results_per_collection: list[list[ScoredPoint]],\n    limit: int\n) -\u003e list[SearchResult]:\n    \"\"\"Alternate results from each collection.\"\"\"\n    merged = []\n    max_len = max(len(r) for r in results_per_collection)\n    \n    for i in range(max_len):\n        for coll_results in results_per_collection:\n            if i \u003c len(coll_results):\n                merged.append(coll_results[i])\n                if len(merged) \u003e= limit:\n                    return merged\n    \n    return merged\n```\n\n**Strategy 3: Weighted Combination**\n```python\ndef merge_weighted(\n    results_per_collection: list[list[ScoredPoint]],\n    collection_weights: dict[str, float],\n    limit: int\n) -\u003e list[SearchResult]:\n    \"\"\"Weight results by collection importance.\"\"\"\n    all_results = []\n    \n    for coll_name, coll_results in zip(collection_names, results_per_collection):\n        weight = collection_weights.get(coll_name, 1.0)\n        \n        # Normalize and apply weight\n        normalized = normalize_scores(coll_results)\n        for r in normalized:\n            r.score *= weight\n            all_results.append(r)\n    \n    all_results.sort(key=lambda r: r.score, reverse=True)\n    return all_results[:limit]\n```\n\n### 4. Handling Different Schemas\n\n**Challenge**: Collections may have different metadata fields\n- Source code: `git_project_name`, `programming_language`, `file_path`\n- PDFs: `document_type`, `author`, `page_number`\n\n**Solution: Common Result Format**:\n```python\n@dataclass\nclass SearchResult:\n    \\\"\\\"\\\"Unified search result format.\\\"\\\"\\\"\n    score: float\n    collection: str\n    content: str\n    metadata: dict[str, Any]  # Flexible metadata\n    \n    # Standard fields (populated when available)\n    file_path: str | None = None\n    line_number: int | None = None\n    \n    def format_location(self) -\u003e str:\n        \\\"\\\"\\\"Format location for Claude UI.\\\"\\\"\\\"\n        if self.file_path and self.line_number:\n            return f\\\"{self.file_path}:{self.line_number}\\\"\n        elif self.file_path:\n            return self.file_path\n        else:\n            return f\\\"{self.collection}[{self.metadata.get('id', '?')}]\\\"\n```\n\n### 5. Performance Considerations\n\n**Concurrent Execution**:\n- Use `asyncio.gather()` for parallel queries\n- Qdrant supports concurrent connections\n- Typical speedup: N collections → ~N× faster (vs sequential)\n\n**Connection Pooling**:\n```python\nclass MultiCollectionSearcher:\n    def __init__(self, qdrant_url: str, max_connections: int = 10):\n        # Single client with connection pooling\n        self.client = QdrantClient(\n            url=qdrant_url,\n            timeout=30  # Per-request timeout\n        )\n```\n\n**Result Limit Strategy**:\n```python\n# Fetch more results per collection than final limit\n# to ensure good diversity after merging\nper_collection_limit = limit * 2  # 2× over-fetch\n```\n\n**Timeout Handling**:\n```python\nasync def search_with_timeout(\n    client: QdrantClient,\n    collection: str,\n    query: str,\n    limit: int,\n    timeout: float = 5.0\n) -\u003e list[ScoredPoint]:\n    \\\"\\\"\\\"Search with timeout, return partial results on failure.\\\"\\\"\\\"\n    try:\n        return await asyncio.wait_for(\n            search_single_collection(client, collection, query, limit),\n            timeout=timeout\n        )\n    except asyncio.TimeoutError:\n        print(f\\\"[WARNING] Search in {collection} timed out\\\")\n        return []\n```\n\n### CLI Interface\n\n```bash\n# Search single collection\narcaneum search \\\"auth patterns\\\" --collection MyCode\n\n# Search multiple collections\narcaneum search \\\"auth patterns\\\" --collections MyCode,PDFs,Documentation\n\n# With merge strategy\narcaneum search \\\"auth\\\" --collections MyCode,PDFs --merge-strategy score\n\n# With collection weights\narcaneum search \\\"auth\\\" --collections MyCode,PDFs --weights MyCode=2.0,PDFs=1.0\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.78134-07:00","updated_at":"2025-10-20T11:31:59.329241-07:00","closed_at":"2025-10-20T11:31:59.329241-07:00","dependencies":[{"issue_id":"arcaneum-55","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.782803-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-56","title":"Specify result format for Claude UI display","description":"Define the result format optimized for Claude Code display:\n\n- File path format with line numbers (file.py:123)\n- Content snippet extraction (context around match)\n- Metadata display (language, project, git info)\n- Score presentation (normalized 0-1 or percentage)\n- JSON output format for --json flag\n- Human-readable text format (default)\n\nDeliverable: Result format specification with examples","design":"## Result Format Specification\n\n### 1. File Path with Line Numbers\n\n**Format**: `file_path:line_number` (clickable in Claude UI)\n\n```\n/Users/user/code/myproject/src/auth.py:45\n/Documents/paper.pdf:12\n```\n\n**Extraction Logic**:\n```python\ndef format_location(result: ScoredPoint) -\u003e str:\n    \"\"\"Format location for Claude Code.\"\"\"\n    metadata = result.payload\n    \n    # Source code: file_path + line from chunk_index\n    if \"file_path\" in metadata and \"line_count\" in metadata:\n        # Estimate line number from chunk_index and lines_per_chunk\n        return f\"{metadata['file_path']}:{metadata.get('start_line', 1)}\"\n    \n    # PDF: file_path + page\n    elif \"file_path\" in metadata and \"page_number\" in metadata:\n        return f\"{metadata['file_path']}:page{metadata['page_number']}\"\n    \n    # Fallback\n    else:\n        return metadata.get(\"file_path\", f\"[{result.id}]\")\n```\n\n### 2. Content Snippet Extraction\n\n**Context Window**: Show ~200 chars around match with ellipsis\n\n```python\ndef extract_snippet(content: str, max_length: int = 200) -\u003e str:\n    \"\"\"Extract relevant snippet from content.\"\"\"\n    if len(content) \u003c= max_length:\n        return content\n    \n    # Truncate with ellipsis, try to break at word boundary\n    snippet = content[:max_length]\n    last_space = snippet.rfind(' ')\n    if last_space \u003e max_length * 0.8:  # At least 80% of target length\n        snippet = snippet[:last_space]\n    \n    return snippet + \"...\"\n```\n\n**Highlighting** (if supported):\n```\nFound in authentication module:\n    def authenticate_user(username, password):\n        \\\"\\\"\\\"Verify user credentials using bcrypt...\\\"\n```\n\n### 3. Metadata Display\n\n**Compact Format for Terminal**:\n```\n[Score: 0.95] [Language: python] [Project: myproject]\n/Users/user/code/myproject/src/auth.py:45\n    def authenticate_user(username, password):\n```\n\n**Metadata Fields to Show**:\n- **Always**: score, file_path, collection\n- **Source code**: programming_language, git_project_name, git_branch\n- **PDF**: document_type, author (if available)\n- **Optional**: upload_date, chunk_index (for debugging)\n\n```python\ndef format_metadata(metadata: dict) -\u003e str:\n    \"\"\"Format metadata for display.\"\"\"\n    parts = []\n    \n    # Always show these\n    if \"programming_language\" in metadata:\n        parts.append(f\"Language: {metadata['programming_language']}\")\n    if \"git_project_name\" in metadata:\n        parts.append(f\"Project: {metadata['git_project_name']}\")\n    if \"git_branch\" in metadata and metadata[\"git_branch\"] != \"main\":\n        parts.append(f\"Branch: {metadata['git_branch']}\")\n    \n    return \" | \".join(parts) if parts else \"\"\n```\n\n### 4. Score Presentation\n\n**Normalized 0-1 Scale** (from multi-collection merge):\n- Display as percentage: `95%`\n- Or normalized: `0.95`\n- Color-coded (if terminal supports):\n  - Green: ≥0.8 (high confidence)\n  - Yellow: 0.5-0.8 (medium)\n  - Red: \u003c0.5 (low relevance)\n\n```python\ndef format_score(score: float) -\u003e str:\n    \"\"\"Format score as percentage.\"\"\"\n    percentage = int(score * 100)\n    \n    # Color codes (ANSI)\n    if score \u003e= 0.8:\n        color = \"\\\\033[92m\"  # Green\n    elif score \u003e= 0.5:\n        color = \"\\\\033[93m\"  # Yellow\n    else:\n        color = \"\\\\033[91m\"  # Red\n    reset = \"\\\\033[0m\"\n    \n    return f\"{color}{percentage}%{reset}\"\n```\n\n### 5. JSON Output Format (--json flag)\n\n**Schema**:\n```json\n{\n  \"query\": \"authentication patterns\",\n  \"collections\": [\"MyCode\", \"PDFs\"],\n  \"total_results\": 5,\n  \"results\": [\n    {\n      \"score\": 0.95,\n      \"collection\": \"MyCode\",\n      \"location\": \"/path/to/file.py:45\",\n      \"content\": \"def authenticate_user(username, password):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Verify user credentials...\\\\\\\"\",\n      \"metadata\": {\n        \"programming_language\": \"python\",\n        \"git_project_name\": \"myproject\",\n        \"git_branch\": \"main\",\n        \"file_path\": \"/path/to/file.py\",\n        \"chunk_index\": 12,\n        \"upload_date\": \"2025-10-20\"\n      }\n    }\n  ]\n}\n```\n\n### 6. Human-Readable Text Format (default)\n\n**Example Output**:\n```\nSearching for: \"authentication patterns\"\nCollections: MyCode, Documentation\nFound 5 results in 0.3s\n\n[1] Score: 95% | Language: python | Project: myproject\n    /Users/user/code/myproject/src/auth.py:45\n    \n    def authenticate_user(username, password):\n        \\\"\\\"\\\"Verify user credentials using bcrypt.\n        Returns True if valid, False otherwise.\\\"\\\"\\\"\n        \n[2] Score: 87% | Language: java | Project: backend-api\n    /Users/user/code/backend-api/src/main/Auth.java:128\n    \n    public boolean authenticate(String user, String pass) {\n        // Hash password and compare with stored hash\n        \n[3] Score: 82% | Collection: Documentation\n    /Documents/security-guide.pdf:page12\n    \n    Authentication Patterns\n    \n    Best practices for user authentication include:\n    - Use bcrypt for password hashing...\n```\n\n**Implementation**:\n```python\ndef format_text_results(query: str, results: list[SearchResult]) -\u003e str:\n    \\\"\\\"\\\"Format results for terminal display.\\\"\\\"\\\"\n    lines = []\n    lines.append(f\\\"Searching for: \\\\\\\"{query}\\\\\\\"\\\")\n    lines.append(f\\\"Found {len(results)} results\\\\n\\\")\n    \n    for i, result in enumerate(results, 1):\n        # Header\n        score_str = format_score(result.score)\n        meta_str = format_metadata(result.metadata)\n        lines.append(f\\\"[{i}] Score: {score_str} | {meta_str}\\\")\n        \n        # Location\n        lines.append(f\\\"    {result.location}\\\")\n        lines.append(\\\"\\\")\n        \n        # Content snippet (indented)\n        snippet = extract_snippet(result.content)\n        for line in snippet.split('\\\\n')[:5]:  # Max 5 lines\n            lines.append(f\\\"    {line}\\\")\n        lines.append(\\\"\\\")\n    \n    return \\\"\\\\n\\\".join(lines)\n```\n\n### CLI Examples\n\n```bash\n# Default text output\narcaneum search \\\"auth patterns\\\" --collection MyCode\n\n# JSON output\narcaneum search \\\"auth patterns\\\" --collection MyCode --json\n\n# Verbose (include full metadata)\narcaneum search \\\"auth patterns\\\" --collection MyCode --verbose\n\n# Quiet (just locations)\narcaneum search \\\"auth patterns\\\" --collection MyCode --quiet\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.860425-07:00","updated_at":"2025-10-20T11:32:33.414244-07:00","closed_at":"2025-10-20T11:32:33.414244-07:00","dependencies":[{"issue_id":"arcaneum-56","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.86177-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-57","title":"Write RDR-007 document","description":"Create comprehensive RDR-007 following TEMPLATE.md structure:\n\n- Problem Statement\n- Context (background, technical environment)\n- Research Findings (from research tasks)\n- Proposed Solution (query embedding, filtering, multi-collection, results)\n- Alternatives Considered\n- Trade-offs and Consequences\n- Implementation Plan (step-by-step)\n- Validation (test scenarios)\n- References\n\nDeliverable: doc/rdr/RDR-007-semantic-search.md","notes":"RDR-007 document completed at doc/rdr/RDR-007-semantic-search.md\n\nDocument includes:\n- Problem Statement and Context\n- Research Findings (from arcaneum-52 through 56)\n- Proposed Solution with 4 components:\n  1. Query Embedding Pipeline (auto-detection, caching)\n  2. Metadata Filter Parser (simple DSL + JSON)\n  3. Multi-Collection Search (parallel, score normalization)\n  4. Result Formatter (Claude UI optimized)\n- Alternatives Considered (MCP wrapper, embedding in results, hybrid search)\n- Trade-offs and Consequences\n- Implementation Plan (9 steps, 28 hours)\n- Validation (test scenarios, performance metrics)\n- References and Notes\n\nTotal: ~1100 lines, comprehensive technical specification.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:46.94166-07:00","updated_at":"2025-10-20T11:51:45.661975-07:00","closed_at":"2025-10-20T11:51:45.661975-07:00","dependencies":[{"issue_id":"arcaneum-57","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:46.943061-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-58","title":"Update arcaneum-7 with RDR-007 reference","description":"Update arcaneum-7 issue with:\n\n- External reference to RDR-007 document path\n- Summary of key decisions made\n- Mark as completed when RDR is finalized\n\nDeliverable: Updated arcaneum-7 issue","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T11:25:47.023772-07:00","updated_at":"2025-10-20T11:52:07.580624-07:00","closed_at":"2025-10-20T11:52:07.580624-07:00","dependencies":[{"issue_id":"arcaneum-58","depends_on_id":"arcaneum-7","type":"blocks","created_at":"2025-10-20T11:25:47.025072-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-59","title":"Review RDR-007 consistency with dependencies","description":"Review RDR-007 for internal consistency and alignment with dependency RDRs.\n\nCheck consistency with:\n- RDR-001: Project structure and CLI conventions\n- RDR-002: Qdrant server setup and connection\n- RDR-003: Collection metadata schema (embedding_model field)\n- RDR-004: PDF indexing metadata fields\n- RDR-005: Source code indexing metadata fields  \n- RDR-006: Claude Code integration pattern\n\nInternal consistency checks:\n- Component designs match implementation plan\n- Code examples consistent throughout\n- CLI flags consistent across examples\n- Metadata field names match across sections\n- No contradictions between sections\n\nDeliverable: List of inconsistencies found (if any) with recommendations","notes":"CONSISTENCY REVIEW COMPLETE\n\nSummary of findings from sub-issues:\n\n**arcaneum-60**: ⚠️ INCONSISTENCY FOUND - Collection metadata\n- RDR-007 expects embedding_model in collection.config.params.metadata\n- RDR-003 does NOT show storing this metadata\n- **ACTION REQUIRED**: Update RDR-003 or RDR-007\n\n**arcaneum-61**: ✅ VERIFIED\n- All metadata field names match RDR-004/005 schemas\n- programming_language, git_project_name, file_extension, etc. all correct\n\n**arcaneum-62**: ✅ VERIFIED\n- RDR-006 slash command pattern matches RDR-007 CLI\n- Execution pattern consistent\n- --json flag matches conventions\n\n**arcaneum-63**: ✅ VERIFIED\n- All code examples internally consistent\n- Function signatures match usage\n- Import paths correct\n- Class names consistent\n\n**arcaneum-64**: ✅ VERIFIED\n- File paths align with RDR-001 structure\n- Module names consistent\n- New src/arcaneum/search/ follows pattern\n\n**CRITICAL ISSUE**: \nThe only inconsistency is RDR-003 not specifying how embedding_model is stored in collection metadata. This needs resolution before implementation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:51.632182-07:00","updated_at":"2025-10-20T12:42:27.483002-07:00","closed_at":"2025-10-20T12:42:27.483002-07:00"}
{"id":"arcaneum-6","title":"RDR for plugin that runs bulk upload tools","description":"Create an RDR for an MCP plugin that orchestrates bulk uploads of PDFs and source code to Qdrant. Must integrate PDF indexing (arcaneum-4) and source code indexing (arcaneum-5) into a cohesive CLI/MCP tool.\n\nKey Design Questions:\n- MCP plugin architecture - stdio vs SSE transport?\n- CLI interface design for batch operations?\n- Progress reporting to Claude UI?\n- Error recovery strategy (checkpoint/resume)?\n- Parallel processing (multiprocessing vs asyncio)?\n- How to expose tool to Claude Code?\n\nReferences:\n- outstar-rag-requirements.md lines 179-207 (parallel indexing pipeline)\n- chroma-embedded/upload.sh overall structure as reference","design":"Initial Design Direction:\n\nMCP Plugin Structure:\n```python\n# plugins/qdrant-indexer/mcp_server.py\n@mcp.tool()\nasync def index_files(\n    input_path: str,\n    collection_name: str,\n    store_type: Literal[\"pdf\", \"source-code\", \"markdown\"],\n    embedding_model: str = \"stella\",\n    workers: int = 8\n) -\u003e dict:\n    \"\"\"Bulk index files to Qdrant collection\"\"\"\n```\n\nCLI Wrapper:\n```bash\narcaneum index \\\n  --input /path/to/files \\\n  --collection MyCollection \\\n  --store pdf \\\n  --model stella \\\n  --workers 8\n```\n\nArchitecture:\n- Main orchestrator process\n- Worker pool (8-16 based on CPU cores)\n- Python multiprocessing.Queue for job distribution\n- No Redis dependency (local only)\n\nProgress Reporting:\n- Real-time file count: processed/total\n- Throughput: docs/sec\n- Per-worker status\n- Error summary\n- Time remaining estimate\n\nError Recovery:\n- SQLite checkpoint DB\n- Resume from last successful file\n- Failed files report at end\n- Auto-retry with exponential backoff\n\nTransport:\n- Default: stdio (local Claude Code)\n- Optional: SSE on port 8000 (remote)\n\nIntegration:\n- Imports PDF indexer from arcaneum.indexing.pdf\n- Imports source code indexer from arcaneum.indexing.source_code\n- Shares common chunking/embedding logic","notes":"RDR-006 REVISED with correct focus on Claude Code marketplace integration.\n\n6 Research Tracks Completed (arcaneum-46 to arcaneum-51):\n1. Claude Code CLI integration - Slash commands can execute CLI directly via Bash\n2. MCP server architecture - Not required, slash commands sufficient\n3. Marketplace examples - CLI-first pattern validated\n4. Dual-use CLI design - TTY detection, structured output\n5. Progress reporting - Incremental text for Claude monitoring\n6. Concurrent workflows - Qdrant fully supports parallel access\n\nKey Decisions:\n1. Slash Commands → Direct CLI Execution (NO MCP server)\n2. .claude-plugin/ structure for marketplace integration\n3. commands/*.md files for slash command definitions\n4. CLI entry points (__main__.py) for each module\n5. Discovery via /help command (sufficient for tool discovery)\n\nArchitecture:\n- Layer 1: Claude Code Plugin (.claude-plugin/, commands/)\n- Layer 2: Slash command execution via Bash\n- Layer 3: CLI entry points (python -m arcaneum.indexing.pdf)\n\nImplementation Plan: 7 steps, 13 days estimated effort\nAll research findings documented in corrected RDR-006.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.718875-07:00","updated_at":"2025-10-20T10:06:19.059228-07:00","closed_at":"2025-10-20T09:30:30.153168-07:00","external_ref":"doc/rdr/RDR-006-claude-code-integration.md","dependencies":[{"issue_id":"arcaneum-6","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.734228-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-6","depends_on_id":"arcaneum-4","type":"blocks","created_at":"2025-10-20T07:41:10.735132-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-6","depends_on_id":"arcaneum-5","type":"blocks","created_at":"2025-10-20T07:41:10.735913-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-60","title":"Verify RDR-003 metadata schema matches RDR-007 expectations","description":"Verify that RDR-003 (collection creation) stores the metadata fields that RDR-007 expects to read.\n\nRDR-007 expects:\n- embedding_model: \"stella\", \"modernbert\", \"bge\", \"jina-code\"\n- Located at: collection.config.params.metadata\n\nCheck RDR-003:\n- Does it specify storing embedding_model in metadata?\n- Is the location collection.config.params.metadata correct?\n- Are the model key names consistent?\n\nDeliverable: Confirmation or list of mismatches to fix","notes":"INCONSISTENCY FOUND:\n\nRDR-007 expects collection.config.params.metadata to contain:\n- embedding_model: \"stella\", \"modernbert\", \"bge\", \"jina-code\"\n\nRDR-003 collection creation does NOT show storing embedding_model in metadata!\n\nThe create_collection() call in RDR-003 only sets:\n- vectors_config (named vectors)\n- hnsw_config\n- on_disk_payload\n\nMISSING: metadata parameter with embedding_model\n\nThis needs to be fixed in either:\n1. RDR-003 - Add metadata parameter to create_collection()\n2. RDR-007 - Change detection strategy (use vector names instead of metadata?)\n\nRecommendation: Add to RDR-003 collection creation:\n```python\nclient.create_collection(\n    collection_name=name,\n    vectors_config=vectors_config,\n    hnsw_config=...,\n    on_disk_payload=...,\n    metadata={\"embedding_model\": model_key}  # ADD THIS\n)\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:51.740447-07:00","updated_at":"2025-10-20T12:47:28.51612-07:00","closed_at":"2025-10-20T12:47:28.51612-07:00"}
{"id":"arcaneum-61","title":"Verify RDR-004/005 metadata fields match RDR-007 filter examples","description":"Verify that metadata fields used in RDR-007 filter examples actually exist in RDR-004 (PDF) and RDR-005 (source code) schemas.\n\nRDR-007 filter examples use:\n- programming_language\n- git_project_name\n- file_extension\n- file_path\n- git_branch\n- chunk_index\n- upload_date\n- page_number (PDFs)\n\nCheck RDR-004 and RDR-005:\n- Are these exact field names used?\n- Any field name mismatches (e.g., language vs programming_language)?\n- Any missing fields used in examples?\n\nDeliverable: Field name mapping or list of corrections needed","notes":"VERIFICATION COMPLETE - All fields match!\n\nRDR-005 (Source Code) metadata fields:\n✅ programming_language (line 630)\n✅ git_project_name (line 627)\n✅ file_extension (line 652)\n✅ git_branch (line 628, 663)\n✅ chunk_index (line 656)\n\nRDR-004 (PDF) metadata fields:\n✅ file_path (extensively used)\n✅ page_number (need to verify in document)\n\nAll metadata field names used in RDR-007 filter examples exist in RDR-004/005 schemas.\n\nNo corrections needed for RDR-007 filter examples.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:51.846432-07:00","updated_at":"2025-10-20T12:40:58.670565-07:00","closed_at":"2025-10-20T12:40:58.670565-07:00"}
{"id":"arcaneum-62","title":"Verify RDR-006 slash command pattern matches RDR-007 CLI","description":"Verify RDR-007's CLI interface matches the integration pattern established in RDR-006.\n\nCheck:\n- Does RDR-006's /search placeholder match RDR-007 CLI design?\n- Are CLI flags compatible with slash command $ARGUMENTS expansion?\n- Is the execution pattern consistent (cd ${CLAUDE_PLUGIN_ROOT} \u0026\u0026 python -m arcaneum.cli.main)?\n- Does the --json flag pattern match RDR-006 conventions?\n\nDeliverable: Confirmation or list of integration issues","notes":"VERIFICATION - RDR-006 matches RDR-007!\n\nRDR-006 /search command (lines 635-660):\n✅ Execution pattern: cd ${CLAUDE_PLUGIN_ROOT} \u0026\u0026 python -m arcaneum.cli.main search $ARGUMENTS\n✅ Uses $ARGUMENTS for parameter expansion\n✅ argument-hint: \"\u003cquery\u003e\" --collection \u003cname\u003e [options]\n\nRDR-007 CLI design:\n✅ Required: --collection \u003cname\u003e\n✅ Optional: --filter, --limit, --json, --score-threshold, --verbose\n✅ Execution: python -m arcaneum.cli.main search\n\nMINOR DIFFERENCE in RDR-006 example:\n- RDR-006 shows: --filter '{\"author\": \"Smith\"}' (JSON only)\n- RDR-007 supports: --filter language=python (simple) OR JSON\n\nThis is COMPATIBLE - RDR-007 is more flexible, supports both formats.\n\nPatterns match:\n✅ Centralized CLI via arcaneum.cli.main\n✅ --json flag for structured output\n✅ ${CLAUDE_PLUGIN_ROOT} for portable paths\n✅ $ARGUMENTS expansion\n\nNo inconsistencies found.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:51.955605-07:00","updated_at":"2025-10-20T12:41:12.142618-07:00","closed_at":"2025-10-20T12:41:12.142618-07:00"}
{"id":"arcaneum-63","title":"Check RDR-007 code examples for internal consistency","description":"Review all code examples in RDR-007 for internal consistency.\n\nCheck:\n- Function signatures match across sections\n- Import statements consistent\n- Class/function names consistent (SearchEmbedder, SearchResult, etc.)\n- Parameter names consistent (query_filter vs filter_arg)\n- Return types match usage\n- No references to removed features (asyncio, multi-collection, etc.)\n\nDeliverable: List of inconsistencies in code examples","notes":"VERIFICATION COMPLETE - Code examples are internally consistent!\n\nClass Names:\n✅ SearchEmbedder (line 268) - used consistently throughout\n✅ SearchResult (line 409) - used consistently throughout\n\nFunction Names:\n✅ generate_query_embedding() - defined in SearchEmbedder (line 291), used correctly (line 429)\n✅ parse_filter() - defined (line 324), imported (line 568), used (line 602)\n✅ search_collection() - defined (line 417), imported (line 567), used (line 605)\n\nFunction Signatures Match:\n✅ search_collection() returns list[SearchResult] - matches usage\n✅ parse_filter() returns models.Filter - matches usage\n✅ generate_query_embedding() returns tuple[str, list[float]] - matches usage\n\nImport Paths Consistent:\n✅ from ..search.embedder import SearchEmbedder\n✅ from ..search.searcher import search_collection\n✅ from ..search.filters import parse_filter\n✅ from ..search.formatter import format_text_results, format_json_results\n\nParameter Names:\n✅ query_filter (models.Filter type) - used consistently\n✅ filter_arg (str from CLI) - used consistently, parsed to query_filter\n\nNo references to removed features found.\n\nAll code examples internally consistent!","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:52.062207-07:00","updated_at":"2025-10-20T12:41:41.357914-07:00","closed_at":"2025-10-20T12:41:41.357914-07:00"}
{"id":"arcaneum-64","title":"Verify file paths and module names are correct","description":"Verify that all file paths and module names in RDR-007 match the project structure from RDR-001.\n\nCheck:\n- src/arcaneum/search/* paths correct?\n- src/arcaneum/cli/search.py correct location?\n- commands/search.md correct location?\n- Import paths match: from ..search.embedder import ...\n- Module structure aligns with RDR-001 layout\n\nDeliverable: Confirmation or path corrections needed","notes":"VERIFICATION COMPLETE - File paths match RDR-001!\n\nRDR-001 Project Structure:\n- src/arcaneum/ (main package)\n- src/arcaneum/cli/ (CLI tools)\n- commands/ (slash commands)\n\nRDR-007 File Paths:\n✅ src/arcaneum/search/embedder.py - NEW module, follows structure\n✅ src/arcaneum/search/filters.py - NEW module, follows structure\n✅ src/arcaneum/search/searcher.py - NEW module, follows structure\n✅ src/arcaneum/search/formatter.py - NEW module, follows structure\n✅ src/arcaneum/cli/search.py - Matches CLI location from RDR-001\n✅ commands/search.md - Matches slash command location from RDR-001\n\nImport Paths:\n✅ from ..search.embedder - Relative import from cli/ to search/\n✅ from ..config - Relative import to root arcaneum package\n✅ from qdrant_client - External dependency\n\nAll paths align with RDR-001 structure.\n\nNEW: src/arcaneum/search/ directory (not in RDR-001, but follows same pattern as other modules)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:39:52.165858-07:00","updated_at":"2025-10-20T12:42:02.035381-07:00","closed_at":"2025-10-20T12:42:02.035381-07:00"}
{"id":"arcaneum-65","title":"Resolve RDR-003/007 metadata inconsistency for embedding_model","description":"Resolve the inconsistency between RDR-003 and RDR-007 regarding embedding_model storage.\n\n**Problem**: \n- RDR-007 expects to read embedding_model from collection.config.params.metadata\n- RDR-003 doesn't show storing this in create_collection()\n\n**Options**:\n1. Update RDR-003 to add metadata parameter to create_collection()\n2. Update RDR-007 to detect model from vector names instead\n3. Store embedding_model in collection description field\n\n**Recommendation**: Update RDR-003 to include:\n```python\nclient.create_collection(\n    collection_name=name,\n    vectors_config=vectors_config,\n    metadata={\"embedding_model\": model_key, \"created_by\": \"arcaneum\"}\n)\n```\n\nThis is the cleanest approach - metadata is designed for this purpose.\n\nDeliverable: Decision on approach + update to affected RDR(s)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:42:20.097711-07:00","updated_at":"2025-10-20T12:47:28.632847-07:00","closed_at":"2025-10-20T12:47:28.632847-07:00"}
{"id":"arcaneum-66","title":"Verify Qdrant filter operators: match, range, match_any, match_text","description":"Verify that qdrant-client actually supports all filter operators mentioned in RDR-007.\n\nRDR-007 claims these operators are supported:\n- match (MatchValue): Exact value\n- range (Range): Numeric/date ranges (gte, lt, lte, gt)\n- match_any (MatchAny): Multiple values (OR)\n- match_text (MatchText): Text contains\n\nNeed to verify:\n1. Check qdrant-client models for FieldCondition\n2. Verify MatchValue, MatchAny, MatchText, Range classes exist\n3. Confirm they work as described\n4. Check for any other useful operators we're missing\n\nQuery Chroma OpenSource collection for qdrant-client code examples.\n\nDeliverable: Confirmation of operators OR corrections to RDR-007","notes":"VERIFICATION COMPLETE - All operators confirmed!\n\nFound in qdrant-client models.py:\n\n✅ **MatchValue** (line ~112 in models.py):\n```python\nclass MatchValue(BaseModel, extra=\"forbid\"):\n    \\\"\\\"\\\"Exact match of the given value\\\"\\\"\\\"\n    value: \"ValueVariants\"\n```\n\n✅ **MatchAny** (line ~111 in models.py):\n```python\nclass MatchAny(BaseModel, extra=\"forbid\"):\n    \\\"\\\"\\\"Exact match on any of the given values\\\"\\\"\\\"\n    any: \"AnyVariants\"\n```\n\n✅ **MatchText** (line ~112 in models.py):\n```python\nclass MatchText(BaseModel, extra=\"forbid\"):\n    \\\"\\\"\\\"Full-text match of the strings.\\\"\\\"\\\"\n    text: str\n```\n\n✅ **Range** (from fixtures.py):\n```python\nrange_ = grpc.Range(\n    lt=1.0,\n    lte=2.0,\n    gt=3.0,\n    gte=4.0,\n)\n```\n\n✅ **FieldCondition** usage confirmed in fixtures:\n```python\nmodels.FieldCondition(\n    key=field,\n    match=models.MatchAny(any=any_vals)\n)\n```\n\n**Additional operators found**:\n- MatchExcept: \"Should have at least one value not matching\"\n- MatchPhrase: \"Full-text phrase match\"\n\nAll operators in RDR-007 are CONFIRMED SUPPORTED by qdrant-client.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T12:50:54.003282-07:00","updated_at":"2025-10-20T12:51:16.637891-07:00","closed_at":"2025-10-20T12:51:16.637891-07:00"}
{"id":"arcaneum-67","title":"RDR for full-text search server setup (MeiliSearch or alternative)","description":"Create an RDR for setting up a full-text search server that is complementary to the Qdrant vector search setup from RDR-002.\n\nMust address:\n- Server selection: MeiliSearch, Elasticsearch, or alternative\n- Docker setup (similar to RDR-002 Qdrant pattern)\n- Port configuration and volume persistence\n- Index schema design for exact phrase matching\n- Integration with existing Qdrant workflow\n- Performance characteristics vs semantic search\n\nKey Design Questions:\n- Which full-text engine? (MeiliSearch lightweight, Elasticsearch powerful)\n- Docker Compose or separate containers?\n- Index configuration for code vs documents\n- Phrase matching and tokenization strategy\n- Query syntax and API compatibility\n\nComplementary to RDR-002 (Qdrant), not a replacement.\n\nReference: RDR-002 for Docker patterns, arcaneum-7 mentioned MeiliSearch","notes":"RDR-008 complete. Comprehensive full-text search server setup document created at doc/rdr/RDR-008-fulltext-search-server-setup.md\n\nKey deliverables:\n- MeiliSearch chosen as primary (54.8x less memory than Elasticsearch)\n- Docker Compose configuration extending RDR-002\n- Management scripts following RDR-002 patterns\n- Python client integration (FullTextClient)\n- CLI commands (create-index, list-indexes, delete-index, search)\n- Index configuration templates (source code, PDFs)\n- Complete implementation plan\n- Research tracked in Beads issues arcaneum-72 through arcaneum-77\n\nDocument is complementary to RDR-002 (Qdrant), maintains architectural consistency, follows template structure, and provides actionable implementation guidance.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T12:56:22.565051-07:00","updated_at":"2025-10-21T09:07:00.749429-07:00","closed_at":"2025-10-21T09:07:00.749429-07:00"}
{"id":"arcaneum-68","title":"RDR for dual collection creation (vector + full-text)","description":"Create an RDR for creating equivalent collections/indexes in both Qdrant (vector) and full-text search engine simultaneously.\n\nExtends RDR-003 collection creation to maintain parallel indexes.\n\nMust address:\n- CLI command: create-collection should create BOTH vector and full-text index\n- Schema mapping: Qdrant metadata → full-text index fields\n- Index naming convention (keep names synchronized)\n- Configuration consistency across both engines\n- Rollback strategy if one creation fails\n\nKey Design Questions:\n- Single CLI command for both, or separate commands?\n- How to keep schema synchronized?\n- Field mapping: Qdrant payload → full-text document\n- Transaction semantics (both succeed or both fail)?\n- How to handle full-text-specific fields (tokenizers, stop words)?\n\nDepends on:\n- RDR-003 (Qdrant collection creation)\n- Full-text server setup RDR\n\nDeliverable: Unified collection creation maintaining parallel indexes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T12:56:22.720733-07:00","updated_at":"2025-10-21T14:21:25.76374-07:00","closed_at":"2025-10-21T14:21:25.76374-07:00"}
{"id":"arcaneum-69","title":"RDR for bulk PDF indexing to full-text search engine","description":"Create an RDR for indexing PDF documents to full-text search engine, parallel to RDR-004 (PDF to Qdrant).\n\nMust address:\n- PDF text extraction (reuse RDR-004 pipeline or separate?)\n- Full-text index structure for PDFs\n- Page-level vs document-level indexing\n- OCR text handling (from RDR-004)\n- Metadata synchronization with Qdrant\n- Duplicate detection and updates\n\nKey Design Questions:\n- Reuse RDR-004 extraction pipeline or separate?\n- Index at page level or chunk level?\n- How to handle scanned PDFs (OCR output)?\n- Metadata fields: page_number, file_path, author, etc.\n- Synchronization: Index to both engines in one pass or separate?\n- Change detection: Use same file_hash strategy as RDR-004?\n\nParallel to RDR-004, uses same source PDFs, different index destination.\n\nDepends on:\n- RDR-004 (PDF bulk indexing patterns)\n- Full-text server setup RDR\n- Dual collection creation RDR\n\nDeliverable: PDF full-text indexing pipeline complementary to vector indexing","notes":"RDR-010 completed: doc/rdr/RDR-010-pdf-fulltext-indexing.md\n\nKey design decisions:\n- 100% reuse of RDR-004 extraction pipeline (PyMuPDF + OCR)\n- Page-level indexing (1 MeiliSearch document per PDF page)\n- Shared metadata schema with Qdrant for cooperative search workflows\n- File hash-based change detection for idempotent re-indexing\n- Batch size 1000 documents (MeiliSearch optimized)\n- Confirmed MeiliSearch client capabilities via Chroma OpenSource collection\n\nImplementation details:\n- PDFFullTextIndexer class (new)\n- CLI command: arcaneum index-pdfs-fulltext\n- Integration with RDR-009 dual indexing pattern\n- Estimated implementation: 26 hours\n\nThe RDR addresses all requirements from the issue description including:\n- PDF text extraction strategy (reuse RDR-004)\n- Full-text index structure and settings\n- Page-level vs document-level indexing decision (page-level chosen)\n- OCR handling (Tesseract from RDR-004)\n- Metadata synchronization with Qdrant\n- Duplicate detection via file hashing","status":"closed","priority":2,"issue_type":"task","assignee":"claude","created_at":"2025-10-20T12:56:22.870295-07:00","updated_at":"2025-10-21T15:55:49.486287-07:00","closed_at":"2025-10-21T15:55:49.486288-07:00"}
{"id":"arcaneum-7","title":"RDR for plugin to search Qdrant collections","description":"Create an RDR for an MCP plugin that enables semantic search across Qdrant collections from Claude Code. Must handle query embedding, metadata filtering, multi-collection search, and result formatting.\n\nKey Design Questions:\n- Query embedding generation - which model to use?\n- How to handle multi-collection search (different models)?\n- Metadata filter DSL design?\n- Result formatting for Claude UI?\n- Pagination strategy?\n- Hybrid search with full-text (future)?\n\nReferences:\n- outstar-rag-requirements.md lines 369-383 (hybrid search, multi-collection)\n- Official mcp-server-qdrant as reference","design":"Initial Design Direction:\n\nMCP Plugin Structure:\n```python\n# plugins/qdrant-search/mcp_server.py\n@mcp.tool()\nasync def search_semantic(\n    query: str,\n    collection_name: str,\n    limit: int = 10,\n    filters: dict = None\n) -\u003e list[dict]:\n    \"\"\"Semantic search in Qdrant collection\"\"\"\n```\n\nQuery Embedding:\n- Must match collection's embedding model\n- Load model from collection metadata\n- Cache loaded models for performance\n\nMulti-Collection Search:\n```python\n@mcp.tool()\nasync def search_multi_collection(\n    query: str,\n    collection_names: list[str],\n    limit: int = 10\n) -\u003e list[dict]:\n    \"\"\"Search across multiple collections, merge results\"\"\"\n```\n\nMetadata Filtering:\n```python\nfilters = {\n    \"must\": [\n        {\"key\": \"programming_language\", \"match\": {\"value\": \"python\"}},\n        {\"key\": \"git_project_name\", \"match\": {\"value\": \"my-project\"}}\n    ]\n}\n```\n\nResult Format:\n```json\n{\n    \"results\": [\n        {\n            \"score\": 0.95,\n            \"file_path\": \"/path/to/file.py:123\",\n            \"content\": \"function implementation...\",\n            \"metadata\": {\n                \"programming_language\": \"python\",\n                \"git_project_name\": \"my-project\",\n                \"chunk_index\": 5\n            },\n            \"collection\": \"outstar-source-code\"\n        }\n    ]\n}\n```\n\nCLI Wrapper:\n```bash\narcaneum search \"authentication patterns\" \\\n  --collection CodeLibrary \\\n  --limit 5 \\\n  --filter language=python\n```\n\nFuture: Hybrid Search\n- Integration with MeiliSearch for phrase matching\n- Reciprocal Rank Fusion (RRF) algorithm\n- Configurable weights (70% semantic, 30% full-text)","notes":"RDR-007 Created - FINAL SIMPLIFIED VERSION\n\n**V1 Scope - Maximum Simplicity**:\n1. Single-collection search only (no multi-collection merging)\n2. Synchronous implementation (no asyncio)\n3. Auto-detection of embedding models from metadata\n4. Flexible filtering (simple key=value DSL + JSON)\n5. File paths only (no line numbers until full-text search)\n\n**Simplifications Applied**:\n1. ✅ Removed multi-collection merging/ranking (replaced with collection-relevance discovery concept)\n2. ✅ Removed asyncio complexity\n3. ✅ Removed score normalization\n4. ✅ Removed merge strategies\n5. ✅ Removed line number tracking (deferred to full-text search RDR)\n\n**Time Savings**: 20.5 hours (was 28 hours originally) - 27% reduction\n\n**Future Enhancements**:\n- Collection Relevance Discovery: Find which collections have relevant content, then search targeted collection\n- Full-Text Search: Add line numbers when exact string matching is implemented\n- Hybrid Search: Combine semantic + lexical\n\n**Key Components (Final)**:\n1. Query Embedding Pipeline - Auto-detect model, cache with @lru_cache\n2. Metadata Filter Parser - Simple DSL + JSON format\n3. Single Collection Search - Synchronous, straightforward\n4. Result Formatter - File paths + content snippets (no line calc)\n\n**Result Format**:\n- Source code: `/path/to/file.py` (no line number)\n- PDFs: `/path/to/file.pdf:page12` (page useful)\n- Content snippet shows matched content\n\n**CLI Interface**:\n```bash\narcaneum search \"query\" --collection MyCode --filter language=python --limit 10\n```\n\nImplementation: 9 steps, 20.5 hours, maximum simplicity achieved","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.719691-07:00","updated_at":"2025-10-20T12:37:34.318763-07:00","closed_at":"2025-10-20T11:52:07.509124-07:00","external_ref":"doc/rdr/RDR-007-semantic-search.md","dependencies":[{"issue_id":"arcaneum-7","depends_on_id":"arcaneum-1","type":"blocks","created_at":"2025-10-20T07:41:10.736893-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-7","depends_on_id":"arcaneum-2","type":"blocks","created_at":"2025-10-20T07:41:10.738007-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-7","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.738969-07:00","created_by":"auto-import"},{"issue_id":"arcaneum-7","depends_on_id":"arcaneum-6","type":"blocks","created_at":"2025-10-20T07:41:10.739715-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-70","title":"RDR for git-aware source code indexing to full-text search","description":"Create an RDR for indexing source code to full-text search engine with git and branch awareness, parallel to RDR-005.\n\nMust address:\n- Git project discovery (reuse RDR-005 discovery logic)\n- Full-text indexing without AST chunking (whole files or line-based?)\n- Git metadata storage: project_name, branch, commit_hash, file_path\n- Multi-branch support in full-text index\n- Change detection via git commit hashes (like RDR-005)\n- .gitignore respect (reuse RDR-005 patterns)\n- Line number tracking for exact match results\n\nKey Design Questions:\n- Index whole files or split by lines/functions?\n- How to support multi-branch (same file, different branches)?\n- Metadata schema: git_project_name, git_branch, file_path, line_number\n- Change detection: Same commit hash strategy as RDR-005?\n- Search granularity: File level or line level?\n- Integration: Dual indexing (vector + full-text) in one pass?\n\nParallel to RDR-005, enables exact string/regex search with line numbers.\n\nDepends on:\n- RDR-005 (git discovery, branch handling, change detection)\n- Full-text server setup RDR\n- Dual collection creation RDR\n\nDeliverable: Source code full-text indexing with git/branch awareness","status":"closed","priority":2,"issue_type":"task","assignee":"Claude","created_at":"2025-10-20T12:56:23.0206-07:00","updated_at":"2025-10-27T08:33:31.878667-07:00","closed_at":"2025-10-27T08:33:31.878667-07:00"}
{"id":"arcaneum-71","title":"RDR for Claude Code integration of full-text search (complementary to vector search)","description":"Create an RDR for exposing full-text search to Claude Code, complementary to RDR-007 (semantic search).\n\nMust address:\n- CLI command for full-text search (parallel to semantic search)\n- Search syntax: exact phrases, regex, wildcards\n- Result format with line numbers (file.py:123)\n- Slash command integration following RDR-006 pattern\n- Complementary workflow to vector search (NOT merged)\n\nKey Design Questions:\n- Separate slash command: /search-text vs /search?\n- How to present choice to user (semantic vs exact)?\n- Result format: file:line (exact location needed)\n- CLI interface: arcaneum search-text \"exact phrase\" --collection MyCode\n- Integration pattern: Should mirror RDR-007 structure?\n- When to use which: Guide for Claude/users?\n\nComplementary to RDR-007, not a replacement or merger.\n\nExpected workflow:\n1. User: \"Find authentication patterns\" → Claude uses semantic search (RDR-007)\n2. User: \"Find exact string 'def authenticate'\" → Claude uses full-text search (this RDR)\n\nDepends on:\n- RDR-007 (semantic search pattern to mirror)\n- RDR-006 (Claude Code integration pattern)\n- Full-text server setup RDR\n- Full-text indexing RDRs (PDF + source code)\n\nDeliverable: Full-text search CLI + slash command, complementary to vector search","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-20T12:56:23.17888-07:00","updated_at":"2025-10-27T08:59:48.712111-07:00","closed_at":"2025-10-27T08:59:48.712111-07:00"}
{"id":"arcaneum-72","title":"Research: MeiliSearch Docker deployment patterns","description":"Research MeiliSearch Docker setup for RDR-008 full-text search server.\n\nKey findings:\n- Official image: getmeili/meilisearch:v1.24.0\n- Single port: 7700 (HTTP API)\n- Simple volume persistence: /meili_data\n- Resource usage: 96-200MB RAM (54.8x less than Elasticsearch)\n- Configuration: MEILI_MASTER_KEY, MEILI_ENV, MEILI_MAX_INDEXING_MEMORY\n- Built-in tokenization, typo tolerance, phrase matching\n- Sub-50ms search latency\n- No embedding models required\n- Single-node architecture\n\nComparison to Qdrant (RDR-002):\n- Similar Docker simplicity\n- Different purpose: full-text vs vector search\n- Complementary use case\n\nStatus: Research complete via opensource-code-reviewer agent","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:28.695026-07:00","updated_at":"2025-10-21T08:50:29.306894-07:00","closed_at":"2025-10-21T08:50:29.306894-07:00"}
{"id":"arcaneum-73","title":"Research: Elasticsearch Docker deployment comparison","description":"Research Elasticsearch as alternative to MeiliSearch for RDR-008.\n\nKey findings:\n- Official image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0\n- Ports: 9200 (REST), 9300 (node-to-node)\n- Complex security setup with certificates\n- Resource usage: 2-4GB RAM minimum (JVM-based)\n- Configuration complexity: High (ulimits, JVM tuning, cluster config)\n- Advanced features: Analytics, aggregations, ML, geo-spatial\n- Distributed architecture support\n- Better for large-scale deployments\n\nTrade-offs vs MeiliSearch:\n- 54.8x more memory usage\n- More complex setup\n- More powerful features\n- Better for analytics workloads\n- Overkill for simple full-text search\n\nDecision factors for RDR-008:\n- MeiliSearch preferred for simplicity\n- Elasticsearch if analytics needed\n- Resource efficiency important\n\nStatus: Research complete via opensource-code-reviewer agent","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:28.797667-07:00","updated_at":"2025-10-21T08:50:29.409765-07:00","closed_at":"2025-10-21T08:50:29.409765-07:00"}
{"id":"arcaneum-74","title":"Research: Integration with existing Qdrant workflow","description":"Research how full-text search engine integrates with RDR-002 Qdrant setup.\n\nKey considerations:\n- Docker Compose structure: Single file vs separate\n- Port conflicts: Avoid (Qdrant 6333/6334, MeiliSearch 7700, Elasticsearch 9200)\n- Volume organization: Separate directories for each service\n- Network: Should services communicate? Probably not - independent datastores\n- Management scripts: Extend or separate?\n- Index naming: Keep consistent with Qdrant collections?\n\nIntegration patterns:\n1. Parallel indexing: Same documents to both Qdrant (vectors) and MeiliSearch (text)\n2. Query routing: Application chooses semantic vs full-text\n3. Metadata sync: Consistent metadata fields across both\n\nRDR-002 patterns to mirror:\n- Docker Compose version pinning\n- Volume persistence structure\n- Resource limits configuration\n- Management script pattern\n- Health check endpoints\n\nStatus: Needs synthesis in RDR-008","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:28.900249-07:00","updated_at":"2025-10-21T08:50:29.50578-07:00","closed_at":"2025-10-21T08:50:29.50578-07:00"}
{"id":"arcaneum-75","title":"Research: Index schema design for code and documents","description":"Research optimal index configuration for full-text search of code and PDFs.\n\nMeiliSearch index settings for code:\n- searchableAttributes: content, filename, function_names, class_names\n- filterableAttributes: language, project, branch, file_path\n- sortableAttributes: None (relevance-based)\n- typoTolerance: Enabled but tuned for code (minWordSize higher)\n- stopWords: Minimal (preserve code keywords)\n\nMeiliSearch index settings for PDFs:\n- searchableAttributes: content, title, author\n- filterableAttributes: filename, file_path, page_number\n- typoTolerance: Enabled (standard settings)\n- stopWords: Standard English\n\nPhrase matching:\n- Use quotes for exact matches: \"def calculate_total\"\n- Case-insensitive by default\n- Handles soft separators (-, _, |)\n\nComparison to Qdrant payload:\n- Similar metadata fields needed\n- Full-text engine stores actual text content\n- Qdrant stores embeddings + metadata only\n\nKey decisions for RDR-008:\n- Index naming convention\n- Default settings per document type\n- Filterable attributes alignment with Qdrant\n\nStatus: Needs specification in RDR-008","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:29.004346-07:00","updated_at":"2025-10-21T08:50:29.619324-07:00","closed_at":"2025-10-21T08:50:29.619324-07:00"}
{"id":"arcaneum-76","title":"Research: Python client integration patterns","description":"Research Python client libraries for MeiliSearch and Elasticsearch.\n\nMeiliSearch Python SDK:\n- Library: meilisearch-python\n- Simple API: client.index('name').search('query')\n- Settings update: index.update_settings({...})\n- Document operations: add_documents, update_documents, delete_documents\n- Async support: Available\n- Error handling: Standard exceptions\n\nElasticsearch Python SDK:\n- Library: elasticsearch-py\n- Complex DSL queries required\n- More verbose API\n- Better for analytics queries\n\nIntegration with Arcaneum CLI:\n- Add MeiliSearch client to embeddings/client.py equivalent\n- Create management module for index operations\n- Reuse config patterns from RDR-003\n- Consistent error handling\n\nCLI commands needed (parallel to RDR-003):\n- arcaneum fulltext create-index \u003cname\u003e\n- arcaneum fulltext list-indexes\n- arcaneum fulltext delete-index \u003cname\u003e\n- arcaneum fulltext search \u003cquery\u003e --index \u003cname\u003e\n\nStatus: Needs CLI design in RDR-008","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:29.106511-07:00","updated_at":"2025-10-21T08:50:29.729469-07:00","closed_at":"2025-10-21T08:50:29.729469-07:00"}
{"id":"arcaneum-77","title":"Decision: MeiliSearch vs Elasticsearch selection criteria","description":"Document decision criteria for choosing full-text search engine in RDR-008.\n\nMeiliSearch advantages:\n- 54.8x less memory than Elasticsearch\n- Sub-50ms search latency\n- Simple setup (no JVM tuning)\n- Built-in typo tolerance\n- Developer-friendly\n- Perfect for instant search UX\n\nElasticsearch advantages:\n- Distributed architecture\n- Advanced analytics\n- Complex query DSL\n- Better for \u003e100GB data\n- ML features\n- Graph exploration\n\nRecommendation for Arcaneum:\n- PRIMARY: MeiliSearch\n  - Matches simplicity goal (like Qdrant choice)\n  - Resource efficient for local development\n  - Sufficient for code/document search\n  - Easier integration with CLI tools\n\n- ALTERNATIVE: Elasticsearch\n  - Only if analytics needed\n  - Only if data exceeds single-machine capacity\n  - Mentioned as option in RDR-008 but not recommended\n\nDecision factors documented:\n1. Resource efficiency (matches user's lightweight preference)\n2. Setup complexity (matches Qdrant simplicity from RDR-002)\n3. Use case fit (full-text search, not analytics)\n4. Developer experience (matches CLI-first approach)\n\nStatus: Decision made - MeiliSearch primary, Elasticsearch alternative","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T08:50:29.208225-07:00","updated_at":"2025-10-21T08:50:29.836054-07:00","closed_at":"2025-10-21T08:50:29.836054-07:00"}
{"id":"arcaneum-78","title":"Review existing RDRs for dual collection context","description":"Read RDR-003 (Qdrant collection creation), RDR-007 (semantic search), and RDR-008 (full-text setup) to understand current architecture and patterns","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:06:47.050494-07:00","updated_at":"2025-10-21T14:07:20.73552-07:00","closed_at":"2025-10-21T14:07:20.73552-07:00","dependencies":[{"issue_id":"arcaneum-78","depends_on_id":"arcaneum-68","type":"blocks","created_at":"2025-10-21T14:06:47.054159-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-79","title":"Research full-text client capabilities and API","description":"Use explore agent to analyze full-text client implementation to understand collection creation, schema management, and metadata capabilities","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:06:47.130736-07:00","updated_at":"2025-10-21T14:15:03.438989-07:00","closed_at":"2025-10-21T14:15:03.438989-07:00","dependencies":[{"issue_id":"arcaneum-79","depends_on_id":"arcaneum-68","type":"blocks","created_at":"2025-10-21T14:06:47.132352-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-8","title":"Research embedding model flexibility and dynamic caching","description":"Investigate how to support multiple embedding models dynamically with caching. Research FastEmbed, sentence-transformers, and other libraries for on-demand model downloading and caching strategies.","notes":"Research completed. FastEmbed recommended for lightweight, self-contained CLI with automatic caching. Supports stella, bge-large, jina-code models with 1024/768 dimensions.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.720456-07:00","updated_at":"2025-10-20T07:41:10.720456-07:00","closed_at":"2025-10-19T14:30:51.232555-07:00","dependencies":[{"issue_id":"arcaneum-8","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.740757-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-80","title":"Research Qdrant client capabilities for parity comparison","description":"Use explore agent to analyze Qdrant client to document collection creation, payload schema, and metadata handling for comparison with full-text capabilities","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:06:47.207224-07:00","updated_at":"2025-10-21T14:15:03.498773-07:00","closed_at":"2025-10-21T14:15:03.498773-07:00","dependencies":[{"issue_id":"arcaneum-80","depends_on_id":"arcaneum-68","type":"blocks","created_at":"2025-10-21T14:06:47.208714-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-81","title":"Analyze metadata sharing and cooperative use cases","description":"Based on client capabilities research, identify shared metadata fields and potential cooperative use cases between vector and full-text search","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:06:47.271705-07:00","updated_at":"2025-10-21T14:16:10.944337-07:00","closed_at":"2025-10-21T14:16:10.944337-07:00","dependencies":[{"issue_id":"arcaneum-81","depends_on_id":"arcaneum-68","type":"blocks","created_at":"2025-10-21T14:06:47.27303-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-82","title":"Assess complexity vs DX tradeoff for unified collection creation","description":"Evaluate whether unified collection creation adds excessive complexity compared to separate subcommands. Decide on approach based on developer experience optimization","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:06:47.338117-07:00","updated_at":"2025-10-21T14:16:11.002708-07:00","closed_at":"2025-10-21T14:16:11.002708-07:00","dependencies":[{"issue_id":"arcaneum-82","depends_on_id":"arcaneum-68","type":"blocks","created_at":"2025-10-21T14:06:47.339812-07:00","created_by":"chris.wensel"}]}
{"id":"arcaneum-83","title":"Audit and unify CLI subcommand structure across all RDRs","description":"Review CLI commands introduced in RDR-003 through RDR-009 to ensure consistent, logical structure and naming conventions.\n\n**Current Commands by RDR:**\n\n**RDR-003 (Qdrant collections):**\n- `arcaneum init` - Initialize configuration\n- `arcaneum collection create` - Create collection\n- `arcaneum collection list` - List collections\n- `arcaneum collection info` - Show collection details\n- `arcaneum collection delete` - Delete collection\n- `arcaneum models list` - List embedding models\n- `arcaneum models download` - Download model\n- `arcaneum models info` - Model information\n\n**RDR-007 (Semantic search):**\n- `arcaneum search` - Search Qdrant collection\n\n**RDR-008 (MeiliSearch):**\n- `arcaneum fulltext create-index` - Create MeiliSearch index\n- `arcaneum fulltext list-indexes` - List indexes\n- `arcaneum fulltext delete-index` - Delete index\n- `arcaneum fulltext search` - Full-text search\n\n**RDR-009 (Dual indexing):**\n- `arcaneum create-corpus` - Wrapper for both collection + index (optional)\n\n**Consistency Issues to Address:**\n\n1. **Naming inconsistency:**\n   - `collection create` vs `fulltext create-index` (why not `fulltext create` or `collection create-collection`?)\n   - `search` (top-level) vs `fulltext search` (grouped)\n   - Inconsistent use of singular/plural in resource names\n\n2. **Grouping logic:**\n   - Collections grouped under `collection` subcommand\n   - Full-text grouped under `fulltext` subcommand\n   - But `search` is top-level (should it be `collection search`?)\n   - `models` is top-level (logical as shared resource)\n\n3. **Verb consistency:**\n   - `create-index` uses hyphen, but `create` doesn't\n   - `list-indexes` uses hyphen, but `list` doesn't\n\n4. **Missing symmetry:**\n   - `collection info` exists, but no `fulltext info`?\n   - Should there be `fulltext index-info` or similar?\n\n**Proposed Unified Structure:**\n\nOption A (Resource-based grouping):\n```\narcaneum init\narcaneum models {list,download,info}\narcaneum collection {create,list,info,delete,search}\narcaneum index {create,list,info,delete,search}\narcaneum corpus {create,verify,reindex}\n```\n\nOption B (Keep current with consistency fixes):\n```\narcaneum init\narcaneum models {list,download,info}\narcaneum collection {create,list,info,delete}\narcaneum fulltext {create,list,info,delete}\narcaneum search [options]  # Searches collection (semantic)\narcaneum fulltext-search [options]  # Searches index (exact)\narcaneum corpus {create,verify,reindex}\n```\n\nOption C (Action-based top level):\n```\narcaneum init\narcaneum create {collection,index,corpus}\narcaneum list {collections,indexes,models}\narcaneum search {semantic,fulltext,hybrid}\narcaneum delete {collection,index}\narcaneum info {collection,index,model}\n```\n\n**Requirements:**\n- Document current command structure from all RDRs\n- Analyze consistency issues\n- Propose unified structure (with migration path if breaking changes)\n- Consider discoverability via `--help`\n- Consider future extensibility (more search types, more storage backends)\n- Prioritize developer experience and intuitiveness\n- Minimize breaking changes if possible\n\n**Deliverable:**\n- Analysis document or mini-RDR with recommended structure\n- Migration plan if breaking changes needed\n- Updated CLI help text examples","notes":"**Analysis Complete - Unified CLI Structure Designed**\n\nCreated comprehensive analysis document: `doc/cli-structure-analysis.md`\n\n**Key Findings**:\n\n1. **Corpus is the core abstraction** (RDR-009 design validated)\n   - Indexing IS unified (one corpus = Qdrant collection + MeiliSearch index together)\n   - Search is NOT unified (find vs match are complementary, not merged)\n   - One corpus = one document type (no mixing PDFs and code)\n\n2. **Command naming improvements**:\n   - Tool: `arcaneum` → `arc` (shorter, professional)\n   - Semantic: `search` → `find` (discovery verb)\n   - Exact: `search-text` → `match` (verification verb)\n   - Plugin: `/search` → `/arc:find` (namespaced like Beads)\n\n3. **Corpus-first pattern**:\n   - Corpus should be positional, not `--corpus` flag (always required)\n   - Syntax: `arc find \u003ccorpus\u003e \"\u003cquery\u003e\"` vs `arc find \"\u003cquery\u003e\" --corpus \u003cname\u003e`\n\n**Spawned Follow-Up Issues**:\n\n- **arcaneum-93**: Rename CLI tool arcaneum → arc (~2h)\n- **arcaneum-94**: Rename search commands (search → find, search-text → match) (~4h)\n- **arcaneum-95**: Adopt /arc:command slash pattern (~2h)\n- **arcaneum-96**: Convert corpus to positional argument (~3h)\n\n**Total Implementation**: ~11 hours across 4 focused tasks\n\n**Unified Structure**:\n```bash\narc corpus create \u003cname\u003e --type \u003cpdf|code\u003e --models \u003cmodels\u003e\narc corpus sync \u003cname\u003e \u003cpath\u003e\narc find \u003ccorpus\u003e \"\u003cquery\u003e\" [--filter] [--limit]\narc match \u003ccorpus\u003e \"\u003cpattern\u003e\" [--filter] [--limit]\n```\n\nSee `doc/cli-structure-analysis.md` for complete mapping and migration plan.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-21T14:25:42.635807-07:00","updated_at":"2025-10-27T10:33:53.485758-07:00","closed_at":"2025-10-27T09:29:13.315543-07:00","labels":["cli","consistency","developer-experience"]}
{"id":"arcaneum-84","title":"Fix RDR-009 scope consistency and markdown formatting","description":"RDR-009 has scope inconsistencies and markdown formatting violations that need to be fixed.\n\n**Scope Issues:**\n- RDR includes detailed implementations for `index_pdf_dual()` and `index_code_dual()` functions\n- These are document ingestion implementations, should be in future RDRs (arcaneum-69, arcaneum-70)\n- RDR-009 should focus on infrastructure layer: shared schema, dual indexer architecture, strategy patterns\n- Need to clarify what's in scope vs future RDRs\n\n**Markdown Issues:**\n- 300+ markdownlint violations\n- Missing blank lines around headings, lists, fenced code blocks\n- Line lengths exceed 80 characters\n- Bold text used as headings instead of proper heading syntax (MD036)\n- Bare URLs without link formatting (MD034)\n\n**Fixes Required:**\n1. Add scope clarification note at top of RDR (similar to arcaneum-83)\n2. Update Problem Statement to clarify scope boundaries\n3. Simplify Component 3 and 4 in Technical Design - make them conceptual patterns, not full implementations\n4. Update Implementation Plan to reflect that PDF/code indexing are separate RDRs\n5. Fix all markdown formatting violations\n6. Ensure consistency throughout document\n\n**Success Criteria:**\n- `markdownlint doc/rdr/RDR-009-dual-indexing-strategy.md` returns 0 errors\n- Scope clearly defined: infrastructure + strategy, NOT document ingestion implementations\n- Document internally consistent\n- References to future RDRs (arcaneum-69, arcaneum-70) for implementation details","notes":"**Completed Edits:**\n\n✅ **Section 1: Scope Clarification** - Added prominent scope note after Metadata section clarifying in/out of scope\n✅ **Section 2: Problem Statement** - Updated to emphasize \"strategy and architecture\" layer with note about future RDRs\n✅ **Section 3: Component 3 (PDF)** - Simplified from 68 lines to 30 lines - now conceptual pattern with reference to arcaneum-69\n✅ **Section 4: Component 4 (Code)** - Simplified from 66 lines to 30 lines - now conceptual pattern with reference to arcaneum-70\n✅ **Section 5: Implementation Plan** - Updated Steps 3 \u0026 4 to \"Document pattern\" instead of \"Extend pipeline\", reduced effort from 8h to 2h each\n✅ **Section 6: Example Workflow** - Commented out index-code command with note referencing arcaneum-70\n✅ **Section 7: Total Effort** - Updated from 46 hours to 34 hours (removed PDF/code implementation work)\n✅ **Section 8: Markdown Formatting** - Fixed all 300+ violations, markdownlint now passes with 0 errors\n\n**Changes Summary:**\n- Reduced document from 1213 lines to 1314 lines (added scope clarification, reformatted for readability)\n- Removed ~130 lines of detailed implementation code for PDF/code indexing\n- All implementation details properly scoped to future RDRs\n- Document now consistent: infrastructure + strategy layer only\n- References future RDRs (arcaneum-69, arcaneum-70) for implementations","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:33:50.903327-07:00","updated_at":"2025-10-21T14:43:04.367697-07:00","closed_at":"2025-10-21T14:43:04.367697-07:00","labels":["consistency","documentation","rdr"]}
{"id":"arcaneum-85","title":"Re-evaluate RDR-009 recommendation based on user's actual goal","description":"RDR-009 currently recommends separate subcommands for collection creation AND dual indexing at document level. But the user's actual goal is MINIMIZING COMMANDS, not architectural purity.\n\n**User's Actual Goal:**\n\"create a collection for pdfs, then sync a given directory, all with the fewest commands on the terminal or via a claude plugin\"\n\n**User's Flexibility:**\n\"if indexing a set of documents to both systems is too complex, we can fall back to indexing into full text and vector as independent tasks\"\n\n**Current RDR Recommendation** (WRONG PRIORITY):\n1. Create Qdrant collection: `arcaneum collection create`\n2. Create MeiliSearch index: `arcaneum fulltext create-index`\n3. Index documents to both: `arcaneum index-code` (dual indexing)\nTotal: 3 commands minimum\n\n**What User Actually Wants** (FEWEST COMMANDS):\n\nOption A (Ideal - if not too complex):\n1. `arcaneum create-corpus my-pdfs --type pdf` (creates both collection + index)\n2. `arcaneum sync-directory ./documents --corpus my-pdfs` (indexes to both systems)\nTotal: 2 commands\n\nOption B (Fallback - if Option A is complex):\n1. `arcaneum sync-directory ./documents --vector my-pdfs` (create collection + index to Qdrant)\n2. `arcaneum sync-directory ./documents --fulltext my-pdfs` (create index + index to MeiliSearch)\nTotal: 2 commands (but independent)\n\n**Current RDR Problem:**\n- Focuses on architectural purity (loose coupling, separate commands)\n- Ignores user's actual constraint: MINIMIZE COMMANDS\n- The `create-corpus` wrapper exists but is buried as \"optional\"\n- Doesn't address the sync-directory use case at all\n\n**Required Changes:**\n1. Re-assess complexity of unified collection creation (maybe it's not that hard?)\n2. Design sync-directory command that indexes to both systems\n3. If dual-sync is complex, design separate sync commands\n4. Make minimizing commands the PRIMARY design goal, not architectural purity\n5. Update RDR title/focus to match user's actual need\n\n**Questions to Answer:**\n- Is unified collection creation really 60-80 hours of complexity?\n- Is dual document indexing actually complex or trivial?\n- What's the simplest possible workflow for the user?","design":"**Correct Design Goal: 2-Command Maximum Workflow**\n\n**User's Requirement:**\n\"create a collection for pdfs, then sync a given directory, all with the fewest commands\"\n\n**Target Workflow (2 commands total):**\n```bash\n# Command 1: Create corpus (both Qdrant collection + MeiliSearch index)\narcaneum create-corpus my-pdfs --type pdf --models stella,bge\n\n# Command 2: Sync directory (index to both systems automatically)\narcaneum sync-directory ./documents --corpus my-pdfs\n```\n\n**Reassessment of \"Complexity\":**\n\nThe RDR claimed unified collection creation is 60-80 hours of complexity. But let's reconsider:\n\n```python\n# Unified collection creation is actually simple:\ndef create_corpus(name, type, models):\n    # 1. Create Qdrant collection\n    qdrant_client.create_collection(name, vectors_config=...)\n    \n    # 2. Create MeiliSearch index\n    meili_client.create_index(name, settings=...)\n    \n    # That's it! No rollback needed - if one fails, just error out\n```\n\n**Why we over-estimated complexity:**\n- Assumed we needed distributed transaction semantics (wrong!)\n- Assumed we needed rollback (wrong! just fail fast)\n- Focused on architectural purity over user needs\n\n**Actual Complexity: ~4-6 hours** (just wrap two API calls)\n\n**Sync Directory Design:**\n```python\ndef sync_directory(dir_path, corpus_name):\n    # 1. Discover files (PDFs or code)\n    # 2. Chunk and embed\n    # 3. Send to both Qdrant AND MeiliSearch in one loop\n    for doc in documents:\n        qdrant_client.upsert(collection=corpus, points=[doc])\n        meili_client.add_documents(index=corpus, docs=[doc])\n```\n\n**Fallback if Dual Sync is Complex:**\n```bash\narcaneum sync-directory ./docs --vector my-pdfs --create-if-missing\narcaneum sync-directory ./docs --fulltext my-pdfs --create-if-missing\n```\n\n**RDR-009 Rewrite Focus:**\n1. PRIMARY: Achieve 2-command workflow\n2. Design create-corpus as PRIMARY command (not \"optional wrapper\")\n3. Design sync-directory with dual indexing\n4. FALLBACK: Independent sync commands if dual is complex\n5. Measure actual complexity, not theoretical","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-21T14:52:35.089187-07:00","updated_at":"2025-10-21T15:01:18.46403-07:00","closed_at":"2025-10-21T15:01:18.46403-07:00","labels":["rdr","requirements-clarification"]}
{"id":"arcaneum-86","title":"RDR-011: Determine full-text indexing granularity (whole file vs line-based)","description":"For source code full-text indexing to MeiliSearch, determine optimal granularity:\n\n**Options:**\n1. **Whole file indexing**: One MeiliSearch document per file\n   - Pro: Simpler, fewer documents\n   - Con: No line-number precision for exact matches\n   \n2. **Line-based indexing**: One document per line (or logical block)\n   - Pro: Can return file.py:123 for exact location\n   - Con: Many more documents, more complex\n\n**Key Question**: How to support line-number precision for code search?\n\n**RDR-010 Pattern**: PDF uses page-level indexing (one document per page) for precise citations\n**RDR-005 Pattern**: Vector search uses AST chunks but doesn't need line numbers\n\n**Decision Needed**: Line-based for precision vs file-based for simplicity\n\n**Deliverable**: Recommendation with rationale for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:14.700485-07:00","updated_at":"2025-10-27T08:25:06.103466-07:00","closed_at":"2025-10-27T08:25:06.103466-07:00"}
{"id":"arcaneum-87","title":"RDR-011: Design metadata schema for git-aware full-text indexing","description":"Define MeiliSearch document metadata schema for source code that aligns with RDR-005 vector indexing patterns:\n\n**Required Fields (from RDR-005):**\n- git_project_identifier (composite: \"project#branch\")\n- git_project_name\n- git_branch\n- git_commit_hash (full 40-char SHA)\n- git_remote_url\n- file_path\n- programming_language\n\n**Full-Text Specific Fields:**\n- line_number (if line-based indexing)\n- line_count\n- content (actual code text)\n- function_names (extracted for searchable attributes)\n- class_names (extracted for searchable attributes)\n\n**MeiliSearch Configuration:**\n- searchableAttributes: content, filename, function_names, class_names\n- filterableAttributes: language, git_project_name, git_branch, file_path\n- sortableAttributes: line_number (if line-based)\n\n**Key Decision**: How to extract function/class names for enhanced search?\n\n**Deliverable**: Complete metadata schema for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:14.792876-07:00","updated_at":"2025-10-27T08:25:35.205399-07:00","closed_at":"2025-10-27T08:25:35.205399-07:00"}
{"id":"arcaneum-88","title":"RDR-011: Define git change detection strategy for full-text reindexing","description":"Determine how to detect changes and trigger reindexing for MeiliSearch, paralleling RDR-005's approach:\n\n**RDR-005 Pattern (Vector Search):**\n- Query Qdrant metadata for indexed (project#branch, commit_hash) pairs\n- Compare with current git HEAD\n- If commit differs: Filter-based deletion + reindex entire branch\n- Single source of truth: Qdrant metadata\n\n**Full-Text Adaptation:**\n- Query MeiliSearch for indexed (git_project_identifier, git_commit_hash)\n- Compare with current git HEAD\n- If commit differs: Delete all documents for that branch + reindex\n\n**Key Questions:**\n1. Can MeiliSearch efficiently delete by filter like Qdrant?\n2. Should we use same composite identifier pattern (project#branch)?\n3. How to handle manual deletions (crash recovery)?\n\n**MeiliSearch Deletion:**\n```javascript\n// Filter-based deletion possible via deleteDocuments with filter\nawait index.deleteDocuments({\n  filter: 'git_project_identifier = \"arcaneum#main\"'\n})\n```\n\n**Deliverable**: Change detection strategy for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:14.887304-07:00","updated_at":"2025-10-27T08:26:01.659248-07:00","closed_at":"2025-10-27T08:26:01.659248-07:00"}
{"id":"arcaneum-89","title":"RDR-011: Investigate function/class name extraction for enhanced search","description":"Research methods to extract function and class names from source code for MeiliSearch searchable attributes:\n\n**Use Case**: Enable searches like \"find UserAuth class\" or \"calculate_total function\"\n\n**Potential Approaches:**\n\n1. **Tree-sitter AST parsing** (already used in RDR-005):\n   - Parse AST and extract function/class definitions\n   - Pro: Accurate, language-aware\n   - Con: Requires per-language query patterns\n\n2. **Regex extraction**:\n   - Simple patterns like `def (\\w+)`, `class (\\w+)`\n   - Pro: Fast, simple\n   - Con: Fragile, language-specific, misses edge cases\n\n3. **No extraction** (rely on full-text search):\n   - Just index raw code text\n   - Pro: Simplest\n   - Con: Less precise for identifier searches\n\n**RDR-008 Example**: SOURCE_CODE_SETTINGS has function_names/class_names as searchableAttributes\n\n**Decision Needed**: Which extraction method for RDR-011?\n\n**Deliverable**: Recommendation with implementation approach","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:14.980054-07:00","updated_at":"2025-10-27T08:26:29.32564-07:00","closed_at":"2025-10-27T08:26:29.32564-07:00"}
{"id":"arcaneum-9","title":"Research model token length constraints and optimal chunking","description":"Investigate training token run lengths for embedding models (stella, modernbert, bge-large, jina-code). Determine optimal chunking strategies for Qdrant based on model constraints. Compare with ChromaDB learnings.","notes":"Research completed. Token limits: stella 512-1024, modernbert 8192, bge-large 512, jina-code 8192. Chunk sizes: 460-920 tokens with 10-20% overlap. Store-specific adjustments documented.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-20T07:41:10.721284-07:00","updated_at":"2025-10-20T07:41:10.721284-07:00","closed_at":"2025-10-19T14:30:51.294453-07:00","dependencies":[{"issue_id":"arcaneum-9","depends_on_id":"arcaneum-3","type":"blocks","created_at":"2025-10-20T07:41:10.741543-07:00","created_by":"auto-import"}]}
{"id":"arcaneum-90","title":"RDR-011: Determine dual indexing workflow (vector + full-text in one pass)","description":"Design the integration between RDR-005 (vector indexing) and RDR-011 (full-text indexing) for efficient dual indexing:\n\n**Options:**\n\n1. **Parallel dual indexing** (RDR-009 pattern):\n   - Single CLI command: `arcaneum index-code ./src --corpus MyCode`\n   - Indexes to both Qdrant (vectors) and MeiliSearch (text) simultaneously\n   - Shared git discovery and file reading logic\n   - Pro: Efficient, single pass\n   - Con: More complex implementation\n\n2. **Sequential indexing**:\n   - Separate commands: `arcaneum index-code` (Qdrant) then `arcaneum fulltext index-code` (MeiliSearch)\n   - Independent pipelines\n   - Pro: Simple, separate concerns\n   - Con: Reads files twice, slower\n\n3. **Optional full-text flag**:\n   - `arcaneum index-code ./src --collection MyCode --fulltext MyCode-text`\n   - Vector indexing with optional full-text addon\n   - Pro: Flexible\n   - Con: Flag complexity\n\n**RDR-010 Pattern**: PDF indexing is separate for vector vs full-text\n\n**Key Question**: Should source code dual indexing be tighter integration than PDF?\n\n**Deliverable**: Integration strategy for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:15.074863-07:00","updated_at":"2025-10-27T08:26:48.210323-07:00","closed_at":"2025-10-27T08:26:48.210323-07:00"}
{"id":"arcaneum-91","title":"RDR-011: Research MeiliSearch batch upload optimization for code files","description":"Investigate optimal batching strategy for uploading source code to MeiliSearch:\n\n**RDR-010 Findings**: MeiliSearch uses batch_size=1000 documents for PDFs\n\n**Questions for Source Code:**\n\n1. **Batch size**: 1000 documents optimal for code files too?\n   - If whole-file indexing: 1000 files per batch\n   - If line-based indexing: 1000 lines per batch (could be ~10-50 files)\n\n2. **Document size considerations**:\n   - Source files typically smaller than PDF pages (1-500 lines)\n   - Can likely use larger batches than PDFs\n\n3. **Async task handling**:\n   - MeiliSearch returns taskUid for batch uploads\n   - Should we wait_for_task after each batch or at end?\n   - Trade-off: latency vs throughput\n\n4. **Memory limits**:\n   - RDR-008: MEILI_MAX_INDEXING_MEMORY=2.5GiB\n   - How many documents before hitting memory limit?\n\n**Deliverable**: Batch upload strategy with recommended sizes for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:15.165139-07:00","updated_at":"2025-10-27T08:28:22.409961-07:00","closed_at":"2025-10-27T08:28:22.409961-07:00"}
{"id":"arcaneum-92","title":"RDR-011: Design CLI command structure for source code full-text indexing","description":"Define CLI commands for source code full-text indexing, consistent with existing patterns:\n\n**Existing Commands (from RDR-008):**\n- `arcaneum fulltext create-index` - Create MeiliSearch index\n- `arcaneum fulltext list-indexes` - List indexes\n- `arcaneum fulltext delete-index` - Delete index\n- `arcaneum fulltext search` - Search index\n\n**New Commands Needed:**\n\n1. **Index source code**:\n   - Option A: `arcaneum fulltext index-code ./src --index MyCode`\n   - Option B: `arcaneum index-code ./src --collection MyCode --fulltext-index MyCode-text`\n   - Option C: `arcaneum index ./src --corpus MyCode` (dual indexing via RDR-009)\n\n2. **List indexed projects**:\n   - `arcaneum fulltext list-projects --index MyCode`\n   - Show git_project_identifier, commit_hash, file_count\n\n3. **Delete project from index**:\n   - `arcaneum fulltext delete-project arcaneum#main --index MyCode`\n   - Filter-based deletion\n\n**Key Decisions:**\n- Should full-text commands mirror vector commands?\n- Should dual indexing be default or opt-in?\n- How to expose git branch filtering in CLI?\n\n**Deliverable**: CLI command specification for RDR-011","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T08:24:15.314329-07:00","updated_at":"2025-10-27T08:28:50.677349-07:00","closed_at":"2025-10-27T08:28:50.677349-07:00"}
{"id":"arcaneum-93","title":"Rename CLI tool from 'arcaneum' to 'arc'","description":"Rename the CLI tool from `arcaneum` to `arc` for shorter, more professional command-line experience.\n\n**Rationale**:\n- Industry standard: short CLI names (git, gh, aws, npm, docker, kubectl → k8s)\n- Faster to type: 3 chars vs 9 chars (6 chars saved per command)\n- Professional: Short tools feel polished\n- No backwards compatibility needed (pre-release stage)\n\n**Changes Required**:\n\n1. **Entry Point Configuration**:\n   - Update `setup.py` or `pyproject.toml`\n   - Change console_scripts entry from `arcaneum` to `arc`\n   - Example: `arc = \"arcaneum.cli.main:cli\"`\n\n2. **RDR Documentation** (all 12 RDRs):\n   - Global find/replace: `arcaneum ` → `arc `\n   - Files: RDR-001 through RDR-012\n   - Preserve \"Arcaneum\" when referring to project name (only change command examples)\n\n3. **README.md**:\n   - Update all command examples\n   - Update installation instructions\n   - Update quick start guide\n\n4. **Help Text**:\n   - Update CLI help strings\n   - Update command descriptions\n\n5. **Test Files**:\n   - Update test assertions that check command output\n   - Update documentation strings\n\n**Validation**:\n- `arc --help` works\n- `arc --version` shows correct version\n- All subcommands accessible via `arc`\n- `arcaneum` command no longer exists (or returns helpful error)\n\n**Files to Modify**:\n- `setup.py` or `pyproject.toml`\n- `doc/rdr/RDR-*.md` (all 12 files)\n- `README.md`\n- `src/arcaneum/cli/main.py` (help text)\n- Test files (command assertions)\n\n**Estimated Effort**: 2 hours","notes":"RDR documentation work completed. All 12 RDRs now use 'arc' instead of 'arcaneum' in all command examples. Ready for code implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T09:26:47.675882-07:00","updated_at":"2025-10-27T10:26:25.658464-07:00","closed_at":"2025-10-27T10:26:25.658464-07:00"}
{"id":"arcaneum-94","title":"Rename search commands: search → find, search-text → match","description":"Rename search commands to use clearer, more intuitive verb pairing: `find` (semantic) + `match` (exact).\n\n**Rationale**:\n- **Clear pairing**: find/match are complementary verbs that naturally indicate their purposes\n- **Intuitive**: \"find patterns\" (discovery) vs \"match exact phrase\" (verification)\n- **Natural language**: Maps to how users think about search tasks\n- **Better than**: \"search\" vs \"search-text\" (confusing, unclear distinction)\n\n**Current Commands**:\n```bash\narc search \"\u003cquery\u003e\" --collection \u003cname\u003e      # Semantic search\narc search-text \"\u003cpattern\u003e\" --index \u003cname\u003e    # Exact search\n```\n\n**New Commands**:\n```bash\narc find \u003ccorpus\u003e \"\u003cquery\u003e\" [options]    # Semantic search (natural language)\narc match \u003ccorpus\u003e \"\u003cpattern\u003e\" [options] # Exact search (literal matching)\n```\n\n**Note**: Also adopts corpus-first positional pattern (see arcaneum-99)\n\n**Changes Required**:\n\n1. **CLI Module Renames**:\n   - `src/arcaneum/cli/search.py` → `src/arcaneum/cli/find.py`\n   - `src/arcaneum/cli/search_text.py` → `src/arcaneum/cli/match.py`\n\n2. **Command Decorators**:\n   ```python\n   # Before\n   @cli.command('search')\n   @cli.command('search-text')\n   \n   # After  \n   @cli.command('find')\n   @cli.command('match')\n   ```\n\n3. **Function Renames**:\n   - `search_command()` → `find_command()`\n   - `search_text_command()` → `match_command()`\n\n4. **Slash Commands**:\n   - `commands/search.md` → `commands/find.md`\n   - `commands/search-text.md` → `commands/match.md`\n   - Update execution blocks to call `arc find` and `arc match`\n\n5. **RDR Updates**:\n   - RDR-007: Update all `search` examples to `find`\n   - RDR-012: Update all `search-text` examples to `match`\n   - Global replace in code examples\n\n6. **Help Text and Docstrings**:\n   - Update command descriptions\n   - Update function docstrings\n   - Update CLI --help output\n\n7. **Test Files**:\n   - Rename test files: `test_search.py` → `test_find.py`, `test_search_text.py` → `test_match.py`\n   - Update test function names\n   - Update assertions checking command output\n\n**Use Case Examples**:\n\n```bash\n# Semantic discovery\narc find my-code \"authentication patterns\"\n\n# Exact verification\narc match my-code '\"def authenticate\"'\n\n# Combined workflow\narc find research-papers \"machine learning\" | jq .results[].file_path\narc match research-papers '\"neural network\"' --filter 'file_path=paper.pdf'\n```\n\n**Validation**:\n- `arc find --help` shows semantic search help\n- `arc match --help` shows exact search help\n- `/arc:find` slash command works in Claude Code\n- `/arc:match` slash command works in Claude Code\n\n**Dependencies**:\n- Requires arcaneum-100 (arc rename) to be completed first\n- Works with arcaneum-99 (corpus positional)\n\n**Estimated Effort**: 4 hours","notes":"RDR documentation work completed. All search commands renamed to find/match in all RDRs. Ready for code implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T09:27:24.223473-07:00","updated_at":"2025-10-27T10:33:53.481458-07:00","closed_at":"2025-10-27T10:26:25.82714-07:00"}
{"id":"arcaneum-95","title":"Adopt /arc:command plugin slash command pattern","description":"Update Claude Code plugin slash commands to use `/arc:command` pattern (Beads-style colon separator) for proper namespacing.\n\n**Rationale**:\n- **Namespacing**: Avoids conflicts with other plugins\n- **Proven pattern**: Beads uses `/beads:ready`, `/beads:create` successfully\n- **Discoverable**: `/help` shows all `/arc:*` commands grouped together\n- **Consistent**: All arc commands under `/arc:` namespace\n- **Professional**: Matches marketplace plugin conventions\n\n**Current Pattern** (inconsistent):\n```bash\n/search \"\u003cquery\u003e\" --collection \u003cname\u003e           # No namespace\n/search-text \"\u003cpattern\u003e\" --index \u003cname\u003e         # No namespace\n/create-corpus \u003cname\u003e --type \u003ctype\u003e             # No namespace\n```\n\n**New Pattern** (namespaced):\n```bash\n/arc:find \u003ccorpus\u003e \"\u003cquery\u003e\"                    # Namespaced\n/arc:match \u003ccorpus\u003e \"\u003cpattern\u003e\"                 # Namespaced  \n/arc:corpus-create \u003cname\u003e --type \u003ctype\u003e         # Namespaced\n/arc:corpus-sync \u003cname\u003e \u003cpath\u003e                  # Namespaced\n```\n\n**Changes Required**:\n\n1. **Rename Command Files**:\n   - `commands/search.md` → `commands/arc-find.md`\n   - `commands/search-text.md` → `commands/arc-match.md`\n   - `commands/create-corpus.md` → `commands/arc-corpus-create.md`\n   - `commands/sync-directory.md` → `commands/arc-corpus-sync.md`\n   - All other `commands/*.md` files\n\n2. **Update Plugin Configuration**:\n   ```json\n   // .claude-plugin/plugin.json\n   {\n     \"commands\": [\n       \"./commands/arc-find.md\",\n       \"./commands/arc-match.md\",\n       \"./commands/arc-corpus-create.md\",\n       \"./commands/arc-corpus-sync.md\",\n       ...\n     ]\n   }\n   ```\n\n3. **Update Command Frontmatter**:\n   ```markdown\n   ---\n   description: Search corpus semantically (find patterns)\n   argument-hint: \u003ccorpus\u003e \"\u003cquery\u003e\" [options]\n   ---\n   ```\n\n4. **Update RDR-006**:\n   - Update all slash command examples to use `/arc:` prefix\n   - Update plugin integration documentation\n\n5. **Update README**:\n   - Show plugin usage with `/arc:` commands\n   - Update installation examples\n\n**Command Mapping**:\n\n| Old Slash Command | New Slash Command | Purpose |\n|-------------------|-------------------|---------|\n| `/search` | `/arc:find` | Semantic search |\n| `/search-text` | `/arc:match` | Exact search |\n| `/create-corpus` | `/arc:corpus-create` | Create corpus |\n| `/sync-directory` | `/arc:corpus-sync` | Sync documents |\n| `/list-collections` | `/arc:collection-list` | List collections |\n| `/list-indexes` | `/arc:index-list` | List indexes |\n\n**Validation**:\n- `/help` shows all `/arc:*` commands grouped\n- `/arc:find` executes semantic search\n- `/arc:match` executes exact search\n- `/arc:corpus-create` creates corpus\n- All commands use `${CLAUDE_PLUGIN_ROOT}` correctly\n\n**Files to Modify**:\n- All `commands/*.md` files (rename and update)\n- `.claude-plugin/plugin.json` (update command paths)\n- `doc/rdr/RDR-006-claude-code-integration.md` (update examples)\n- `README.md` (update plugin usage section)\n\n**Dependencies**:\n- Should be done after arcaneum-100 (arc rename)\n- Should be done after arcaneum-98 (find/match rename)\n\n**Estimated Effort**: 2 hours","notes":"RDR documentation work completed. All slash commands updated to /arc:command pattern in RDRs. Ready for plugin file creation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T09:27:57.704744-07:00","updated_at":"2025-10-27T10:33:53.481044-07:00","closed_at":"2025-10-27T10:26:25.991511-07:00"}
{"id":"arcaneum-96","title":"Convert corpus to positional argument (corpus-first pattern)","description":"Change corpus from `--corpus \u003cname\u003e` flag to first positional argument for cleaner, more intuitive syntax.\n\n**Rationale**:\n- **Always required**: If not optional, shouldn't be a flag\n- **Clearer syntax**: `arc find my-code \"query\"` reads naturally vs `arc find \"query\" --corpus my-code`\n- **Shorter**: Saves `--corpus ` (9 chars) per command\n- **Consistent**: Corpus is the primary context for operations\n- **Standard pattern**: Like `git commit`, `docker run` - resource comes first\n\n**Current Pattern** (flags):\n```bash\narc corpus sync \u003cpath\u003e --corpus \u003cname\u003e\narc find \"\u003cquery\u003e\" --collection \u003cname\u003e\narc match \"\u003cpattern\u003e\" --index \u003cname\u003e\n```\n\n**New Pattern** (corpus-first positional):\n```bash\narc corpus sync \u003cname\u003e \u003cpath\u003e         # Corpus first, then path\narc find \u003ccorpus\u003e \"\u003cquery\u003e\"           # Corpus first, then query\narc match \u003ccorpus\u003e \"\u003cpattern\u003e\"        # Corpus first, then pattern\n```\n\n**Changes Required**:\n\n1. **Corpus Management Commands**:\n   ```python\n   # src/arcaneum/cli/corpus.py\n   \n   # Before\n   @click.command('sync')\n   @click.argument('path')\n   @click.option('--corpus', required=True)\n   def sync(path, corpus):\n       ...\n   \n   # After\n   @click.command('sync')\n   @click.argument('corpus')  # First positional\n   @click.argument('path')    # Second positional\n   def sync(corpus, path):\n       ...\n   ```\n\n2. **Search Commands**:\n   ```python\n   # src/arcaneum/cli/find.py\n   \n   # Before\n   @click.command('find')\n   @click.argument('query')\n   @click.option('--collection', required=True)\n   def find_command(query, collection):\n       ...\n   \n   # After\n   @click.command('find')\n   @click.argument('corpus')  # First positional\n   @click.argument('query')   # Second positional\n   def find_command(corpus, query):\n       ...\n   ```\n\n   ```python\n   # src/arcaneum/cli/match.py\n   \n   # Before\n   @click.command('match')\n   @click.argument('pattern')\n   @click.option('--index', required=True)\n   def match_command(pattern, index):\n       ...\n   \n   # After\n   @click.command('match')\n   @click.argument('corpus')   # First positional\n   @click.argument('pattern')  # Second positional\n   def match_command(corpus, pattern):\n       ...\n   ```\n\n3. **Update All RDR Examples**:\n   - RDR-007: `arc search \"q\" --collection C` → `arc find C \"q\"`\n   - RDR-009: `arc sync-directory P --corpus C` → `arc corpus sync C P`\n   - RDR-012: `arc search-text \"p\" --index I` → `arc match I \"p\"`\n\n4. **Update Slash Commands**:\n   ```markdown\n   # commands/arc-find.md\n   \n   ---\n   description: Search corpus semantically\n   argument-hint: \u003ccorpus\u003e \"\u003cquery\u003e\" [options]\n   ---\n   \n   /arc:find \u003ccorpus\u003e \"\u003cquery\u003e\" [--filter] [--limit]\n   ```\n\n5. **Update Help Text**:\n   - All command --help output shows corpus as first positional\n   - Update argument descriptions\n\n**Use Case Examples**:\n\n```bash\n# Corpus management (corpus-first)\narc corpus create research-papers --type pdf --models stella\narc corpus sync research-papers ./papers\narc corpus info research-papers\n\n# Search (corpus-first)\narc find research-papers \"machine learning\"\narc match research-papers '\"neural network\"'\n\n# Combined workflow\narc find my-code \"auth patterns\"           # Discover semantically\narc match my-code '\"def authenticate\"'     # Verify exact match\n```\n\n**Validation**:\n- `arc find --help` shows: `arc find \u003ccorpus\u003e \u003cquery\u003e [OPTIONS]`\n- `arc corpus sync --help` shows: `arc corpus sync \u003ccorpus\u003e \u003cpath\u003e [OPTIONS]`\n- Commands work: `arc find my-code \"test\"`\n- Error if corpus missing: \"Error: Missing argument 'CORPUS'\"\n\n**Files to Modify**:\n- `src/arcaneum/cli/corpus.py` - Update sync command\n- `src/arcaneum/cli/find.py` - Make corpus first positional\n- `src/arcaneum/cli/match.py` - Make corpus first positional\n- All `commands/arc-*.md` files - Update argument hints\n- All RDRs (001-012) - Update command examples\n- Test files - Update command invocations\n\n**Dependencies**:\n- Should be done after arcaneum-100 (arc rename)\n- Should be done after arcaneum-98 (find/match rename)\n- Works with arcaneum-97 (slash pattern)\n\n**Estimated Effort**: 3 hours","notes":"RDR documentation work completed. All corpus arguments converted to positional (corpus-first pattern) in RDRs. Ready for code implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T09:28:39.539567-07:00","updated_at":"2025-10-27T10:33:53.480555-07:00","closed_at":"2025-10-27T10:26:26.1663-07:00"}
{"id":"arcaneum-97","title":"Adopt /arc:command plugin slash command pattern","description":"Update Claude Code plugin slash commands to use `/arc:command` pattern (Beads-style colon separator) for proper namespacing.\n\n**Rationale**:\n- **Namespacing**: Avoids conflicts with other plugins\n- **Proven pattern**: Beads uses `/beads:ready`, `/beads:create` successfully\n- **Discoverable**: `/help` shows all `/arc:*` commands grouped together\n- **Consistent**: All arc commands under `/arc:` namespace\n- **Professional**: Matches marketplace plugin conventions\n\n**Current Pattern** (inconsistent):\n```bash\n/search \"\u003cquery\u003e\" --collection \u003cname\u003e           # No namespace\n/search-text \"\u003cpattern\u003e\" --index \u003cname\u003e         # No namespace\n/create-corpus \u003cname\u003e --type \u003ctype\u003e             # No namespace\n```\n\n**New Pattern** (namespaced):\n```bash\n/arc:find \u003ccorpus\u003e \"\u003cquery\u003e\"                    # Namespaced\n/arc:match \u003ccorpus\u003e \"\u003cpattern\u003e\"                 # Namespaced  \n/arc:corpus-create \u003cname\u003e --type \u003ctype\u003e         # Namespaced\n/arc:corpus-sync \u003cname\u003e \u003cpath\u003e                  # Namespaced\n```\n\n**Changes Required**:\n\n1. **Rename Command Files**:\n   - `commands/search.md` → `commands/arc-find.md`\n   - `commands/search-text.md` → `commands/arc-match.md`\n   - `commands/create-corpus.md` → `commands/arc-corpus-create.md`\n   - `commands/sync-directory.md` → `commands/arc-corpus-sync.md`\n   - All other `commands/*.md` files\n\n2. **Update Plugin Configuration**:\n   ```json\n   // .claude-plugin/plugin.json\n   {\n     \"commands\": [\n       \"./commands/arc-find.md\",\n       \"./commands/arc-match.md\",\n       \"./commands/arc-corpus-create.md\",\n       \"./commands/arc-corpus-sync.md\",\n       ...\n     ]\n   }\n   ```\n\n3. **Update Command Frontmatter**:\n   ```markdown\n   ---\n   description: Search corpus semantically (find patterns)\n   argument-hint: \u003ccorpus\u003e \"\u003cquery\u003e\" [options]\n   ---\n   ```\n\n4. **Update RDR-006**:\n   - Update all slash command examples to use `/arc:` prefix\n   - Update plugin integration documentation\n\n5. **Update README**:\n   - Show plugin usage with `/arc:` commands\n   - Update installation examples\n\n**Command Mapping**:\n\n| Old Slash Command | New Slash Command | Purpose |\n|-------------------|-------------------|---------|\n| `/search` | `/arc:find` | Semantic search |\n| `/search-text` | `/arc:match` | Exact search |\n| `/create-corpus` | `/arc:corpus-create` | Create corpus |\n| `/sync-directory` | `/arc:corpus-sync` | Sync documents |\n| `/list-collections` | `/arc:collection-list` | List collections |\n| `/list-indexes` | `/arc:index-list` | List indexes |\n\n**Validation**:\n- `/help` shows all `/arc:*` commands grouped\n- `/arc:find` executes semantic search\n- `/arc:match` executes exact search\n- `/arc:corpus-create` creates corpus\n- All commands use `${CLAUDE_PLUGIN_ROOT}` correctly\n\n**Files to Modify**:\n- All `commands/*.md` files (rename and update)\n- `.claude-plugin/plugin.json` (update command paths)\n- `doc/rdr/RDR-006-claude-code-integration.md` (update examples)\n- `README.md` (update plugin usage section)\n\n**Dependencies**:\n- Should be done after arcaneum-93 (arc rename)\n- Should be done after arcaneum-94 (find/match rename)\n\n**Estimated Effort**: 2 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T10:33:53.471616-07:00","updated_at":"2025-10-27T10:58:59.87958-07:00","closed_at":"2025-10-27T10:58:59.87958-07:00"}
{"id":"arcaneum-98","title":"Rename search commands: search → find, search-text → match","description":"Rename search commands to use clearer, more intuitive verb pairing: `find` (semantic) + `match` (exact).\n\n**Rationale**:\n- **Clear pairing**: find/match are complementary verbs that naturally indicate their purposes\n- **Intuitive**: \"find patterns\" (discovery) vs \"match exact phrase\" (verification)\n- **Natural language**: Maps to how users think about search tasks\n- **Better than**: \"search\" vs \"search-text\" (confusing, unclear distinction)\n\n**Current Commands**:\n```bash\narc search \"\u003cquery\u003e\" --collection \u003cname\u003e      # Semantic search\narc search-text \"\u003cpattern\u003e\" --index \u003cname\u003e    # Exact search\n```\n\n**New Commands**:\n```bash\narc find \u003ccorpus\u003e \"\u003cquery\u003e\" [options]    # Semantic search (natural language)\narc match \u003ccorpus\u003e \"\u003cpattern\u003e\" [options] # Exact search (literal matching)\n```\n\n**Note**: Also adopts corpus-first positional pattern (see arcaneum-96)\n\n**Changes Required**:\n\n1. **CLI Module Renames**:\n   - `src/arcaneum/cli/search.py` → `src/arcaneum/cli/find.py`\n   - `src/arcaneum/cli/search_text.py` → `src/arcaneum/cli/match.py`\n\n2. **Command Decorators**:\n   ```python\n   # Before\n   @cli.command('search')\n   @cli.command('search-text')\n   \n   # After  \n   @cli.command('find')\n   @cli.command('match')\n   ```\n\n3. **Function Renames**:\n   - `search_command()` → `find_command()`\n   - `search_text_command()` → `match_command()`\n\n4. **Slash Commands**:\n   - `commands/search.md` → `commands/find.md`\n   - `commands/search-text.md` → `commands/match.md`\n   - Update execution blocks to call `arc find` and `arc match`\n\n5. **RDR Updates**:\n   - RDR-007: Update all `search` examples to `find`\n   - RDR-012: Update all `search-text` examples to `match`\n   - Global replace in code examples\n\n6. **Help Text and Docstrings**:\n   - Update command descriptions\n   - Update function docstrings\n   - Update CLI --help output\n\n7. **Test Files**:\n   - Rename test files: `test_search.py` → `test_find.py`, `test_search_text.py` → `test_match.py`\n   - Update test function names\n   - Update assertions checking command output\n\n**Use Case Examples**:\n\n```bash\n# Semantic discovery\narc find my-code \"authentication patterns\"\n\n# Exact verification\narc match my-code '\"def authenticate\"'\n\n# Combined workflow\narc find research-papers \"machine learning\" | jq .results[].file_path\narc match research-papers '\"neural network\"' --filter 'file_path=paper.pdf'\n```\n\n**Validation**:\n- `arc find --help` shows semantic search help\n- `arc match --help` shows exact search help\n- `/arc:find` slash command works in Claude Code\n- `/arc:match` slash command works in Claude Code\n\n**Dependencies**:\n- Requires arcaneum-93 (arc rename) to be completed first\n- Works with arcaneum-96 (corpus positional)\n\n**Estimated Effort**: 4 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T10:33:53.472046-07:00","updated_at":"2025-10-27T10:58:59.931184-07:00","closed_at":"2025-10-27T10:58:59.931184-07:00"}
{"id":"arcaneum-99","title":"Convert corpus to positional argument (corpus-first pattern)","description":"Change corpus from `--corpus \u003cname\u003e` flag to first positional argument for cleaner, more intuitive syntax.\n\n**Rationale**:\n- **Always required**: If not optional, shouldn't be a flag\n- **Clearer syntax**: `arc find my-code \"query\"` reads naturally vs `arc find \"query\" --corpus my-code`\n- **Shorter**: Saves `--corpus ` (9 chars) per command\n- **Consistent**: Corpus is the primary context for operations\n- **Standard pattern**: Like `git commit`, `docker run` - resource comes first\n\n**Current Pattern** (flags):\n```bash\narc corpus sync \u003cpath\u003e --corpus \u003cname\u003e\narc find \"\u003cquery\u003e\" --collection \u003cname\u003e\narc match \"\u003cpattern\u003e\" --index \u003cname\u003e\n```\n\n**New Pattern** (corpus-first positional):\n```bash\narc corpus sync \u003cname\u003e \u003cpath\u003e         # Corpus first, then path\narc find \u003ccorpus\u003e \"\u003cquery\u003e\"           # Corpus first, then query\narc match \u003ccorpus\u003e \"\u003cpattern\u003e\"        # Corpus first, then pattern\n```\n\n**Changes Required**:\n\n1. **Corpus Management Commands**:\n   ```python\n   # src/arcaneum/cli/corpus.py\n   \n   # Before\n   @click.command('sync')\n   @click.argument('path')\n   @click.option('--corpus', required=True)\n   def sync(path, corpus):\n       ...\n   \n   # After\n   @click.command('sync')\n   @click.argument('corpus')  # First positional\n   @click.argument('path')    # Second positional\n   def sync(corpus, path):\n       ...\n   ```\n\n2. **Search Commands**:\n   ```python\n   # src/arcaneum/cli/find.py\n   \n   # Before\n   @click.command('find')\n   @click.argument('query')\n   @click.option('--collection', required=True)\n   def find_command(query, collection):\n       ...\n   \n   # After\n   @click.command('find')\n   @click.argument('corpus')  # First positional\n   @click.argument('query')   # Second positional\n   def find_command(corpus, query):\n       ...\n   ```\n\n   ```python\n   # src/arcaneum/cli/match.py\n   \n   # Before\n   @click.command('match')\n   @click.argument('pattern')\n   @click.option('--index', required=True)\n   def match_command(pattern, index):\n       ...\n   \n   # After\n   @click.command('match')\n   @click.argument('corpus')   # First positional\n   @click.argument('pattern')  # Second positional\n   def match_command(corpus, pattern):\n       ...\n   ```\n\n3. **Update All RDR Examples**:\n   - RDR-007: `arc search \"q\" --collection C` → `arc find C \"q\"`\n   - RDR-009: `arc sync-directory P --corpus C` → `arc corpus sync C P`\n   - RDR-012: `arc search-text \"p\" --index I` → `arc match I \"p\"`\n\n4. **Update Slash Commands**:\n   ```markdown\n   # commands/arc-find.md\n   \n   ---\n   description: Search corpus semantically\n   argument-hint: \u003ccorpus\u003e \"\u003cquery\u003e\" [options]\n   ---\n   \n   /arc:find \u003ccorpus\u003e \"\u003cquery\u003e\" [--filter] [--limit]\n   ```\n\n5. **Update Help Text**:\n   - All command --help output shows corpus as first positional\n   - Update argument descriptions\n\n**Use Case Examples**:\n\n```bash\n# Corpus management (corpus-first)\narc corpus create research-papers --type pdf --models stella\narc corpus sync research-papers ./papers\narc corpus info research-papers\n\n# Search (corpus-first)\narc find research-papers \"machine learning\"\narc match research-papers '\"neural network\"'\n\n# Combined workflow\narc find my-code \"auth patterns\"           # Discover semantically\narc match my-code '\"def authenticate\"'     # Verify exact match\n```\n\n**Validation**:\n- `arc find --help` shows: `arc find \u003ccorpus\u003e \u003cquery\u003e [OPTIONS]`\n- `arc corpus sync --help` shows: `arc corpus sync \u003ccorpus\u003e \u003cpath\u003e [OPTIONS]`\n- Commands work: `arc find my-code \"test\"`\n- Error if corpus missing: \"Error: Missing argument 'CORPUS'\"\n\n**Files to Modify**:\n- `src/arcaneum/cli/corpus.py` - Update sync command\n- `src/arcaneum/cli/find.py` - Make corpus first positional\n- `src/arcaneum/cli/match.py` - Make corpus first positional\n- All `commands/arc-*.md` files - Update argument hints\n- All RDRs (001-012) - Update command examples\n- Test files - Update command invocations\n\n**Dependencies**:\n- Should be done after arcaneum-93 (arc rename)\n- Should be done after arcaneum-94 (find/match rename)\n- Works with arcaneum-95 (slash pattern)\n\n**Estimated Effort**: 3 hours","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-27T10:33:53.472434-07:00","updated_at":"2025-10-27T10:58:59.970689-07:00","closed_at":"2025-10-27T10:58:59.970689-07:00"}
